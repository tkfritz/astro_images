{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf439999",
   "metadata": {},
   "source": [
    "Neural network to get galaxy type, Here only two types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dbc7960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.cm as cm\n",
    "import sys\n",
    "import os\n",
    "#wcs is incompabible with newest numpy thus below not used \n",
    "#from astropy import wcs\n",
    "#to access astronomical images in fits format\n",
    "from astropy.io import fits\n",
    "#torch functions\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "#sklearn helper functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score,f1_score, log_loss\n",
    "#xgboost for comparison\n",
    "from xgboost import XGBClassifier\n",
    "#logistic regression for comparison \n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ef3837",
   "metadata": {},
   "source": [
    "Getting the data. It are currently four fields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9700cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 43, 1, 168)\n",
      "Index(['Unnamed: 0', 'index', 'objid', 'ra', 'dec', 'psfMag_u', 'psfMag_g',\n",
      "       'psfMag_r', 'psfMag_i', 'psfMag_z', 'probPSF_u', 'probPSF_g',\n",
      "       'probPSF_r', 'probPSF_i', 'probPSF_z', 'modelMag_u', 'modelMag_g',\n",
      "       'modelMag_r', 'modelMag_i', 'modelMag_z', 'petroRad_g', 'petroRad_r',\n",
      "       'petroRad_i', 'run', 'rerun', 'camcol', 'field', 'type', 'specobjid',\n",
      "       'class', 'subclass', 'redshift', 'plate', 'mjd', 'fiberid', 'nvote',\n",
      "       'p_el', 'p_cw', 'p_acw', 'p_edge', 'p_dk', 'p_mg', 'p_el_debiased',\n",
      "       'p_cs_debiased', 'spiral', 'elliptical', 'uncertain', 'image',\n",
      "       'pixel_x', 'pixel_y', 'off_image'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cutouts1=np.load(\"stripe82_1_ell_spiral_im.npy\")\n",
    "cutouts2=np.load(\"stripe82_2_ell_spiral_im.npy\")\n",
    "cutouts3=np.load(\"stripe82_3_ell_spiral_im.npy\")\n",
    "cutouts4=np.load(\"stripe82_4_ell_spiral_im.npy\")\n",
    "print(cutouts1.shape)\n",
    "df1=pd.read_csv(\"stripe82_1_ell_spiral_table.csv\")\n",
    "df2=pd.read_csv(\"stripe82_2_ell_spiral_table.csv\")\n",
    "df3=pd.read_csv(\"stripe82_3_ell_spiral_table.csv\")\n",
    "df4=pd.read_csv(\"stripe82_4_ell_spiral_table.csv\")\n",
    "print(df1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403b53ab",
   "metadata": {},
   "source": [
    "Now I built the function to combine the four numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec257466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combines numpy arrays of 4d shape, same shape first 3, last variable\n",
    "def comb_nump_4d(input_list):\n",
    "    l=0\n",
    "    for i in range(len(input_list)):\n",
    "        l+=input_list[i].shape[3]\n",
    "    combined=np.zeros((input_list[0].shape[0],input_list[0].shape[1],input_list[0].shape[2],l))\n",
    "    l=0\n",
    "    for i in range(len(input_list)):\n",
    "        combined[:,:,:,l:l+input_list[i].shape[3]]=input_list[i]\n",
    "        l+=input_list[i].shape[3]  \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e9fb82",
   "metadata": {},
   "source": [
    "Combining the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a533282",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_lists=[cutouts1,cutouts2,cutouts3,cutouts4]\n",
    "cutouts=comb_nump_4d(cutout_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d32e5f",
   "metadata": {},
   "source": [
    "Now combining the data frames with the classfications and more meta data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09b8126a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  index                objid         ra       dec  psfMag_u  \\\n",
      "0           0      1  1237663237128388701  50.130513 -1.228488  22.01211   \n",
      "1           1    123  1237666299481817102  50.160628 -1.035026  19.01124   \n",
      "2           2    140  1237663237128388949  50.167304 -1.241885  22.36878   \n",
      "3           3    458  1237666300018557091  50.006004 -0.495751  21.98376   \n",
      "4           4    110  1237663238739067202  50.387910  0.198944  21.86834   \n",
      "\n",
      "   psfMag_g  psfMag_r  psfMag_i  psfMag_z  ...   p_mg  p_el_debiased  \\\n",
      "0  20.06700  18.86854  18.35853  17.93478  ...  0.032          0.935   \n",
      "1  17.46116  16.85288  16.54355  16.19304  ...  0.000          0.971   \n",
      "2  20.17246  18.94735  18.44240  17.99196  ...  0.000          0.964   \n",
      "3  19.93291  18.73658  18.31895  17.89719  ...  0.000          0.893   \n",
      "4  19.78908  18.63620  18.16101  17.63892  ...  0.018          0.755   \n",
      "\n",
      "   p_cs_debiased  spiral  elliptical  uncertain  image      pixel_x  \\\n",
      "0          0.000       0           1          0      5  3362.991349   \n",
      "1          0.029       0           1          0      5  3089.338382   \n",
      "2          0.036       0           1          0      5  3028.607250   \n",
      "3          0.000       0           1          0      6  4495.057900   \n",
      "4          0.168       0           1          0      7  1023.284682   \n",
      "\n",
      "       pixel_y  off_image  \n",
      "0   199.840666      False  \n",
      "1  1958.577472      False  \n",
      "2    78.041829      False  \n",
      "3  2315.626917      False  \n",
      "4  4085.577633      False  \n",
      "\n",
      "[5 rows x 51 columns]    Unnamed: 0  index                objid         ra       dec  psfMag_u  \\\n",
      "0           0      1  1237663237128388701  50.130513 -1.228488  22.01211   \n",
      "1           1    123  1237666299481817102  50.160628 -1.035026  19.01124   \n",
      "2           2    140  1237663237128388949  50.167304 -1.241885  22.36878   \n",
      "3           3    458  1237666300018557091  50.006004 -0.495751  21.98376   \n",
      "4           4    110  1237663238739067202  50.387910  0.198944  21.86834   \n",
      "\n",
      "   psfMag_g  psfMag_r  psfMag_i  psfMag_z  ...   p_mg  p_el_debiased  \\\n",
      "0  20.06700  18.86854  18.35853  17.93478  ...  0.032          0.935   \n",
      "1  17.46116  16.85288  16.54355  16.19304  ...  0.000          0.971   \n",
      "2  20.17246  18.94735  18.44240  17.99196  ...  0.000          0.964   \n",
      "3  19.93291  18.73658  18.31895  17.89719  ...  0.000          0.893   \n",
      "4  19.78908  18.63620  18.16101  17.63892  ...  0.018          0.755   \n",
      "\n",
      "   p_cs_debiased  spiral  elliptical  uncertain  image      pixel_x  \\\n",
      "0          0.000       0           1          0      5  3362.991349   \n",
      "1          0.029       0           1          0      5  3089.338382   \n",
      "2          0.036       0           1          0      5  3028.607250   \n",
      "3          0.000       0           1          0      6  4495.057900   \n",
      "4          0.168       0           1          0      7  1023.284682   \n",
      "\n",
      "       pixel_y  off_image  \n",
      "0   199.840666      False  \n",
      "1  1958.577472      False  \n",
      "2    78.041829      False  \n",
      "3  2315.626917      False  \n",
      "4  4085.577633      False  \n",
      "\n",
      "[5 rows x 51 columns]      Unnamed: 0  index                objid         ra       dec  psfMag_u  \\\n",
      "130         132     62  1237678617437470859  44.819196  0.808289  21.83158   \n",
      "131         133    386  1237678437018632283  44.798261  0.977963  21.35310   \n",
      "132         134    176  1237678617437405309  44.745545  0.792307  20.98310   \n",
      "133         135    102  1237678617437339747  44.556297  0.777128  21.42082   \n",
      "134         136    192  1237678617974210788  44.601434  1.138604  20.16281   \n",
      "\n",
      "     psfMag_g  psfMag_r  psfMag_i  psfMag_z  ...  p_mg  p_el_debiased  \\\n",
      "130  20.10588  18.78611  18.27595  17.91708  ...   0.0          0.913   \n",
      "131  19.27308  18.25705  17.83170  17.34455  ...   0.0          0.838   \n",
      "132  19.07507  17.89066  17.32709  16.82939  ...   0.0          0.082   \n",
      "133  19.90794  19.16694  18.76981  18.22978  ...   0.0          0.110   \n",
      "134  18.77133  18.06879  17.64503  17.17350  ...   0.0          0.906   \n",
      "\n",
      "     p_cs_debiased  spiral  elliptical  uncertain  image      pixel_x  \\\n",
      "130          0.000       0           1          0     29  1648.010218   \n",
      "131          0.000       0           1          0     29  1838.328477   \n",
      "132          0.918       1           0          0     29  2317.493942   \n",
      "133          0.890       1           0          0     29  4037.775643   \n",
      "134          0.000       0           1          0     29  3627.329256   \n",
      "\n",
      "         pixel_y  off_image  \n",
      "130   534.170921      False  \n",
      "131  2076.665012      False  \n",
      "132   388.877702      False  \n",
      "133   250.891034      False  \n",
      "134  3537.034422      False  \n",
      "\n",
      "[5 rows x 51 columns]      Unnamed: 0  index                objid         ra       dec  psfMag_u  \\\n",
      "705         132     62  1237678617437470859  44.819196  0.808289  21.83158   \n",
      "706         133    386  1237678437018632283  44.798261  0.977963  21.35310   \n",
      "707         134    176  1237678617437405309  44.745545  0.792307  20.98310   \n",
      "708         135    102  1237678617437339747  44.556297  0.777128  21.42082   \n",
      "709         136    192  1237678617974210788  44.601434  1.138604  20.16281   \n",
      "\n",
      "     psfMag_g  psfMag_r  psfMag_i  psfMag_z  ...  p_mg  p_el_debiased  \\\n",
      "705  20.10588  18.78611  18.27595  17.91708  ...   0.0          0.913   \n",
      "706  19.27308  18.25705  17.83170  17.34455  ...   0.0          0.838   \n",
      "707  19.07507  17.89066  17.32709  16.82939  ...   0.0          0.082   \n",
      "708  19.90794  19.16694  18.76981  18.22978  ...   0.0          0.110   \n",
      "709  18.77133  18.06879  17.64503  17.17350  ...   0.0          0.906   \n",
      "\n",
      "     p_cs_debiased  spiral  elliptical  uncertain  image      pixel_x  \\\n",
      "705          0.000       0           1          0     29  1648.010218   \n",
      "706          0.000       0           1          0     29  1838.328477   \n",
      "707          0.918       1           0          0     29  2317.493942   \n",
      "708          0.890       1           0          0     29  4037.775643   \n",
      "709          0.000       0           1          0     29  3627.329256   \n",
      "\n",
      "         pixel_y  off_image  \n",
      "705   534.170921      False  \n",
      "706  2076.665012      False  \n",
      "707   388.877702      False  \n",
      "708   250.891034      False  \n",
      "709  3537.034422      False  \n",
      "\n",
      "[5 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.concat([df1,df2,df3,df4],ignore_index=True)\n",
    "print(df1.head(),df.head(),df4.tail(),df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3869cb3",
   "metadata": {},
   "source": [
    "Has worked, now looking on classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c050e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    504\n",
      "0    206\n",
      "Name: spiral, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.spiral.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e80bacb",
   "metadata": {},
   "source": [
    "Somewhat inbalanced, clearly more spirals than ellipctical galaxies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64f1c534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "#adding cpu\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fd05437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of image train data\n",
      "(426, 1, 43, 43)\n",
      "(284, 1, 43, 43)\n"
     ]
    }
   ],
   "source": [
    "target_train, target_test,image_train,image_test,df_train,df_test= train_test_split(df.loc[:,\"spiral\"],cutouts.T,df,train_size=0.60, shuffle=True, random_state=1)\n",
    "print(\"shape of image train data\")\n",
    "print(image_train.shape)\n",
    "print(image_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c110c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_torch(model,data):\n",
    "    y_pred_list_c = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X_batch, _ in data:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_pred_list_c.append(y_test_pred.cpu().numpy())\n",
    "    y_pred_list_c = [a.squeeze().tolist() for a in y_pred_list_c]\n",
    "    return y_pred_list_c  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce2603da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfafe815",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train, target_test = np.array(target_train), np.array(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b6cd967",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b64b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_im_dataset = ClassificationDataset(torch.from_numpy(image_train).float(), torch.from_numpy(target_train).float())\n",
    "test_im_dataset = ClassificationDataset(torch.from_numpy(image_test).float(), torch.from_numpy(target_test).float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48612e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_im_loader = DataLoader(dataset=train_im_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_im_loader = DataLoader(dataset=test_im_dataset, batch_size=1)\n",
    "train_im_loader_pred = DataLoader(dataset=train_im_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd54b66",
   "metadata": {},
   "source": [
    "Test input outputs relations for network of 3 layers, it is still 3 *3 convolutional and 2 *2 maximuma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd3e904e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first conv layer input: torch.Size([1, 1, 43, 43]) output: torch.Size([1, 16, 41, 41])\n",
      "max pool input:torch.Size([1, 16, 41, 41]) output:torch.Size([1, 16, 20, 20])\n",
      "second conv layer input: torch.Size([1, 16, 20, 20]) output: torch.Size([1, 32, 18, 18])\n",
      "second max pool layer input: torch.Size([1, 32, 18, 18]) output: torch.Size([1, 32, 9, 9])\n",
      "third conv layer input: torch.Size([1, 32, 9, 9]) output: torch.Size([1, 64, 7, 7])\n",
      "third max pool layer input: torch.Size([1, 64, 7, 7]) output: torch.Size([1, 64, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "input0 = torch.randn(1, 1, 43, 43)\n",
    "b=torch.nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=0)\n",
    "output0=b(input0)\n",
    "print(f\"first conv layer input: {input0.shape} output: {output0.shape}\")\n",
    "\n",
    "m = nn.MaxPool2d((2, 2), stride=(2, 2))\n",
    "#standard drops but can be changed, can also use pooling and co get better number \n",
    "output1 = m(output0)\n",
    "print(f\"max pool input:{output0.shape} output:{output1.shape}\")\n",
    "#input format (Batch, Number Channels, height, width)\n",
    "b2=torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "output2=b2(output1)\n",
    "print(f\"second conv layer input: {output1.shape} output: {output2.shape}\")\n",
    "output3 = m(output2)\n",
    "print(f\"second max pool layer input: {output2.shape} output: {output3.shape}\")\n",
    "\n",
    "b3=torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "output4=b3(output3)\n",
    "print(f\"third conv layer input: {output3.shape} output: {output4.shape}\")\n",
    "output5 = m(output4)\n",
    "print(f\"third max pool layer input: {output4.shape} output: {output5.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6af116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBinary4(torch.nn.Module):\n",
    "    #no padding because image does not really end when the data ends. \n",
    "    def __init__(self):\n",
    "        super(CNNBinary4, self).__init__()\n",
    "        # L1 ImgIn shape=(?, 43, 43, 1)\n",
    "        # Conv -> (?, 41, 41, 16)\n",
    "        # Pool -> (?, 20, 20, 16)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=0),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "        # L2 ImgIn shape=(?, 20, 20, 16)\n",
    "        # Conv      ->(?, 18, 18, 32)\n",
    "        # Pool      ->(?, 9, 9, 32)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=0),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "        # L3 ImgIn shape=(?, 9, 9, 32)\n",
    "        # Conv      ->(?, 7, 7, 64)\n",
    "        # Pool      ->(?, 3, 3, 64)\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))        \n",
    "        # L3 FC 3x3x64 inputs -> 128 outputs\n",
    "        self.fc1 = torch.nn.Linear(3 * 3 * 64, 128, bias=True)\n",
    "        torch.nn.init.xavier_uniform(self.fc1.weight)\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            self.fc1,\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "        # L4 Final FC 128 inputs -> 1 output\n",
    "        self.fc2 = torch.nn.Linear(128, 1, bias=True) #\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight) # initialize parameters\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out) #dont forget to add/omit layer here\n",
    "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
    "        out = self.fc1(out)\n",
    "        out = torch.sigmoid(self.fc2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18c57640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNBinary4(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=576, out_features=128, bias=True)\n",
      "  (layer4): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19938/994019738.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight)\n"
     ]
    }
   ],
   "source": [
    "keep_prob=1\n",
    "model1 =CNNBinary4()\n",
    "model1.to(device)\n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f3c2e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the function to fit it\n",
    "#parameters: model used, train_data, test_data, epchs, batch_size, learning_rate, file to collect sats, \n",
    "#optional regularization \n",
    "def torch_fit(model,train_loader,test_loader,epochs,batch_size,learning_rate,loss_stats,l2reg=0):\n",
    "    learning_rate = learning_rate\n",
    "    criterion = torch.nn.BCELoss()    # Softmax is internally computed.\n",
    "    #if no regularization\n",
    "    if l2reg==0:\n",
    "        optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    #l2 regularization is added in optimizer as weight_decay=1e-5 or nsimilar \n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate,weight_decay=l2reg)        \n",
    "    print(\"Begin training.\")\n",
    "    for e in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "        # TRAINING\n",
    "        train_epoch_loss = 0\n",
    "        model.train()\n",
    "        for X_train_batch, y_train_batch in train_loader:\n",
    "            X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            y_train_pred = model(X_train_batch)\n",
    "        \n",
    "            train_loss = criterion(y_train_pred, y_train_batch.unsqueeze(1))\n",
    "        \n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            train_epoch_loss += train_loss.item()\n",
    "        \n",
    "        \n",
    "        # VALIDATION    \n",
    "        with torch.no_grad():\n",
    "        \n",
    "            test_epoch_loss = 0\n",
    "        \n",
    "            model.eval()\n",
    "            for X_test_batch, y_test_batch in test_loader:\n",
    "                X_test_batch, y_test_batch = X_test_batch.to(device), y_test_batch.to(device)\n",
    "            \n",
    "                y_test_pred = model(X_test_batch)\n",
    "                        \n",
    "                test_loss = criterion(y_test_pred, y_test_batch.unsqueeze(1))\n",
    "            \n",
    "                test_epoch_loss += test_loss.item()\n",
    "        loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "        loss_stats['test'].append(test_epoch_loss/len(test_loader))                              \n",
    "    \n",
    "        print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Test Loss: {test_epoch_loss/len(test_loader):.5f}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d09738a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ce306e4ab04de7b78dc9e8ab3ceea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 28.15375 | Test Loss: 27.46479\n",
      "Epoch 002: | Train Loss: 29.06250 | Test Loss: 27.46479\n",
      "Epoch 003: | Train Loss: 30.04464 | Test Loss: 27.46479\n",
      "Epoch 004: | Train Loss: 30.53571 | Test Loss: 27.46479\n",
      "Epoch 005: | Train Loss: 30.04464 | Test Loss: 27.46479\n",
      "Epoch 006: | Train Loss: 29.06250 | Test Loss: 27.46479\n",
      "Epoch 007: | Train Loss: 31.02679 | Test Loss: 27.46479\n",
      "Epoch 008: | Train Loss: 30.04464 | Test Loss: 27.46479\n",
      "Epoch 009: | Train Loss: 30.04464 | Test Loss: 27.46479\n",
      "Epoch 010: | Train Loss: 29.06250 | Test Loss: 27.46479\n",
      "Epoch 011: | Train Loss: 30.53571 | Test Loss: 27.46479\n",
      "Epoch 012: | Train Loss: 29.55357 | Test Loss: 27.46479\n",
      "Epoch 013: | Train Loss: 30.04464 | Test Loss: 27.46479\n",
      "Epoch 014: | Train Loss: 29.55357 | Test Loss: 27.46479\n",
      "Epoch 015: | Train Loss: 31.02679 | Test Loss: 27.46479\n",
      "Epoch 016: | Train Loss: 28.57143 | Test Loss: 27.46479\n",
      "Epoch 017: | Train Loss: 29.55357 | Test Loss: 27.46479\n",
      "Epoch 018: | Train Loss: 30.53571 | Test Loss: 27.46479\n",
      "Epoch 019: | Train Loss: 30.53571 | Test Loss: 27.46479\n",
      "Epoch 020: | Train Loss: 30.04464 | Test Loss: 27.46479\n",
      "Epoch 021: | Train Loss: 29.06250 | Test Loss: 27.46479\n",
      "Epoch 022: | Train Loss: 29.55357 | Test Loss: 27.46479\n",
      "Epoch 023: | Train Loss: 30.53571 | Test Loss: 27.46479\n",
      "Epoch 024: | Train Loss: 30.04464 | Test Loss: 27.46479\n",
      "Epoch 025: | Train Loss: 30.04464 | Test Loss: 27.46479\n",
      "Epoch 026: | Train Loss: 31.02679 | Test Loss: 27.46479\n",
      "Epoch 027: | Train Loss: 30.04464 | Test Loss: 27.46479\n",
      "Epoch 028: | Train Loss: 30.04464 | Test Loss: 27.46479\n",
      "Epoch 029: | Train Loss: 30.04464 | Test Loss: 27.46479\n",
      "Epoch 030: | Train Loss: 30.53571 | Test Loss: 27.46479\n",
      "Epoch 031: | Train Loss: 29.55357 | Test Loss: 27.46479\n",
      "Epoch 032: | Train Loss: 30.53571 | Test Loss: 27.46479\n",
      "Epoch 033: | Train Loss: 29.06250 | Test Loss: 27.46479\n",
      "Epoch 034: | Train Loss: 29.55357 | Test Loss: 27.46479\n",
      "Epoch 035: | Train Loss: 30.04464 | Test Loss: 27.46479\n",
      "Epoch 036: | Train Loss: 30.04464 | Test Loss: 27.46479\n",
      "Epoch 037: | Train Loss: 29.55357 | Test Loss: 27.46479\n",
      "Epoch 038: | Train Loss: 29.55357 | Test Loss: 27.46479\n",
      "Epoch 039: | Train Loss: 30.53571 | Test Loss: 27.46479\n",
      "Epoch 040: | Train Loss: 29.55357 | Test Loss: 27.46479\n",
      "Epoch 041: | Train Loss: 29.06250 | Test Loss: 27.46479\n",
      "Epoch 042: | Train Loss: 30.04464 | Test Loss: 27.46479\n",
      "Epoch 043: | Train Loss: 30.53571 | Test Loss: 27.46479\n",
      "Epoch 044: | Train Loss: 31.02679 | Test Loss: 27.46479\n",
      "Epoch 045: | Train Loss: 30.53571 | Test Loss: 27.46479\n",
      "Epoch 046: | Train Loss: 30.53571 | Test Loss: 27.46479\n",
      "Epoch 047: | Train Loss: 30.04464 | Test Loss: 27.46479\n",
      "Epoch 048: | Train Loss: 29.55357 | Test Loss: 27.46479\n",
      "Epoch 049: | Train Loss: 29.06250 | Test Loss: 27.46479\n",
      "Epoch 050: | Train Loss: 30.53571 | Test Loss: 27.46479\n",
      "Epoch 051: | Train Loss: 29.55357 | Test Loss: 27.46479\n",
      "Epoch 052: | Train Loss: 30.53571 | Test Loss: 27.46479\n",
      "Epoch 053: | Train Loss: 30.53571 | Test Loss: 27.46479\n",
      "Epoch 054: | Train Loss: 30.04464 | Test Loss: 27.46479\n",
      "Epoch 055: | Train Loss: 31.02679 | Test Loss: 27.46479\n",
      "Epoch 056: | Train Loss: 30.04464 | Test Loss: 27.46479\n",
      "Epoch 057: | Train Loss: 30.53571 | Test Loss: 27.46479\n",
      "Epoch 058: | Train Loss: 30.53571 | Test Loss: 27.46479\n",
      "Epoch 059: | Train Loss: 29.06250 | Test Loss: 27.46479\n",
      "Epoch 060: | Train Loss: 29.06250 | Test Loss: 27.46479\n"
     ]
    }
   ],
   "source": [
    "#somehow nothing improves like sometimes, unclear what is reason mistake in setup or real chance ? \n",
    "loss_stats_test = {\n",
    "    'train': [], 'test': []\n",
    "}\n",
    "torch_fit(model1,train_im_loader,test_im_loader,200,32,0.01,loss_stats_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab1f2a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0\n",
      " 1 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 1 0 0 0\n",
      " 1 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0\n",
      " 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 1] (426,)\n"
     ]
    }
   ],
   "source": [
    "print(target_test,target_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f9753a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_test=pred_torch(model1,test_im_loader)\n",
    "c_train=pred_torch(model1,train_im_loader_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a89bec36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(c_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235f8bce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
