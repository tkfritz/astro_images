{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf439999",
   "metadata": {},
   "source": [
    "Neural network to get galaxy type, Here only two types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dbc7960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.cm as cm\n",
    "import sys\n",
    "import os\n",
    "#wcs is incompabible with newest numpy thus below not used \n",
    "#from astropy import wcs\n",
    "#to access astronomical images in fits format\n",
    "from astropy.io import fits\n",
    "#torch functions\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "#sklearn helper functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score,f1_score, log_loss\n",
    "#xgboost for comparison\n",
    "from xgboost import XGBClassifier\n",
    "#logistic regression for comparison \n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ef3837",
   "metadata": {},
   "source": [
    "Getting the data. It are 43 fields. From 310 (-50) degree to 60 degree in right ascension with a height from -1.26 to +1.26  degree in declination. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9700cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 43, 1, 168)\n",
      "Index(['Unnamed: 0', 'index', 'objid', 'ra', 'dec', 'psfMag_u', 'psfMag_g',\n",
      "       'psfMag_r', 'psfMag_i', 'psfMag_z', 'probPSF_u', 'probPSF_g',\n",
      "       'probPSF_r', 'probPSF_i', 'probPSF_z', 'modelMag_u', 'modelMag_g',\n",
      "       'modelMag_r', 'modelMag_i', 'modelMag_z', 'petroRad_g', 'petroRad_r',\n",
      "       'petroRad_i', 'run', 'rerun', 'camcol', 'field', 'type', 'specobjid',\n",
      "       'class', 'subclass', 'redshift', 'plate', 'mjd', 'fiberid', 'nvote',\n",
      "       'p_el', 'p_cw', 'p_acw', 'p_edge', 'p_dk', 'p_mg', 'p_el_debiased',\n",
      "       'p_cs_debiased', 'spiral', 'elliptical', 'uncertain', 'image',\n",
      "       'pixel_x', 'pixel_y', 'off_image'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cutouts1=np.load(\"stripe82_1_ell_spiral_im.npy\")\n",
    "cutouts2=np.load(\"stripe82_2_ell_spiral_im.npy\")\n",
    "cutouts3=np.load(\"stripe82_3_ell_spiral_im.npy\")\n",
    "cutouts4=np.load(\"stripe82_4_ell_spiral_im.npy\")\n",
    "cutouts5=np.load(\"stripe82_5_ell_spiral_im.npy\")\n",
    "cutouts6=np.load(\"stripe82_6_ell_spiral_im.npy\")\n",
    "cutouts7=np.load(\"stripe82_7_ell_spiral_im.npy\")\n",
    "cutouts8=np.load(\"stripe82_8_ell_spiral_im.npy\")\n",
    "cutouts9=np.load(\"stripe82_9_ell_spiral_im.npy\")\n",
    "cutouts10=np.load(\"stripe82_10_ell_spiral_im.npy\")\n",
    "cutouts11=np.load(\"stripe82_11_ell_spiral_im.npy\")\n",
    "cutouts12=np.load(\"stripe82_12_ell_spiral_im.npy\")\n",
    "cutouts13=np.load(\"stripe82_13_ell_spiral_im.npy\")\n",
    "cutouts14=np.load(\"stripe82_14_ell_spiral_im.npy\")\n",
    "cutouts15=np.load(\"stripe82_15_ell_spiral_im.npy\")\n",
    "cutouts16=np.load(\"stripe82_16_ell_spiral_im.npy\")\n",
    "cutouts17=np.load(\"stripe82_17_ell_spiral_im.npy\")\n",
    "cutouts18=np.load(\"stripe82_18_ell_spiral_im.npy\")\n",
    "cutouts19=np.load(\"stripe82_19_ell_spiral_im.npy\")\n",
    "cutouts20=np.load(\"stripe82_20_ell_spiral_im.npy\")\n",
    "cutouts21=np.load(\"stripe82_21_ell_spiral_im.npy\")\n",
    "cutouts22=np.load(\"stripe82_22_ell_spiral_im.npy\")\n",
    "cutouts23=np.load(\"stripe82_23_ell_spiral_im.npy\")\n",
    "cutouts24=np.load(\"stripe82_24_ell_spiral_im.npy\")\n",
    "cutouts25=np.load(\"stripe82_25_ell_spiral_im.npy\")\n",
    "cutouts26=np.load(\"stripe82_26_ell_spiral_im.npy\")\n",
    "cutouts27=np.load(\"stripe82_27_ell_spiral_im.npy\")\n",
    "cutouts28=np.load(\"stripe82_28_ell_spiral_im.npy\")\n",
    "cutouts29=np.load(\"stripe82_29_ell_spiral_im.npy\")\n",
    "cutouts30=np.load(\"stripe82_30_ell_spiral_im.npy\")\n",
    "cutouts31=np.load(\"stripe82_31_ell_spiral_im.npy\")\n",
    "cutouts32=np.load(\"stripe82_32_ell_spiral_im.npy\")\n",
    "cutouts33=np.load(\"stripe82_33_ell_spiral_im.npy\")\n",
    "cutouts34=np.load(\"stripe82_34_ell_spiral_im.npy\")\n",
    "cutouts35=np.load(\"stripe82_35_ell_spiral_im.npy\")\n",
    "cutouts36=np.load(\"stripe82_36_ell_spiral_im.npy\")\n",
    "cutouts37=np.load(\"stripe82_37_ell_spiral_im.npy\")\n",
    "cutouts38=np.load(\"stripe82_38_ell_spiral_im.npy\")\n",
    "cutouts39=np.load(\"stripe82_39_ell_spiral_im.npy\")\n",
    "cutouts40=np.load(\"stripe82_40_ell_spiral_im.npy\")\n",
    "cutouts41=np.load(\"stripe82_41_ell_spiral_im.npy\")\n",
    "cutouts42=np.load(\"stripe82_42_ell_spiral_im.npy\")\n",
    "cutouts43=np.load(\"stripe82_43_ell_spiral_im.npy\")\n",
    "print(cutouts1.shape)\n",
    "#better a direct list later \n",
    "df1=pd.read_csv(\"stripe82_1_ell_spiral_table.csv\")\n",
    "df2=pd.read_csv(\"stripe82_2_ell_spiral_table.csv\")\n",
    "df3=pd.read_csv(\"stripe82_3_ell_spiral_table.csv\")\n",
    "df4=pd.read_csv(\"stripe82_4_ell_spiral_table.csv\")\n",
    "df5=pd.read_csv(\"stripe82_5_ell_spiral_table.csv\")\n",
    "df6=pd.read_csv(\"stripe82_6_ell_spiral_table.csv\")\n",
    "df7=pd.read_csv(\"stripe82_7_ell_spiral_table.csv\")\n",
    "df8=pd.read_csv(\"stripe82_8_ell_spiral_table.csv\")\n",
    "df9=pd.read_csv(\"stripe82_9_ell_spiral_table.csv\")\n",
    "df10=pd.read_csv(\"stripe82_10_ell_spiral_table.csv\")\n",
    "df11=pd.read_csv(\"stripe82_11_ell_spiral_table.csv\")\n",
    "df12=pd.read_csv(\"stripe82_12_ell_spiral_table.csv\")\n",
    "df13=pd.read_csv(\"stripe82_13_ell_spiral_table.csv\")\n",
    "df14=pd.read_csv(\"stripe82_14_ell_spiral_table.csv\")\n",
    "df15=pd.read_csv(\"stripe82_15_ell_spiral_table.csv\")\n",
    "df16=pd.read_csv(\"stripe82_16_ell_spiral_table.csv\")\n",
    "df17=pd.read_csv(\"stripe82_17_ell_spiral_table.csv\")\n",
    "df18=pd.read_csv(\"stripe82_18_ell_spiral_table.csv\")\n",
    "df19=pd.read_csv(\"stripe82_19_ell_spiral_table.csv\")\n",
    "df20=pd.read_csv(\"stripe82_20_ell_spiral_table.csv\")\n",
    "df21=pd.read_csv(\"stripe82_21_ell_spiral_table.csv\")\n",
    "df22=pd.read_csv(\"stripe82_22_ell_spiral_table.csv\")\n",
    "df23=pd.read_csv(\"stripe82_23_ell_spiral_table.csv\")\n",
    "df24=pd.read_csv(\"stripe82_24_ell_spiral_table.csv\")\n",
    "df25=pd.read_csv(\"stripe82_5_ell_spiral_table.csv\")\n",
    "df26=pd.read_csv(\"stripe82_6_ell_spiral_table.csv\")\n",
    "df27=pd.read_csv(\"stripe82_7_ell_spiral_table.csv\")\n",
    "df28=pd.read_csv(\"stripe82_8_ell_spiral_table.csv\")\n",
    "df29=pd.read_csv(\"stripe82_9_ell_spiral_table.csv\")\n",
    "df30=pd.read_csv(\"stripe82_10_ell_spiral_table.csv\")\n",
    "df31=pd.read_csv(\"stripe82_11_ell_spiral_table.csv\")\n",
    "df32=pd.read_csv(\"stripe82_12_ell_spiral_table.csv\")\n",
    "df33=pd.read_csv(\"stripe82_13_ell_spiral_table.csv\")\n",
    "df14=pd.read_csv(\"stripe82_14_ell_spiral_table.csv\")\n",
    "df15=pd.read_csv(\"stripe82_15_ell_spiral_table.csv\")\n",
    "df16=pd.read_csv(\"stripe82_16_ell_spiral_table.csv\")\n",
    "df17=pd.read_csv(\"stripe82_17_ell_spiral_table.csv\")\n",
    "df18=pd.read_csv(\"stripe82_18_ell_spiral_table.csv\")\n",
    "df19=pd.read_csv(\"stripe82_19_ell_spiral_table.csv\")\n",
    "df20=pd.read_csv(\"stripe82_20_ell_spiral_table.csv\")\n",
    "df21=pd.read_csv(\"stripe82_21_ell_spiral_table.csv\")\n",
    "df22=pd.read_csv(\"stripe82_22_ell_spiral_table.csv\")\n",
    "df23=pd.read_csv(\"stripe82_23_ell_spiral_table.csv\")\n",
    "df24=pd.read_csv(\"stripe82_24_ell_spiral_table.csv\")\n",
    "df25=pd.read_csv(\"stripe82_25_ell_spiral_table.csv\")\n",
    "df26=pd.read_csv(\"stripe82_26_ell_spiral_table.csv\")\n",
    "df27=pd.read_csv(\"stripe82_27_ell_spiral_table.csv\")\n",
    "df28=pd.read_csv(\"stripe82_28_ell_spiral_table.csv\")\n",
    "df29=pd.read_csv(\"stripe82_29_ell_spiral_table.csv\")\n",
    "df30=pd.read_csv(\"stripe82_30_ell_spiral_table.csv\")\n",
    "df31=pd.read_csv(\"stripe82_31_ell_spiral_table.csv\")\n",
    "df32=pd.read_csv(\"stripe82_32_ell_spiral_table.csv\")\n",
    "df33=pd.read_csv(\"stripe82_33_ell_spiral_table.csv\")\n",
    "df34=pd.read_csv(\"stripe82_34_ell_spiral_table.csv\")\n",
    "df35=pd.read_csv(\"stripe82_35_ell_spiral_table.csv\")\n",
    "df36=pd.read_csv(\"stripe82_36_ell_spiral_table.csv\")\n",
    "df37=pd.read_csv(\"stripe82_37_ell_spiral_table.csv\")\n",
    "df38=pd.read_csv(\"stripe82_38_ell_spiral_table.csv\")\n",
    "df39=pd.read_csv(\"stripe82_39_ell_spiral_table.csv\")\n",
    "df40=pd.read_csv(\"stripe82_40_ell_spiral_table.csv\")\n",
    "df41=pd.read_csv(\"stripe82_41_ell_spiral_table.csv\")\n",
    "df42=pd.read_csv(\"stripe82_42_ell_spiral_table.csv\")\n",
    "df43=pd.read_csv(\"stripe82_43_ell_spiral_table.csv\")\n",
    "print(df1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3783f0",
   "metadata": {},
   "source": [
    "Now I built the function to combine the four numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c91ccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combines numpy arrays of 4d shape, same shape first 3, last variable\n",
    "def comb_nump_4d(input_list):\n",
    "    l=0\n",
    "    for i in range(len(input_list)):\n",
    "        l+=input_list[i].shape[3]\n",
    "    combined=np.zeros((input_list[0].shape[0],input_list[0].shape[1],input_list[0].shape[2],l))\n",
    "    l=0\n",
    "    for i in range(len(input_list)):\n",
    "        combined[:,:,:,l:l+input_list[i].shape[3]]=input_list[i]\n",
    "        l+=input_list[i].shape[3]  \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f8f83",
   "metadata": {},
   "source": [
    "Combining the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f73a3ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_lists=[cutouts1,cutouts2,cutouts3,cutouts4,cutouts5,cutouts6,cutouts7,cutouts8,cutouts9,cutouts10,cutouts11,cutouts12,cutouts13,cutouts14,cutouts15,cutouts16,cutouts17,cutouts18,cutouts19,cutouts20,cutouts21,cutouts22,cutouts23,cutouts24,cutouts25,cutouts26,cutouts27,cutouts28,cutouts29,cutouts30,cutouts31,cutouts32,cutouts33,cutouts34,cutouts35,cutouts36,cutouts37,cutouts38,cutouts39,cutouts40,cutouts41,cutouts42,cutouts43]\n",
    "cutouts=comb_nump_4d(cutout_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac6967d",
   "metadata": {},
   "source": [
    "Now combining the data frames with the classfications and more meta data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "084280f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  index                objid         ra       dec  psfMag_u  \\\n",
      "0           0      1  1237663237128388701  50.130513 -1.228488  22.01211   \n",
      "1           1    123  1237666299481817102  50.160628 -1.035026  19.01124   \n",
      "2           2    140  1237663237128388949  50.167304 -1.241885  22.36878   \n",
      "3           3    458  1237666300018557091  50.006004 -0.495751  21.98376   \n",
      "4           4    110  1237663238739067202  50.387910  0.198944  21.86834   \n",
      "\n",
      "   psfMag_g  psfMag_r  psfMag_i  psfMag_z  ...   p_mg  p_el_debiased  \\\n",
      "0  20.06700  18.86854  18.35853  17.93478  ...  0.032          0.935   \n",
      "1  17.46116  16.85288  16.54355  16.19304  ...  0.000          0.971   \n",
      "2  20.17246  18.94735  18.44240  17.99196  ...  0.000          0.964   \n",
      "3  19.93291  18.73658  18.31895  17.89719  ...  0.000          0.893   \n",
      "4  19.78908  18.63620  18.16101  17.63892  ...  0.018          0.755   \n",
      "\n",
      "   p_cs_debiased  spiral  elliptical  uncertain  image      pixel_x  \\\n",
      "0          0.000       0           1          0      5  3362.991349   \n",
      "1          0.029       0           1          0      5  3089.338382   \n",
      "2          0.036       0           1          0      5  3028.607250   \n",
      "3          0.000       0           1          0      6  4495.057900   \n",
      "4          0.168       0           1          0      7  1023.284682   \n",
      "\n",
      "       pixel_y  off_image  \n",
      "0   199.840666      False  \n",
      "1  1958.577472      False  \n",
      "2    78.041829      False  \n",
      "3  2315.626917      False  \n",
      "4  4085.577633      False  \n",
      "\n",
      "[5 rows x 51 columns]    Unnamed: 0  index                objid         ra       dec  psfMag_u  \\\n",
      "0           0      1  1237663237128388701  50.130513 -1.228488  22.01211   \n",
      "1           1    123  1237666299481817102  50.160628 -1.035026  19.01124   \n",
      "2           2    140  1237663237128388949  50.167304 -1.241885  22.36878   \n",
      "3           3    458  1237666300018557091  50.006004 -0.495751  21.98376   \n",
      "4           4    110  1237663238739067202  50.387910  0.198944  21.86834   \n",
      "\n",
      "   psfMag_g  psfMag_r  psfMag_i  psfMag_z  ...   p_mg  p_el_debiased  \\\n",
      "0  20.06700  18.86854  18.35853  17.93478  ...  0.032          0.935   \n",
      "1  17.46116  16.85288  16.54355  16.19304  ...  0.000          0.971   \n",
      "2  20.17246  18.94735  18.44240  17.99196  ...  0.000          0.964   \n",
      "3  19.93291  18.73658  18.31895  17.89719  ...  0.000          0.893   \n",
      "4  19.78908  18.63620  18.16101  17.63892  ...  0.018          0.755   \n",
      "\n",
      "   p_cs_debiased  spiral  elliptical  uncertain  image      pixel_x  \\\n",
      "0          0.000       0           1          0      5  3362.991349   \n",
      "1          0.029       0           1          0      5  3089.338382   \n",
      "2          0.036       0           1          0      5  3028.607250   \n",
      "3          0.000       0           1          0      6  4495.057900   \n",
      "4          0.168       0           1          0      7  1023.284682   \n",
      "\n",
      "       pixel_y  off_image  \n",
      "0   199.840666      False  \n",
      "1  1958.577472      False  \n",
      "2    78.041829      False  \n",
      "3  2315.626917      False  \n",
      "4  4085.577633      False  \n",
      "\n",
      "[5 rows x 51 columns]      Unnamed: 0  index                objid          ra       dec  psfMag_u  \\\n",
      "98          101    101  1237663543675126583  312.305638  0.325466  21.65428   \n",
      "99          102    243  1237663543675060734  312.252401  0.351028  21.40535   \n",
      "100         103    257  1237678596459004706  312.353091  0.906897  20.69301   \n",
      "101         104    263  1237678596459070093  312.482143  0.899587  20.42247   \n",
      "102         105      8  1237678617933840840  312.415661  0.836877  21.30678   \n",
      "\n",
      "     psfMag_g  psfMag_r  psfMag_i  psfMag_z  ...   p_mg  p_el_debiased  \\\n",
      "98   19.69963  18.97126  18.80456  17.96306  ...  0.000          0.000   \n",
      "99   19.90150  19.24713  18.85280  18.43742  ...  0.000          0.208   \n",
      "100  19.08198  18.25090  17.88519  17.34971  ...  0.032          0.085   \n",
      "101  18.66539  17.60476  17.15648  16.59696  ...  0.000          0.831   \n",
      "102  19.63800  18.80013  18.37699  17.93728  ...  0.000          0.197   \n",
      "\n",
      "     p_cs_debiased  spiral  elliptical  uncertain  image      pixel_x  \\\n",
      "98           1.000       1           0          0     23  1771.211749   \n",
      "99           0.702       1           0          0     23  2255.173119   \n",
      "100          0.847       1           0          0     24  1339.922468   \n",
      "101          0.169       0           1          0     24   166.872332   \n",
      "102          0.736       1           0          0     24   771.148256   \n",
      "\n",
      "         pixel_y  off_image  \n",
      "98    690.326160      False  \n",
      "99    922.708195      False  \n",
      "100  1430.613342      False  \n",
      "101  1364.156903      False  \n",
      "102   794.066990      False  \n",
      "\n",
      "[5 rows x 51 columns]       Unnamed: 0  index                objid          ra       dec  psfMag_u  \\\n",
      "7870         101    101  1237663543675126583  312.305638  0.325466  21.65428   \n",
      "7871         102    243  1237663543675060734  312.252401  0.351028  21.40535   \n",
      "7872         103    257  1237678596459004706  312.353091  0.906897  20.69301   \n",
      "7873         104    263  1237678596459070093  312.482143  0.899587  20.42247   \n",
      "7874         105      8  1237678617933840840  312.415661  0.836877  21.30678   \n",
      "\n",
      "      psfMag_g  psfMag_r  psfMag_i  psfMag_z  ...   p_mg  p_el_debiased  \\\n",
      "7870  19.69963  18.97126  18.80456  17.96306  ...  0.000          0.000   \n",
      "7871  19.90150  19.24713  18.85280  18.43742  ...  0.000          0.208   \n",
      "7872  19.08198  18.25090  17.88519  17.34971  ...  0.032          0.085   \n",
      "7873  18.66539  17.60476  17.15648  16.59696  ...  0.000          0.831   \n",
      "7874  19.63800  18.80013  18.37699  17.93728  ...  0.000          0.197   \n",
      "\n",
      "      p_cs_debiased  spiral  elliptical  uncertain  image      pixel_x  \\\n",
      "7870          1.000       1           0          0     23  1771.211749   \n",
      "7871          0.702       1           0          0     23  2255.173119   \n",
      "7872          0.847       1           0          0     24  1339.922468   \n",
      "7873          0.169       0           1          0     24   166.872332   \n",
      "7874          0.736       1           0          0     24   771.148256   \n",
      "\n",
      "          pixel_y  off_image  \n",
      "7870   690.326160      False  \n",
      "7871   922.708195      False  \n",
      "7872  1430.613342      False  \n",
      "7873  1364.156903      False  \n",
      "7874   794.066990      False  \n",
      "\n",
      "[5 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19,df20,df21,df22,df23,df24,df25,df26,df27,df28,df29,df30,df31,df32,df33,df34,df35,df36,df37,df38,df39,df40,df41,df42,df43],ignore_index=True)\n",
    "print(df1.head(),df.head(),df43.tail(),df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc59889",
   "metadata": {},
   "source": [
    "Has worked, now looking on classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f6ceb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    5766\n",
      "0    2109\n",
      "Name: spiral, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.spiral.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b063f0c",
   "metadata": {},
   "source": [
    "Somewhat inbalanced, clearly more spirals than ellipctical galaxies.\n",
    " \n",
    "Now adding columns to data frame that also other algorithms can work on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f964449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  index                objid          ra       dec  psfMag_u  \\\n",
      "0              0      1  1237663237128388701   50.130513 -1.228488  22.01211   \n",
      "1              1    123  1237666299481817102   50.160628 -1.035026  19.01124   \n",
      "2              2    140  1237663237128388949   50.167304 -1.241885  22.36878   \n",
      "3              3    458  1237666300018557091   50.006004 -0.495751  21.98376   \n",
      "4              4    110  1237663238739067202   50.387910  0.198944  21.86834   \n",
      "...          ...    ...                  ...         ...       ...       ...   \n",
      "7870         101    101  1237663543675126583  312.305638  0.325466  21.65428   \n",
      "7871         102    243  1237663543675060734  312.252401  0.351028  21.40535   \n",
      "7872         103    257  1237678596459004706  312.353091  0.906897  20.69301   \n",
      "7873         104    263  1237678596459070093  312.482143  0.899587  20.42247   \n",
      "7874         105      8  1237678617933840840  312.415661  0.836877  21.30678   \n",
      "\n",
      "      psfMag_g  psfMag_r  psfMag_i  psfMag_z  ...       1839       1840  \\\n",
      "0     20.06700  18.86854  18.35853  17.93478  ...   1.665458   2.004834   \n",
      "1     17.46116  16.85288  16.54355  16.19304  ...  14.379109  11.666973   \n",
      "2     20.17246  18.94735  18.44240  17.99196  ...   3.076642   2.076246   \n",
      "3     19.93291  18.73658  18.31895  17.89719  ...   1.048036   1.109835   \n",
      "4     19.78908  18.63620  18.16101  17.63892  ...   1.184487   1.598326   \n",
      "...        ...       ...       ...       ...  ...        ...        ...   \n",
      "7870  19.69963  18.97126  18.80456  17.96306  ...   1.498235   0.424008   \n",
      "7871  19.90150  19.24713  18.85280  18.43742  ...  -0.112526   0.754794   \n",
      "7872  19.08198  18.25090  17.88519  17.34971  ...   1.064996   2.310383   \n",
      "7873  18.66539  17.60476  17.15648  16.59696  ...  15.580846  14.845871   \n",
      "7874  19.63800  18.80013  18.37699  17.93728  ...   2.193911   0.450266   \n",
      "\n",
      "           1841       1842       1843       1844       1845       1846  \\\n",
      "0      2.611588   2.424317   2.474362   1.353987   1.583795   1.774545   \n",
      "1      9.821115   7.404263   5.446650   6.966890   5.452247   4.376808   \n",
      "2      2.364242   3.476580   2.535928   3.971950   2.529318   2.240578   \n",
      "3      0.297769   0.963585  -0.165940   2.337755   1.023438   0.092747   \n",
      "4      0.643092   2.063930   2.313514   2.106585   0.594379   1.208244   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "7870   0.148396  -0.603792  -0.306632   0.860112  -0.886799  -1.201787   \n",
      "7871  -1.197206  -0.684041  -0.899295  -0.136781   0.276812  -0.445999   \n",
      "7872   5.388972   6.406399   5.050728   2.659925   1.486004   0.777389   \n",
      "7873  14.791656  14.455644  13.986908  15.077876  15.339103  14.927979   \n",
      "7874   0.585787   0.146496   0.991703   1.078620   0.486006   1.749503   \n",
      "\n",
      "           1847       1848  \n",
      "0      1.050895   1.528546  \n",
      "1      4.169206   3.645003  \n",
      "2      3.083265   2.470761  \n",
      "3      1.560674   0.497436  \n",
      "4      0.624576   1.390411  \n",
      "...         ...        ...  \n",
      "7870  -0.522344  -1.171323  \n",
      "7871  -1.089486   0.132339  \n",
      "7872   0.031772   0.233060  \n",
      "7873  14.142972  13.599141  \n",
      "7874   1.564292   0.986832  \n",
      "\n",
      "[7875 rows x 1900 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n",
      "/tmp/ipykernel_16878/748454094.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x]=cutouts[i,j,0,:]\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "for i in range(cutouts.shape[0]):\n",
    "    for j in range(cutouts.shape[1]):\n",
    "        df[x]=cutouts[i,j,0,:]\n",
    "        x+=1\n",
    "print(df)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8612b4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1848\n"
     ]
    }
   ],
   "source": [
    "print(df.columns[51],df.columns[1899])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e5e60e",
   "metadata": {},
   "source": [
    "Now starting with torch spefifics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64f1c534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "#adding cpu\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fd05437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of image train data\n",
      "(4725, 1, 43, 43)\n",
      "           0          1          2          3          4          5     \\\n",
      "7250  -0.671509  -0.270374   0.568258   0.748187   0.106514   0.491256   \n",
      "2896  14.361377  15.999631  15.021544  14.212921  16.437111  18.469778   \n",
      "3329   1.400726   0.407343   0.848358   1.608956   1.318081   1.688733   \n",
      "6120   1.741505   0.490504   0.683172   1.506649   1.003500   1.217041   \n",
      "2842   1.038349   0.094624   1.703698   1.768898   0.666397   2.107406   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "7565  -0.421559   0.220490  -0.020975  -0.416924  -0.335829   1.411871   \n",
      "551    7.063395   7.432566   7.274216   7.202036   6.730490   6.429748   \n",
      "6019   1.913022   1.897351   3.837757   3.496063   2.804465   3.033000   \n",
      "1625   0.714121   0.846052   0.592803   1.055074   0.230322   0.947309   \n",
      "3707  24.069626  27.446905  30.535490  31.509089  31.743973  33.973873   \n",
      "\n",
      "           6          7          8          9     ...       1839       1840  \\\n",
      "7250   0.721377   0.457447   1.182653   0.508963  ...  -1.577943  -0.518812   \n",
      "2896  18.741051  19.557499  20.969507  21.206383  ...  18.329796  16.931213   \n",
      "3329   1.632744   0.583832   2.083723   2.367725  ...   2.788263   1.599384   \n",
      "6120   0.262579  -0.528686   0.752107   0.743199  ...   0.351606  -0.262267   \n",
      "2842   1.790547   2.975658   3.519551   1.004310  ...   3.117839   2.139396   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "7565   0.710307  -0.079770  -1.105981   1.194982  ...  -0.709208   1.041943   \n",
      "551    7.532240   7.924043   7.011593   8.516788  ...   7.156546   6.404053   \n",
      "6019   2.927271   3.620798   4.397440   5.402022  ...   3.581941   2.620989   \n",
      "1625   2.250208   1.845876   3.502650   3.127428  ...  -0.083031  -0.280773   \n",
      "3707  33.594883  35.356945  35.820324  38.069271  ...  31.367376  31.518557   \n",
      "\n",
      "           1841       1842       1843       1844       1845       1846  \\\n",
      "7250  -0.476839  -0.607239  -1.508053   0.210654   0.545668  -0.939328   \n",
      "2896  14.921959  15.412244  15.222718  15.577325  14.229346  14.316903   \n",
      "3329  -0.512176   0.744309  -0.367825  -0.101750   0.649983  -0.004788   \n",
      "6120  -0.968831  -0.303305  -0.324049   0.778398  -0.042321   0.170513   \n",
      "2842   2.439812   3.101371   1.904284   2.649488   1.679398   2.353404   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "7565   0.189462  -0.473620  -0.972846   1.355782  -1.032166  -0.446082   \n",
      "551    6.587650   7.487498   7.264557   5.892326   6.075177   7.390130   \n",
      "6019   2.026137   1.863325   1.781396   1.507837   0.304501  -0.542711   \n",
      "1625  -0.224805   0.107111   0.218300  -0.287577  -0.504434  -0.170517   \n",
      "3707  30.665033  30.909317  29.263224  28.609945  26.199959  24.254389   \n",
      "\n",
      "           1847       1848  \n",
      "7250  -0.158685   0.311610  \n",
      "2896  13.863968  12.857979  \n",
      "3329   1.329447   1.522497  \n",
      "6120   0.149658   0.245534  \n",
      "2842   1.812754   2.619191  \n",
      "...         ...        ...  \n",
      "7565   0.606116  -0.936563  \n",
      "551    5.342247   4.146053  \n",
      "6019  -0.204807   0.032090  \n",
      "1625  -0.016987  -0.458997  \n",
      "3707  19.634184  16.805170  \n",
      "\n",
      "[3150 rows x 1849 columns]\n"
     ]
    }
   ],
   "source": [
    "feature_train, feature_test, target_train, target_test,image_train,image_test,df_train,df_test= train_test_split(df.iloc[:,51:1900],df.loc[:,\"spiral\"],cutouts.T,df,train_size=0.60, shuffle=True, random_state=1)\n",
    "print(\"shape of image train data\")\n",
    "print(image_train.shape)\n",
    "print(feature_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dce715",
   "metadata": {},
   "source": [
    "Now creating multiple entries for each by mirroring and rotations. First make image of the first without. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11ccb109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4725, 1, 43, 43)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3fc80dafd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(image_train.shape)\n",
    "plt.axis('off')\n",
    "plt.title(\"Galaxy normal\")\n",
    "plt.imshow(abs(image_train[2,0,:,:])**0.5,cmap=cm.gray, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25082f9",
   "metadata": {},
   "source": [
    "Thus getting all 7 other apparences means 3 rotations on original and flip on original 3 rotations on it. That are in total 8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b373c5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rot_mirror_square(dat):\n",
    "    if dat.shape[0]!=dat.shape[1]:\n",
    "        print(\"Data is not a square\")\n",
    "    else:\n",
    "        res=np.zeros((8,dat.shape[0],dat.shape[1]))\n",
    "        res[0,:,:]=dat\n",
    "        res[4,:,:]=np.flip(dat,0)\n",
    "        for i in range(3):\n",
    "            res[1+i,:,:]=np.rot90(dat,k=i+1,axes=(0,1))\n",
    "            res[5+i,:,:]=np.rot90(res[4,:,:],k=i+1,axes=(0,1))\n",
    "        return res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7c28725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3fc80aa490>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_rots=get_rot_mirror_square(image_train[2,0,:,:])\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title(\"Galaxy rotated\")\n",
    "plt.imshow(abs(all_rots[1,:,:])**0.5,cmap=cm.gray, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d58b5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3fc8086280>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.axis('off')\n",
    "plt.title(\"Galaxy mirrored\")\n",
    "plt.imshow(abs(all_rots[4,:,:])**0.5,cmap=cm.gray, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f564a2",
   "metadata": {},
   "source": [
    "All work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c110c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_torch(model,data):\n",
    "    y_pred_list_c = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X_batch, _ in data:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_pred_list_c.append(y_test_pred.cpu().numpy())\n",
    "    y_pred_list_c = [a.squeeze().tolist() for a in y_pred_list_c]\n",
    "    return y_pred_list_c  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce2603da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfafe815",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train, target_test = np.array(target_train), np.array(target_test)\n",
    "feature_train, feature_test = np.array(feature_train), np.array(feature_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b6cd967",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b64b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_im_dataset = ClassificationDataset(torch.from_numpy(image_train).float(), torch.from_numpy(target_train).float())\n",
    "test_im_dataset = ClassificationDataset(torch.from_numpy(image_test).float(), torch.from_numpy(target_test).float())\n",
    "train_dataset = ClassificationDataset(torch.from_numpy(feature_train).float(), torch.from_numpy(target_train).float())\n",
    "test_dataset = ClassificationDataset(torch.from_numpy(feature_test).float(), torch.from_numpy(target_test).float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48612e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_im_loader = DataLoader(dataset=train_im_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_im_loader = DataLoader(dataset=test_im_dataset, batch_size=1)\n",
    "train_im_loader_pred = DataLoader(dataset=train_im_dataset, batch_size=1)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1)\n",
    "train_loader_pred = DataLoader(dataset=train_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e4332",
   "metadata": {},
   "source": [
    "Perceptron network. 4 layers tried. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "625c68f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now 4 layers \n",
    "#two output options only \n",
    "class BinaryClassification4(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(BinaryClassification4, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_features, 300)\n",
    "        self.fc2 = nn.Linear(300, 100)  \n",
    "        self.fc3 = nn.Linear(100, 30)        \n",
    "        self.fc4 = nn.Linear(30, 10)   \n",
    "        self.fc5 = nn.Linear(10, 1)          \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))        \n",
    "        x = torch.sigmoid(self.fc5(x))\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4006648f",
   "metadata": {},
   "source": [
    "Now trying smaller networks, likely the data is too noisy and not large enough that the standard amount works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0168565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_FEATURES = 1849"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "935aed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the function to fit it\n",
    "#parameters: model used, train_data, test_data, epchs, batch_size, learning_rate, file to collect stats, \n",
    "#optional regularization \n",
    "def torch_fit(model,train_loader,test_loader,epochs,batch_size,learning_rate,loss_stats,l2reg=0,silent=False):\n",
    "    learning_rate = learning_rate\n",
    "    criterion = torch.nn.BCELoss()    # Softmax is internally computed.\n",
    "    #if no regularization\n",
    "    if l2reg==0:\n",
    "        optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    #l2 regularization is added in optimizer as weight_decay=1e-5 or nsimilar \n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate,weight_decay=l2reg)  \n",
    "    if silent==False:    \n",
    "        print(\"Begin training.\")\n",
    "    for e in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "        # TRAINING\n",
    "        train_epoch_loss = 0\n",
    "        model.train()\n",
    "        for X_train_batch, y_train_batch in train_loader:\n",
    "            X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            y_train_pred = model(X_train_batch)\n",
    "        \n",
    "            train_loss = criterion(y_train_pred, y_train_batch.unsqueeze(1))\n",
    "        \n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            train_epoch_loss += train_loss.item()\n",
    "        \n",
    "        \n",
    "        # VALIDATION    \n",
    "        with torch.no_grad():\n",
    "        \n",
    "            test_epoch_loss = 0\n",
    "        \n",
    "            model.eval()\n",
    "            for X_test_batch, y_test_batch in test_loader:\n",
    "                X_test_batch, y_test_batch = X_test_batch.to(device), y_test_batch.to(device)\n",
    "            \n",
    "                y_test_pred = model(X_test_batch)\n",
    "                        \n",
    "                test_loss = criterion(y_test_pred, y_test_batch.unsqueeze(1))\n",
    "            \n",
    "                test_epoch_loss += test_loss.item()\n",
    "        loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "        loss_stats['test'].append(test_epoch_loss/len(test_loader))                              \n",
    "        if silent==False:\n",
    "            print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Test Loss: {test_epoch_loss/len(test_loader):.5f}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "324faedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_for_torch(predict,target):\n",
    "    #round prediction\n",
    "    round_pred=np.round(np.array(predict))\n",
    "    conf_matrix = confusion_matrix(target, round_pred)\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ebb31d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 layer perceptron\n",
      "train\n",
      "[[ 697    0]\n",
      " [1989    0]]\n",
      "test\n",
      "[[ 521    0]\n",
      " [1271    0]]\n"
     ]
    }
   ],
   "source": [
    "# 2 116 12 | 116 182 test 71 71 | 76 130 \n",
    "# 4  46 82 | 21 277 test  30 48 | 18 188\n",
    "# seems to restart at each trail \n",
    "conf_test_m=conf_for_torch(m_test,target_test)\n",
    "conf_train_m=conf_for_torch(m_train,target_train)\n",
    "print(\"4 layer perceptron\")\n",
    "print(\"train\")\n",
    "print(conf_train_m)\n",
    "print(\"test\")\n",
    "print(conf_test_m)\n",
    "#some have 124 4 18 280 in train, test: 70 8 32 174\n",
    "#now 16 samples, 40 epochs, train  256 38 81 711 \n",
    "#now with 200 got into one sided train 0 454 0 1175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3d37772e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'BCE loss')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_stats_m['test'],label='m test')\n",
    "plt.plot(loss_stats_m['train'],label='m train')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('BCE loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e2328a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7af83e07",
   "metadata": {},
   "source": [
    "Now I other other method for classification, first XGBoost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a336db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "xc1=XGBClassifier(max_depth=6).fit(feature_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "225a9e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix xgboost train\n",
      "[[1238    1]\n",
      " [   0 3486]]\n",
      "confusion matrix xgboost test\n",
      "[[ 753  117]\n",
      " [ 116 2164]]\n"
     ]
    }
   ],
   "source": [
    "train_pred=xc1.predict(feature_train)\n",
    "test_pred=xc1.predict(feature_test)\n",
    "train_pred_prob=xc1.predict_proba(feature_train)\n",
    "test_pred_prob=xc1.predict_proba(feature_test)\n",
    "conf_train = confusion_matrix(target_train, train_pred)\n",
    "conf_test = confusion_matrix(target_test, test_pred)\n",
    "print(\"confusion matrix xgboost train\")\n",
    "print(conf_train)\n",
    "print(\"confusion matrix xgboost test\")\n",
    "print(conf_test)\n",
    "#16 test was 247 47 \\ 55 737\n",
    "#24 test was 440 61  \\ 81 1210\n",
    "#43 test it 753 117 / 116 2164"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb7c638",
   "metadata": {},
   "source": [
    "Xgboost works approximately with standard settings. Likely it can be improved because the train set is perfectly classified and thus thus clearly overfit. \n",
    "\n",
    "Now I try logistic. I really high number of iterations is needed, scaling features would help, but then regularization is more more random. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "702d01ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobias/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lc1=LogisticRegression(max_iter=6000,penalty='none').fit(feature_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cceafa4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix logistic regression train\n",
      "[[1205   34]\n",
      " [  20 3466]]\n",
      "confusion matrix logistic regression test\n",
      "[[ 478  392]\n",
      " [ 540 1740]]\n"
     ]
    }
   ],
   "source": [
    "l_train_pred=lc1.predict(feature_train)\n",
    "l_test_pred=lc1.predict(feature_test)\n",
    "l_train_pred_prob=lc1.predict_proba(feature_train)\n",
    "l_test_pred_prob=lc1.predict_proba(feature_test)\n",
    "l_conf_train = confusion_matrix(target_train, l_train_pred)\n",
    "l_conf_test = confusion_matrix(target_test, l_test_pred)\n",
    "print(\"confusion matrix logistic regression train\")\n",
    "print(l_conf_train)\n",
    "print(\"confusion matrix logistic regression test\")\n",
    "print(l_conf_test)\n",
    "#16 test  169 125 \\ 245 547\n",
    "#24 test  276 245 \\ 349 922 gets worse in the minor class,better in the main \n",
    "#43 test  478 392\\ 540 11740 now again getting better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a045c7c",
   "metadata": {},
   "source": [
    "Logistic works less good as xgboost and does not improve clearlz with more data. Means that wrong features are fit then. Both should improve with regularization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35b93d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_xgboost(feature_train,target_train,feature_test,target_test,regs):\n",
    "    stats=np.zeros((5,len(regs)))\n",
    "    for i in range(len(regs)):\n",
    "        print(f\"doing l2 regularization {regs[i]}\")\n",
    "        xc1=XGBClassifier(max_depth=6,reg_lambda=regs[i]).fit(feature_train,target_train)\n",
    "        train_pred=xc1.predict(feature_train)\n",
    "        test_pred=xc1.predict(feature_test)\n",
    "        train_pred_prob=xc1.predict_proba(feature_train)\n",
    "        test_pred_prob=xc1.predict_proba(feature_test)\n",
    "        stats[0,i]=regs[i]\n",
    "        stats[1,i]=f1_score(target_train,train_pred)\n",
    "        stats[2,i]=f1_score(target_test,test_pred)       \n",
    "        stats[3,i]=log_loss(target_train,train_pred_prob)\n",
    "        stats[4,i]=log_loss(target_test,test_pred_prob)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b35e056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing l2 regularization 0.0001\n",
      "doing l2 regularization 0.0003\n",
      "doing l2 regularization 0.001\n",
      "doing l2 regularization 0.003\n",
      "doing l2 regularization 0.01\n",
      "doing l2 regularization 0.03\n",
      "doing l2 regularization 0.1\n",
      "doing l2 regularization 0.3\n",
      "doing l2 regularization 1\n",
      "doing l2 regularization 3\n",
      "doing l2 regularization 10\n",
      "doing l2 regularization 30\n",
      "doing l2 regularization 100\n",
      "doing l2 regularization 300\n",
      "doing l2 regularization 1000\n",
      "doing l2 regularization 3000\n",
      "doing l2 regularization 10000\n",
      "[[1.00000000e-04 1.00000000e+00 9.49353212e-01 2.56598174e-03\n",
      "  2.24211778e-01]\n",
      " [3.00000000e-04 1.00000000e+00 9.51422319e-01 2.45484942e-03\n",
      "  2.22394796e-01]\n",
      " [1.00000000e-03 9.99856590e-01 9.48381452e-01 2.58556133e-03\n",
      "  2.22074409e-01]\n",
      " [3.00000000e-03 1.00000000e+00 9.49901553e-01 2.57140657e-03\n",
      "  2.22985242e-01]\n",
      " [1.00000000e-02 1.00000000e+00 9.49725576e-01 2.52495030e-03\n",
      "  2.17790500e-01]\n",
      " [3.00000000e-02 9.99856590e-01 9.52234882e-01 2.57514407e-03\n",
      "  2.19505732e-01]\n",
      " [1.00000000e-01 9.99856590e-01 9.51417894e-01 2.68191363e-03\n",
      "  2.21986009e-01]\n",
      " [3.00000000e-01 9.99856590e-01 9.50935094e-01 3.09851164e-03\n",
      "  2.16000639e-01]\n",
      " [1.00000000e+00 9.99856590e-01 9.48914712e-01 3.74754680e-03\n",
      "  2.15246018e-01]\n",
      " [3.00000000e+00 9.99856590e-01 9.50690335e-01 5.87187916e-03\n",
      "  2.01520527e-01]\n",
      " [1.00000000e+01 9.99856590e-01 9.50317356e-01 9.78315717e-03\n",
      "  1.91775035e-01]\n",
      " [3.00000000e+01 9.99856590e-01 9.47805198e-01 1.96523603e-02\n",
      "  1.89096626e-01]\n",
      " [1.00000000e+02 9.97561325e-01 9.45993031e-01 4.98775423e-02\n",
      "  1.93514284e-01]\n",
      " [3.00000000e+02 9.86502010e-01 9.42408377e-01 9.94558293e-02\n",
      "  2.09431240e-01]\n",
      " [1.00000000e+03 9.74300400e-01 9.34111039e-01 1.77208303e-01\n",
      "  2.55620690e-01]\n",
      " [3.00000000e+03 9.44183476e-01 9.12609238e-01 2.98342450e-01\n",
      "  3.50672957e-01]\n",
      " [1.00000000e+04 8.82126348e-01 8.63088292e-01 4.58170799e-01\n",
      "  4.84208569e-01]]\n"
     ]
    }
   ],
   "source": [
    "regs=[0.0001,0.0003,0.001,0.003,0.01,0.03,0.1,0.3,1,3,10,30,100,300,1000,3000,10000]\n",
    "stats_xgb=loop_xgboost(feature_train,target_train,feature_test,target_test,regs)\n",
    "print(stats_xgb.T)\n",
    "np.savetxt(\"xgb_43sets_gal-type_v1.txt\",stats_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75f40e",
   "metadata": {},
   "source": [
    "Is now rather slow with the full data set. \n",
    "\n",
    "Now defining function to do the regularization loop for logistic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91f9333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_logistic(feature_train,target_train,feature_test,target_test,regs):\n",
    "    stats=np.zeros((5,len(regs)))\n",
    "    for i in range(len(regs)):\n",
    "        print(f\"doing l2 regularization {regs[i]}\") #does not always converge but are cases which are certainly not useful ones\n",
    "        xc1=LogisticRegression(max_iter=10000,penalty='l2',C=regs[i]).fit(feature_train,target_train)\n",
    "        train_pred=xc1.predict(feature_train)\n",
    "        test_pred=xc1.predict(feature_test)\n",
    "        train_pred_prob=xc1.predict_proba(feature_train)\n",
    "        test_pred_prob=xc1.predict_proba(feature_test)\n",
    "        stats[0,i]=regs[i]\n",
    "        stats[1,i]=f1_score(target_train,train_pred)\n",
    "        stats[2,i]=f1_score(target_test,test_pred)       \n",
    "        stats[3,i]=log_loss(target_train,train_pred_prob)\n",
    "        stats[4,i]=log_loss(target_test,test_pred_prob)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9940ab0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-10, 3e-09, 1e-08, 3e-08, 1e-07, 3e-07, 1e-06, 3e-06, 1e-05, 3e-05, 0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100]\n",
      "doing l2 regularization 1e-10\n",
      "doing l2 regularization 3e-09\n",
      "doing l2 regularization 1e-08\n",
      "doing l2 regularization 3e-08\n",
      "doing l2 regularization 1e-07\n",
      "doing l2 regularization 3e-07\n",
      "doing l2 regularization 1e-06\n",
      "doing l2 regularization 3e-06\n",
      "doing l2 regularization 1e-05\n",
      "doing l2 regularization 3e-05\n",
      "doing l2 regularization 0.0001\n",
      "doing l2 regularization 0.0003\n",
      "doing l2 regularization 0.001\n",
      "doing l2 regularization 0.003\n",
      "doing l2 regularization 0.01\n",
      "doing l2 regularization 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobias/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing l2 regularization 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobias/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing l2 regularization 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobias/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing l2 regularization 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobias/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing l2 regularization 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobias/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing l2 regularization 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobias/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing l2 regularization 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobias/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing l2 regularization 100\n",
      "[[0.00000e+00 8.49290e-01 8.43020e-01 5.53090e-01 5.62540e-01]\n",
      " [0.00000e+00 8.66870e-01 8.60600e-01 4.75930e-01 4.89510e-01]\n",
      " [0.00000e+00 8.69120e-01 8.61830e-01 4.45890e-01 4.66340e-01]\n",
      " [0.00000e+00 8.67910e-01 8.57430e-01 4.29210e-01 4.56010e-01]\n",
      " [0.00000e+00 8.65360e-01 8.52830e-01 4.19210e-01 4.51130e-01]\n",
      " [0.00000e+00 8.66680e-01 8.53500e-01 4.13000e-01 4.49790e-01]\n",
      " [0.00000e+00 8.67930e-01 8.49400e-01 4.07050e-01 4.53330e-01]\n",
      " [0.00000e+00 8.70310e-01 8.46850e-01 4.00760e-01 4.63900e-01]\n",
      " [1.00000e-05 8.71310e-01 8.44620e-01 3.91520e-01 4.92460e-01]\n",
      " [3.00000e-05 8.76320e-01 8.45540e-01 3.80150e-01 5.30800e-01]\n",
      " [1.00000e-04 8.85370e-01 8.42300e-01 3.62930e-01 5.76390e-01]\n",
      " [3.00000e-04 8.94820e-01 8.44190e-01 3.39190e-01 6.03090e-01]\n",
      " [1.00000e-03 9.11470e-01 8.41570e-01 2.98990e-01 6.63140e-01]\n",
      " [3.00000e-03 9.32760e-01 8.39780e-01 2.51760e-01 7.81500e-01]\n",
      " [1.00000e-02 9.54470e-01 8.28860e-01 1.97970e-01 9.58160e-01]\n",
      " [3.00000e-02 9.67910e-01 8.12800e-01 1.52230e-01 1.22572e+00]\n",
      " [1.00000e-01 9.81910e-01 8.00090e-01 1.08290e-01 1.71292e+00]\n",
      " [3.00000e-01 9.90860e-01 7.93250e-01 7.82400e-02 2.30105e+00]\n",
      " [1.00000e+00 9.98280e-01 7.88330e-01 5.28000e-02 3.07441e+00]\n",
      " [3.00000e+00 9.96710e-01 7.86070e-01 5.24600e-02 3.18763e+00]\n",
      " [1.00000e+01 9.99430e-01 7.84240e-01 3.35400e-02 4.21063e+00]\n",
      " [3.00000e+01 9.97560e-01 7.85990e-01 5.02700e-02 3.43623e+00]\n",
      " [1.00000e+02 9.93420e-01 7.90160e-01 7.24700e-02 2.56775e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobias/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "regs=[0.0000000001,0.000000003,0.00000001,0.00000003,0.0000001,0.0000003,0.000001,0.000003,0.00001,0.00003,0.0001,0.0003,0.001,0.003,0.01,0.03,0.1,0.3,1,3,10,30,100]\n",
    "print(regs)\n",
    "stats_log=loop_logistic(feature_train,target_train,feature_test,target_test,regs)\n",
    "print(np.round(stats_log.T,5))\n",
    "np.savetxt(\"log_43sets_gal-type_v1.txt\",stats_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7b4e60",
   "metadata": {},
   "source": [
    "Now plotting both, first f1 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "560924e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats_xgb=np.loadtxt(\"xgb_43sets_gal-type_v1.txt\")\n",
    "stats_log=np.loadtxt(\"log_43sets_gal-type_v1.txt\")\n",
    "plt.plot(stats_xgb[0],stats_xgb[1],label='xgboost train')\n",
    "plt.plot(stats_xgb[0],stats_xgb[2],label='xgboost test')\n",
    "plt.plot(stats_log[0],stats_log[1],label='logistic train')\n",
    "plt.plot(stats_log[0],stats_log[2],label='logistic test')\n",
    "plt.legend(loc=\"best\")\n",
    "#plt.title('Loss vs Epochs')\n",
    "plt.xlabel('l2 regularization')\n",
    "plt.ylabel('F1 score')\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ff312b",
   "metadata": {},
   "source": [
    "Then log loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fcef0ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stats_xgb[0],stats_xgb[3],label='xgboost train')\n",
    "plt.plot(stats_xgb[0],stats_xgb[4],label='xgboost test')\n",
    "plt.plot(stats_log[0],stats_log[3],label='logistic train')\n",
    "plt.plot(stats_log[0],stats_log[4],label='logistic test')\n",
    "plt.legend(loc=\"best\")\n",
    "#plt.title('Loss vs Epochs')\n",
    "plt.xlabel('l2 regularization')\n",
    "plt.ylabel('log loss')\n",
    "#plt.ylim(0,0.7)\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dd85f2",
   "metadata": {},
   "source": [
    "Probably none convergence cuases change at high high l, but not relevant for sure not best model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a2c175",
   "metadata": {},
   "source": [
    "Xgboost is clearly better. It is in the not so much data limit where adding regularziation is not clearly improving test at F1 score. Below I zoom into log loss to see whether there is a minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db912e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stats_xgb[0],stats_xgb[3],label='xgboost train')\n",
    "plt.plot(stats_xgb[0],stats_xgb[4],label='xgboost test')\n",
    "plt.plot(stats_log[0],stats_log[3],label='logistic train')\n",
    "plt.plot(stats_log[0],stats_log[4],label='logistic test')\n",
    "plt.legend(loc=\"best\")\n",
    "#plt.title('Loss vs Epochs')\n",
    "plt.xlabel('l2 regularization')\n",
    "plt.ylabel('log loss')\n",
    "plt.ylim(0,0.7)\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a778e64",
   "metadata": {},
   "source": [
    "There is one now at not extactly the same position as the local maximum in the F1 score. For linear there is also a minimum now visible, a clearly worse, but still better than a constant probability, similar as to xgboost the local shifts compared to the local maximum in the F1 score.  That shifting is bot ideal, I should likely add rotations mirrorring versions for fitting in any case but is unlikely to solve the main torch problem since it only incrtease the data amount by a factor 8 even if there is no more fundamental problem in torch, which is not clear. Still similar with 24 data sets, it only looks slowly better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd54b66",
   "metadata": {},
   "source": [
    "Test input outputs relations for convolutional network of 3 convolutional layers, it is still 3 *3 convolutional and 2 *2 maximuma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd3e904e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first conv layer input: torch.Size([1, 1, 43, 43]) output: torch.Size([1, 16, 41, 41])\n",
      "max pool input:torch.Size([1, 16, 41, 41]) output:torch.Size([1, 16, 20, 20])\n",
      "second conv layer input: torch.Size([1, 16, 20, 20]) output: torch.Size([1, 32, 18, 18])\n",
      "second max pool layer input: torch.Size([1, 32, 18, 18]) output: torch.Size([1, 32, 9, 9])\n",
      "third conv layer input: torch.Size([1, 32, 9, 9]) output: torch.Size([1, 64, 7, 7])\n",
      "third max pool layer input: torch.Size([1, 64, 7, 7]) output: torch.Size([1, 64, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "input0 = torch.randn(1, 1, 43, 43)\n",
    "b=torch.nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=0)\n",
    "output0=b(input0)\n",
    "print(f\"first conv layer input: {input0.shape} output: {output0.shape}\")\n",
    "\n",
    "m = nn.MaxPool2d((2, 2), stride=(2, 2))\n",
    "#standard drops but can be changed, can also use pooling and co get better number \n",
    "output1 = m(output0)\n",
    "print(f\"max pool input:{output0.shape} output:{output1.shape}\")\n",
    "#input format (Batch, Number Channels, height, width)\n",
    "b2=torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "output2=b2(output1)\n",
    "print(f\"second conv layer input: {output1.shape} output: {output2.shape}\")\n",
    "output3 = m(output2)\n",
    "print(f\"second max pool layer input: {output2.shape} output: {output3.shape}\")\n",
    "\n",
    "b3=torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "output4=b3(output3)\n",
    "print(f\"third conv layer input: {output3.shape} output: {output4.shape}\")\n",
    "output5 = m(output4)\n",
    "print(f\"third max pool layer input: {output4.shape} output: {output5.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6af116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBinary4(torch.nn.Module):\n",
    "    #no padding because image does not really end when the data ends. \n",
    "    def __init__(self):\n",
    "        super(CNNBinary4, self).__init__()\n",
    "        # L1 ImgIn shape=(?, 43, 43, 1)\n",
    "        # Conv -> (?, 41, 41, 16)\n",
    "        # Pool -> (?, 20, 20, 16)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=0),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "        # L2 ImgIn shape=(?, 20, 20, 16)\n",
    "        # Conv      ->(?, 18, 18, 32)\n",
    "        # Pool      ->(?, 9, 9, 32)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=0),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "        # L3 ImgIn shape=(?, 9, 9, 32)\n",
    "        # Conv      ->(?, 7, 7, 64)\n",
    "        # Pool      ->(?, 3, 3, 64)\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))        \n",
    "        # L3 FC 3x3x64 inputs -> 128 outputs\n",
    "        self.fc1 = torch.nn.Linear(3 * 3 * 64, 128, bias=True)\n",
    "        torch.nn.init.xavier_uniform(self.fc1.weight) #old\n",
    "        #nn.init.xavier_uniform_.torch.nn.init.xavier_uniform(self.fc1.weight)\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            self.fc1,\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "        # L4 Final FC 128 inputs -> 1 output\n",
    "        self.fc2 = torch.nn.Linear(128, 1, bias=True) #\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight) # initialize parameters\n",
    "        #nn.init.xavier_uniform_.torch.nn.init.xavier_uniform(self.fc1.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out) #dont forget to add/omit layer here\n",
    "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
    "        out = self.fc1(out)\n",
    "        out = torch.sigmoid(self.fc2(out))       \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9fae1514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 43, 1, 613) (43, 43, 1, 795) (43, 43, 1, 831) (43, 43, 1, 621)\n"
     ]
    }
   ],
   "source": [
    "#that are stars could be added as class, but likely only in other notebook \n",
    "cutouts_s1=np.load(\"stripe82_1_stars_im.npy\")\n",
    "cutouts_s2=np.load(\"stripe82_2_stars_im.npy\")\n",
    "cutouts_s3=np.load(\"stripe82_3_stars_im.npy\")\n",
    "cutouts_s4=np.load(\"stripe82_4_stars_im.npy\")\n",
    "print(cutouts_s1.shape,cutouts_s2.shape,cutouts_s3.shape,cutouts_s4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e724ba1",
   "metadata": {},
   "source": [
    "Now same set up new network and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "358a5969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNBinary4(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=576, out_features=128, bias=True)\n",
      "  (layer4): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7354/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7c6235a2fc436a8d2644193c2f99f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 25.78817 | Test Loss: 29.07366\n",
      "Epoch 002: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 003: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 004: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 005: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 006: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 007: | Train Loss: 25.95734 | Test Loss: 29.07366\n",
      "Epoch 008: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 009: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 010: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 011: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 012: | Train Loss: 25.95734 | Test Loss: 29.07366\n",
      "Epoch 013: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 014: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 015: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 016: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 017: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 018: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 019: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 020: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 021: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 022: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 023: | Train Loss: 25.96230 | Test Loss: 29.07366\n",
      "Epoch 024: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 025: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 026: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 027: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 028: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 029: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 030: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 031: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 032: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 033: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 034: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 035: | Train Loss: 25.93502 | Test Loss: 29.07366\n",
      "Epoch 036: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 037: | Train Loss: 25.93502 | Test Loss: 29.07366\n",
      "Epoch 038: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 039: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 040: | Train Loss: 25.95238 | Test Loss: 29.07366\n"
     ]
    }
   ],
   "source": [
    "keep_prob=1\n",
    "model2c =CNNBinary4()\n",
    "model2c.to(device)\n",
    "print(model2c)\n",
    "loss_stats_st11c = {\n",
    "    'train': [], 'test': []\n",
    "}\n",
    "torch_fit(model2c,train_im_loader,test_im_loader,40,32,0.001,loss_stats_st11c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97858c9",
   "metadata": {},
   "source": [
    "Does not work in 1,2, 3,4 5,trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b512e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop on regularization \n",
    "#model used, train set, test set, train set for predict, train_target, test_target\n",
    "#epochs, batch?size, alpha of fit, list of regularization, optional number of features needed for perceptron \n",
    "def run_loop_torch(model,train,test,train_for_pred,train_target,test_target,epochs,batch,alpha,regs,num_features=0):\n",
    "    stats=np.zeros((5,len(regs)))\n",
    "    for i in range(len(regs)):\n",
    "        print(f\"running reg of {regs[i]}\")\n",
    "        keep_prob=1\n",
    "        if num_features==0:\n",
    "            model3 =model()\n",
    "        else:\n",
    "            #num_features partlz needed\n",
    "            model3 =model(num_features)            \n",
    "        model3.to(device)\n",
    "        loss_stats_test3 = {\n",
    "        'train': [], 'test': []\n",
    "        }\n",
    "        torch_fit(model3,train,test,epochs,batch,alpha,loss_stats_test3,l2reg=regs[i])\n",
    "        test_pred=pred_torch(model3,test)\n",
    "        train_pred=pred_torch(model3,train_for_pred)\n",
    "        stats[0,i]=regs[i]\n",
    "        stats[1,i]=f1_score(train_target,np.round(train_pred))\n",
    "        stats[2,i]=f1_score(test_target,np.round(test_pred))\n",
    "        stats[3,i]=log_loss(train_target,(train_pred))\n",
    "        stats[4,i]=log_loss(test_target,(test_pred))   \n",
    "        print(f\"stats of l2reg of  {regs[i]} are {np.round(stats[1:5,i],5)}\")\n",
    "    print(f\"full stats are {np.round(stats[:,:].T,5)}\")\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cf156b",
   "metadata": {},
   "source": [
    "Now loop with different regularizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "03d62648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running reg of 0.0001\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7354/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddad7d6af9ac4c80a18089ee7bf2ca5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 72.72895 | Test Loss: 70.89854\n",
      "Epoch 002: | Train Loss: 74.05754 | Test Loss: 70.89962\n",
      "Epoch 003: | Train Loss: 74.05754 | Test Loss: 70.90014\n",
      "Epoch 004: | Train Loss: 74.04762 | Test Loss: 70.90043\n",
      "Epoch 005: | Train Loss: 74.05506 | Test Loss: 70.90062\n",
      "Epoch 006: | Train Loss: 74.05506 | Test Loss: 70.90075\n",
      "Epoch 007: | Train Loss: 74.05010 | Test Loss: 70.90080\n",
      "Epoch 008: | Train Loss: 74.05010 | Test Loss: 70.90079\n",
      "Epoch 009: | Train Loss: 74.05258 | Test Loss: 70.90072\n",
      "Epoch 010: | Train Loss: 74.05506 | Test Loss: 70.90062\n",
      "Epoch 011: | Train Loss: 74.04266 | Test Loss: 70.90048\n",
      "Epoch 012: | Train Loss: 74.05010 | Test Loss: 70.90031\n",
      "Epoch 013: | Train Loss: 74.06002 | Test Loss: 70.90011\n",
      "Epoch 014: | Train Loss: 74.04266 | Test Loss: 70.89989\n",
      "Epoch 015: | Train Loss: 74.06002 | Test Loss: 70.89963\n",
      "Epoch 016: | Train Loss: 74.05754 | Test Loss: 70.89934\n",
      "Epoch 017: | Train Loss: 74.05258 | Test Loss: 70.89902\n",
      "Epoch 018: | Train Loss: 74.05506 | Test Loss: 70.89866\n",
      "Epoch 019: | Train Loss: 74.05010 | Test Loss: 70.89826\n",
      "Epoch 020: | Train Loss: 74.05258 | Test Loss: 70.89784\n",
      "Epoch 021: | Train Loss: 74.05010 | Test Loss: 70.89737\n",
      "Epoch 022: | Train Loss: 74.05258 | Test Loss: 70.89686\n",
      "Epoch 023: | Train Loss: 74.04762 | Test Loss: 70.89632\n",
      "Epoch 024: | Train Loss: 74.05754 | Test Loss: 70.89573\n",
      "Epoch 025: | Train Loss: 74.04266 | Test Loss: 70.88860\n",
      "Epoch 026: | Train Loss: 74.04514 | Test Loss: 70.88767\n",
      "Epoch 027: | Train Loss: 74.05506 | Test Loss: 70.88668\n",
      "Epoch 028: | Train Loss: 74.05754 | Test Loss: 70.88564\n",
      "Epoch 029: | Train Loss: 74.05258 | Test Loss: 70.88454\n",
      "Epoch 030: | Train Loss: 74.05258 | Test Loss: 70.87682\n",
      "Epoch 031: | Train Loss: 74.05258 | Test Loss: 70.87528\n",
      "Epoch 032: | Train Loss: 74.05754 | Test Loss: 70.87366\n",
      "Epoch 033: | Train Loss: 74.05010 | Test Loss: 70.87198\n",
      "Epoch 034: | Train Loss: 74.05506 | Test Loss: 70.87021\n",
      "Epoch 035: | Train Loss: 74.04266 | Test Loss: 70.86838\n",
      "Epoch 036: | Train Loss: 74.05258 | Test Loss: 70.86648\n",
      "Epoch 037: | Train Loss: 74.04762 | Test Loss: 70.86450\n",
      "Epoch 038: | Train Loss: 74.06002 | Test Loss: 70.86245\n",
      "Epoch 039: | Train Loss: 74.05304 | Test Loss: 70.86033\n",
      "Epoch 040: | Train Loss: 74.05016 | Test Loss: 70.84476\n",
      "Epoch 041: | Train Loss: 74.06475 | Test Loss: 70.83511\n",
      "Epoch 042: | Train Loss: 74.05218 | Test Loss: 70.83117\n",
      "Epoch 043: | Train Loss: 74.05162 | Test Loss: 70.82069\n",
      "Epoch 044: | Train Loss: 74.04379 | Test Loss: 70.80317\n",
      "Epoch 045: | Train Loss: 74.04896 | Test Loss: 70.78371\n",
      "Epoch 046: | Train Loss: 74.03640 | Test Loss: 70.77613\n",
      "Epoch 047: | Train Loss: 74.02582 | Test Loss: 70.75463\n",
      "Epoch 048: | Train Loss: 74.02394 | Test Loss: 70.73154\n",
      "Epoch 049: | Train Loss: 74.00928 | Test Loss: 70.72037\n",
      "Epoch 050: | Train Loss: 73.99267 | Test Loss: 70.70212\n",
      "Epoch 051: | Train Loss: 73.99083 | Test Loss: 70.68340\n",
      "Epoch 052: | Train Loss: 73.98218 | Test Loss: 70.66992\n",
      "Epoch 053: | Train Loss: 73.98340 | Test Loss: 70.64954\n",
      "Epoch 054: | Train Loss: 73.95418 | Test Loss: 70.62102\n",
      "Epoch 055: | Train Loss: 73.93718 | Test Loss: 70.60416\n",
      "Epoch 056: | Train Loss: 73.93381 | Test Loss: 70.57374\n",
      "Epoch 057: | Train Loss: 73.91369 | Test Loss: 70.54784\n",
      "Epoch 058: | Train Loss: 73.89215 | Test Loss: 70.52707\n",
      "Epoch 059: | Train Loss: 73.86615 | Test Loss: 70.49928\n",
      "Epoch 060: | Train Loss: 73.84092 | Test Loss: 70.46380\n",
      "Epoch 061: | Train Loss: 73.79665 | Test Loss: 70.41887\n",
      "Epoch 062: | Train Loss: 73.74010 | Test Loss: 70.36960\n",
      "Epoch 063: | Train Loss: 73.72676 | Test Loss: 70.30987\n",
      "Epoch 064: | Train Loss: 73.67319 | Test Loss: 70.23012\n",
      "Epoch 065: | Train Loss: 73.61473 | Test Loss: 70.15015\n",
      "Epoch 066: | Train Loss: 73.51067 | Test Loss: 70.06104\n",
      "Epoch 067: | Train Loss: 73.41949 | Test Loss: 69.97176\n",
      "Epoch 068: | Train Loss: 73.27634 | Test Loss: 69.84257\n",
      "Epoch 069: | Train Loss: 73.15026 | Test Loss: 69.69052\n",
      "Epoch 070: | Train Loss: 72.97568 | Test Loss: 69.53210\n",
      "Epoch 071: | Train Loss: 72.79341 | Test Loss: 69.31376\n",
      "Epoch 072: | Train Loss: 72.51866 | Test Loss: 69.10828\n",
      "Epoch 073: | Train Loss: 72.22154 | Test Loss: 68.85059\n",
      "Epoch 074: | Train Loss: 71.90074 | Test Loss: 68.47879\n",
      "Epoch 075: | Train Loss: 71.55682 | Test Loss: 68.09903\n",
      "Epoch 076: | Train Loss: 71.09785 | Test Loss: 67.65137\n",
      "Epoch 077: | Train Loss: 70.56869 | Test Loss: 67.15183\n",
      "Epoch 078: | Train Loss: 69.92639 | Test Loss: 64.96640\n",
      "Epoch 079: | Train Loss: 47.59164 | Test Loss: 29.07366\n",
      "Epoch 080: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 081: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 082: | Train Loss: 25.95982 | Test Loss: 29.07366\n",
      "Epoch 083: | Train Loss: 25.95982 | Test Loss: 29.07366\n",
      "Epoch 084: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 085: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 086: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 087: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 088: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 089: | Train Loss: 25.93750 | Test Loss: 29.07366\n",
      "Epoch 090: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 091: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 092: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 093: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 094: | Train Loss: 25.95734 | Test Loss: 29.07366\n",
      "Epoch 095: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 096: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 097: | Train Loss: 25.93998 | Test Loss: 29.07366\n",
      "Epoch 098: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 099: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 100: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "stats of l2reg of  0.0001 are [ 0.85091  0.82991  8.9628  10.04192]\n",
      "running reg of 0.0003\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7354/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ed8379727d4df0912465302debb86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 25.69725 | Test Loss: 29.07366\n",
      "Epoch 002: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 003: | Train Loss: 25.95734 | Test Loss: 29.07366\n",
      "Epoch 004: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 005: | Train Loss: 25.95982 | Test Loss: 29.07366\n",
      "Epoch 006: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 007: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 008: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 009: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 010: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 011: | Train Loss: 25.93750 | Test Loss: 29.07366\n",
      "Epoch 012: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 013: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 014: | Train Loss: 25.96230 | Test Loss: 29.07366\n",
      "Epoch 015: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 016: | Train Loss: 25.95982 | Test Loss: 29.07366\n",
      "Epoch 017: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 018: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 019: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 020: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 021: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 022: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 023: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 024: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 025: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 026: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 027: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 028: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 029: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 030: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 031: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 032: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 033: | Train Loss: 25.95982 | Test Loss: 29.07366\n",
      "Epoch 034: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 035: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 036: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 037: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 038: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 039: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 040: | Train Loss: 25.96230 | Test Loss: 29.07366\n",
      "Epoch 041: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 042: | Train Loss: 25.95982 | Test Loss: 29.07366\n",
      "Epoch 043: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 044: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 045: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 046: | Train Loss: 25.93998 | Test Loss: 29.07366\n",
      "Epoch 047: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 048: | Train Loss: 25.95982 | Test Loss: 29.07366\n",
      "Epoch 049: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 050: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 051: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 052: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 053: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 054: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 055: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 056: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 057: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 058: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 059: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 060: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 061: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 062: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 063: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 064: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 065: | Train Loss: 25.96230 | Test Loss: 29.07366\n",
      "Epoch 066: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 067: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 068: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 069: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 070: | Train Loss: 25.95982 | Test Loss: 29.07366\n",
      "Epoch 071: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 072: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 073: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 074: | Train Loss: 25.95734 | Test Loss: 29.07366\n",
      "Epoch 075: | Train Loss: 25.93750 | Test Loss: 29.07366\n",
      "Epoch 076: | Train Loss: 25.93998 | Test Loss: 29.07366\n",
      "Epoch 077: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 078: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 079: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 080: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 081: | Train Loss: 25.93998 | Test Loss: 29.07366\n",
      "Epoch 082: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 083: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 084: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 085: | Train Loss: 25.93998 | Test Loss: 29.07366\n",
      "Epoch 086: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 087: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 088: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 089: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 090: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 091: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 092: | Train Loss: 25.95982 | Test Loss: 29.07366\n",
      "Epoch 093: | Train Loss: 25.93998 | Test Loss: 29.07366\n",
      "Epoch 094: | Train Loss: 25.93998 | Test Loss: 29.07366\n",
      "Epoch 095: | Train Loss: 25.94246 | Test Loss: 29.02675\n",
      "Epoch 096: | Train Loss: 25.95238 | Test Loss: 28.97923\n",
      "Epoch 097: | Train Loss: 15.33498 | Test Loss: 0.60283\n",
      "Epoch 098: | Train Loss: 0.57325 | Test Loss: 0.60381\n",
      "Epoch 099: | Train Loss: 0.57327 | Test Loss: 0.60466\n",
      "Epoch 100: | Train Loss: 0.57291 | Test Loss: 0.60573\n",
      "stats of l2reg of  0.0003 are [0.85091 0.82991 0.57254 0.60573]\n",
      "running reg of 0.001\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7354/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec61df339a9740798f5acadadba6758a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 26.04601 | Test Loss: 29.07366\n",
      "Epoch 002: | Train Loss: 25.96478 | Test Loss: 29.07366\n",
      "Epoch 003: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 004: | Train Loss: 25.93750 | Test Loss: 29.07366\n",
      "Epoch 005: | Train Loss: 25.95734 | Test Loss: 29.07366\n",
      "Epoch 006: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 007: | Train Loss: 25.95734 | Test Loss: 29.07366\n",
      "Epoch 008: | Train Loss: 25.96230 | Test Loss: 29.07366\n",
      "Epoch 009: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 010: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 011: | Train Loss: 25.93750 | Test Loss: 29.07366\n",
      "Epoch 012: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 013: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 014: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 015: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 016: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 017: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 018: | Train Loss: 25.95982 | Test Loss: 29.07366\n",
      "Epoch 019: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 020: | Train Loss: 25.93750 | Test Loss: 29.07366\n",
      "Epoch 021: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 022: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 023: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 024: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 025: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 026: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 027: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 028: | Train Loss: 25.93998 | Test Loss: 29.07366\n",
      "Epoch 029: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 030: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 031: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 032: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 033: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 034: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 035: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 036: | Train Loss: 25.93998 | Test Loss: 29.07366\n",
      "Epoch 037: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 038: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 039: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 040: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 041: | Train Loss: 25.93998 | Test Loss: 29.07366\n",
      "Epoch 042: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 043: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 044: | Train Loss: 25.93998 | Test Loss: 29.07366\n",
      "Epoch 045: | Train Loss: 25.95734 | Test Loss: 29.07366\n",
      "Epoch 046: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 047: | Train Loss: 25.96478 | Test Loss: 29.07366\n",
      "Epoch 048: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 049: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 050: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 051: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 052: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 053: | Train Loss: 25.96478 | Test Loss: 29.07366\n",
      "Epoch 054: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 055: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 056: | Train Loss: 25.94742 | Test Loss: 29.02675\n",
      "Epoch 057: | Train Loss: 25.94990 | Test Loss: 28.97907\n",
      "Epoch 058: | Train Loss: 3.39255 | Test Loss: 0.61096\n",
      "Epoch 059: | Train Loss: 0.57330 | Test Loss: 0.60584\n",
      "Epoch 060: | Train Loss: 0.57262 | Test Loss: 0.60367\n",
      "Epoch 061: | Train Loss: 0.57320 | Test Loss: 0.60521\n",
      "Epoch 062: | Train Loss: 0.57298 | Test Loss: 0.60377\n",
      "Epoch 063: | Train Loss: 0.57301 | Test Loss: 0.60549\n",
      "Epoch 064: | Train Loss: 0.57286 | Test Loss: 0.60462\n",
      "Epoch 065: | Train Loss: 0.57294 | Test Loss: 0.60382\n",
      "Epoch 066: | Train Loss: 0.57304 | Test Loss: 0.60454\n",
      "Epoch 067: | Train Loss: 0.57286 | Test Loss: 0.60617\n",
      "Epoch 068: | Train Loss: 0.57270 | Test Loss: 0.60542\n",
      "Epoch 069: | Train Loss: 0.57263 | Test Loss: 0.60502\n",
      "Epoch 070: | Train Loss: 0.57283 | Test Loss: 0.60463\n",
      "Epoch 071: | Train Loss: 0.57280 | Test Loss: 0.60380\n",
      "Epoch 072: | Train Loss: 0.57312 | Test Loss: 0.60413\n",
      "Epoch 073: | Train Loss: 0.57261 | Test Loss: 0.60520\n",
      "Epoch 074: | Train Loss: 0.57319 | Test Loss: 0.60526\n",
      "Epoch 075: | Train Loss: 0.57266 | Test Loss: 0.60540\n",
      "Epoch 076: | Train Loss: 0.57267 | Test Loss: 0.60341\n",
      "Epoch 077: | Train Loss: 0.57276 | Test Loss: 0.60690\n",
      "Epoch 078: | Train Loss: 0.57274 | Test Loss: 0.60504\n",
      "Epoch 079: | Train Loss: 0.57281 | Test Loss: 0.60596\n",
      "Epoch 080: | Train Loss: 0.57293 | Test Loss: 0.60533\n",
      "Epoch 081: | Train Loss: 0.56182 | Test Loss: 0.52674\n",
      "Epoch 082: | Train Loss: 0.47264 | Test Loss: 0.47459\n",
      "Epoch 083: | Train Loss: 0.46348 | Test Loss: 0.47808\n",
      "Epoch 084: | Train Loss: 0.43412 | Test Loss: 0.48204\n",
      "Epoch 085: | Train Loss: 0.42060 | Test Loss: 0.48833\n",
      "Epoch 086: | Train Loss: 0.40856 | Test Loss: 0.43417\n",
      "Epoch 087: | Train Loss: 0.39872 | Test Loss: 0.43644\n",
      "Epoch 088: | Train Loss: 0.38417 | Test Loss: 0.41450\n",
      "Epoch 089: | Train Loss: 0.36940 | Test Loss: 0.42480\n",
      "Epoch 090: | Train Loss: 0.38975 | Test Loss: 0.40971\n",
      "Epoch 091: | Train Loss: 0.37177 | Test Loss: 0.39943\n",
      "Epoch 092: | Train Loss: 0.36779 | Test Loss: 0.39848\n",
      "Epoch 093: | Train Loss: 0.34868 | Test Loss: 0.40255\n",
      "Epoch 094: | Train Loss: 0.34512 | Test Loss: 0.40210\n",
      "Epoch 095: | Train Loss: 0.35961 | Test Loss: 0.38149\n",
      "Epoch 096: | Train Loss: 0.32902 | Test Loss: 0.37787\n",
      "Epoch 097: | Train Loss: 0.32727 | Test Loss: 0.36067\n",
      "Epoch 098: | Train Loss: 0.33800 | Test Loss: 0.37381\n",
      "Epoch 099: | Train Loss: 0.30256 | Test Loss: 0.35545\n",
      "Epoch 100: | Train Loss: 0.29456 | Test Loss: 0.41369\n",
      "stats of l2reg of  0.001 are [0.89909 0.87711 0.33978 0.41369]\n",
      "running reg of 0.003\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7354/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7665862ebe747da8af834c14ad16163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 25.79541 | Test Loss: 29.07366\n",
      "Epoch 002: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 003: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 004: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 005: | Train Loss: 25.93998 | Test Loss: 29.07366\n",
      "Epoch 006: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 007: | Train Loss: 25.95734 | Test Loss: 29.07366\n",
      "Epoch 008: | Train Loss: 25.95982 | Test Loss: 29.07366\n",
      "Epoch 009: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 010: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 011: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 012: | Train Loss: 25.95982 | Test Loss: 29.07366\n",
      "Epoch 013: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 014: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 015: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 016: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 017: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 018: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 019: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 020: | Train Loss: 25.95734 | Test Loss: 29.07366\n",
      "Epoch 021: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 022: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 023: | Train Loss: 25.95982 | Test Loss: 29.07366\n",
      "Epoch 024: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 025: | Train Loss: 25.93998 | Test Loss: 29.07366\n",
      "Epoch 026: | Train Loss: 25.96230 | Test Loss: 29.07366\n",
      "Epoch 027: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 028: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 029: | Train Loss: 25.93998 | Test Loss: 29.07366\n",
      "Epoch 030: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 031: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 032: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 033: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 034: | Train Loss: 25.93998 | Test Loss: 29.07366\n",
      "Epoch 035: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 036: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 037: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 038: | Train Loss: 25.95486 | Test Loss: 29.02675\n",
      "Epoch 039: | Train Loss: 25.92111 | Test Loss: 11.67524\n",
      "Epoch 040: | Train Loss: 0.88768 | Test Loss: 0.60485\n",
      "Epoch 041: | Train Loss: 0.57305 | Test Loss: 0.60416\n",
      "Epoch 042: | Train Loss: 0.57274 | Test Loss: 0.60427\n",
      "Epoch 043: | Train Loss: 0.57331 | Test Loss: 0.60515\n",
      "Epoch 044: | Train Loss: 0.57274 | Test Loss: 0.60410\n",
      "Epoch 045: | Train Loss: 0.57298 | Test Loss: 0.60396\n",
      "Epoch 046: | Train Loss: 0.57287 | Test Loss: 0.60623\n",
      "Epoch 047: | Train Loss: 0.57506 | Test Loss: 0.60584\n",
      "Epoch 048: | Train Loss: 0.57267 | Test Loss: 0.60465\n",
      "Epoch 049: | Train Loss: 0.57290 | Test Loss: 0.60424\n",
      "Epoch 050: | Train Loss: 0.57281 | Test Loss: 0.60351\n",
      "Epoch 051: | Train Loss: 0.57267 | Test Loss: 0.60427\n",
      "Epoch 052: | Train Loss: 0.57287 | Test Loss: 0.60447\n",
      "Epoch 053: | Train Loss: 0.57278 | Test Loss: 0.60744\n",
      "Epoch 054: | Train Loss: 0.57339 | Test Loss: 0.60580\n",
      "Epoch 055: | Train Loss: 0.57292 | Test Loss: 0.60463\n",
      "Epoch 056: | Train Loss: 0.57263 | Test Loss: 0.60443\n",
      "Epoch 057: | Train Loss: 0.57291 | Test Loss: 0.60569\n",
      "Epoch 058: | Train Loss: 0.57291 | Test Loss: 0.60569\n",
      "Epoch 059: | Train Loss: 0.57293 | Test Loss: 0.60399\n",
      "Epoch 060: | Train Loss: 0.57299 | Test Loss: 0.60454\n",
      "Epoch 061: | Train Loss: 0.57334 | Test Loss: 0.60524\n",
      "Epoch 062: | Train Loss: 0.57019 | Test Loss: 0.60820\n",
      "Epoch 063: | Train Loss: 0.57279 | Test Loss: 0.60352\n",
      "Epoch 064: | Train Loss: 0.57303 | Test Loss: 0.60478\n",
      "Epoch 065: | Train Loss: 0.57320 | Test Loss: 0.60552\n",
      "Epoch 066: | Train Loss: 0.57305 | Test Loss: 0.60520\n",
      "Epoch 067: | Train Loss: 0.57198 | Test Loss: 0.59517\n",
      "Epoch 068: | Train Loss: 0.50663 | Test Loss: 0.52504\n",
      "Epoch 069: | Train Loss: 0.48389 | Test Loss: 0.51466\n",
      "Epoch 070: | Train Loss: 0.48033 | Test Loss: 0.51597\n",
      "Epoch 071: | Train Loss: 0.50231 | Test Loss: 0.44042\n",
      "Epoch 072: | Train Loss: 0.41948 | Test Loss: 0.47646\n",
      "Epoch 073: | Train Loss: 0.37910 | Test Loss: 0.45698\n",
      "Epoch 074: | Train Loss: 0.36436 | Test Loss: 0.37752\n",
      "Epoch 075: | Train Loss: 0.33541 | Test Loss: 0.35671\n",
      "Epoch 076: | Train Loss: 0.32626 | Test Loss: 0.48631\n",
      "Epoch 077: | Train Loss: 0.34589 | Test Loss: 0.34777\n",
      "Epoch 078: | Train Loss: 0.31793 | Test Loss: 0.34360\n",
      "Epoch 079: | Train Loss: 0.31067 | Test Loss: 0.33176\n",
      "Epoch 080: | Train Loss: 0.35807 | Test Loss: 0.35011\n",
      "Epoch 081: | Train Loss: 0.31484 | Test Loss: 0.35088\n",
      "Epoch 082: | Train Loss: 0.30768 | Test Loss: 0.32104\n",
      "Epoch 083: | Train Loss: 0.29284 | Test Loss: 0.31392\n",
      "Epoch 084: | Train Loss: 0.28522 | Test Loss: 0.32406\n",
      "Epoch 085: | Train Loss: 0.28958 | Test Loss: 0.33105\n",
      "Epoch 086: | Train Loss: 0.29071 | Test Loss: 0.30465\n",
      "Epoch 087: | Train Loss: 0.26798 | Test Loss: 0.31070\n",
      "Epoch 088: | Train Loss: 0.27197 | Test Loss: 0.30414\n",
      "Epoch 089: | Train Loss: 0.26768 | Test Loss: 0.27292\n",
      "Epoch 090: | Train Loss: 0.25544 | Test Loss: 0.28909\n",
      "Epoch 091: | Train Loss: 0.26211 | Test Loss: 0.27347\n",
      "Epoch 092: | Train Loss: 0.25714 | Test Loss: 0.34198\n",
      "Epoch 093: | Train Loss: 0.28460 | Test Loss: 0.27985\n",
      "Epoch 094: | Train Loss: 0.26058 | Test Loss: 0.27414\n",
      "Epoch 095: | Train Loss: 0.24106 | Test Loss: 0.27399\n",
      "Epoch 096: | Train Loss: 0.24101 | Test Loss: 0.27844\n",
      "Epoch 097: | Train Loss: 0.23607 | Test Loss: 0.26765\n",
      "Epoch 098: | Train Loss: 0.22864 | Test Loss: 0.27101\n",
      "Epoch 099: | Train Loss: 0.24727 | Test Loss: 0.27811\n",
      "Epoch 100: | Train Loss: 0.23520 | Test Loss: 0.25684\n",
      "stats of l2reg of  0.003 are [0.94059 0.93297 0.22636 0.25684]\n",
      "running reg of 0.01\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7354/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42927f5466f941519c12e6e4c6bdcae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 25.82339 | Test Loss: 29.07366\n",
      "Epoch 002: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 003: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 004: | Train Loss: 25.96726 | Test Loss: 29.07366\n",
      "Epoch 005: | Train Loss: 25.95734 | Test Loss: 29.07366\n",
      "Epoch 006: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 007: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 008: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 009: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 010: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 011: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 012: | Train Loss: 25.95734 | Test Loss: 29.07366\n",
      "Epoch 013: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 014: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 015: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 016: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 017: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 018: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 019: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 020: | Train Loss: 25.93998 | Test Loss: 29.07366\n",
      "Epoch 021: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 022: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 023: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 024: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 025: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 026: | Train Loss: 25.95734 | Test Loss: 29.07366\n",
      "Epoch 027: | Train Loss: 25.95734 | Test Loss: 29.07366\n",
      "Epoch 028: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 029: | Train Loss: 25.69341 | Test Loss: 29.07366\n",
      "Epoch 030: | Train Loss: 25.95734 | Test Loss: 29.07366\n",
      "Epoch 031: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 032: | Train Loss: 25.95734 | Test Loss: 29.07366\n",
      "Epoch 033: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 034: | Train Loss: 25.93998 | Test Loss: 29.07366\n",
      "Epoch 035: | Train Loss: 25.94990 | Test Loss: 29.07366\n",
      "Epoch 036: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 037: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 038: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 039: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 040: | Train Loss: 25.95734 | Test Loss: 29.07366\n",
      "Epoch 041: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 042: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 043: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 044: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 045: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 046: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 047: | Train Loss: 25.93998 | Test Loss: 29.02675\n",
      "Epoch 048: | Train Loss: 12.39275 | Test Loss: 0.60345\n",
      "Epoch 049: | Train Loss: 0.57482 | Test Loss: 0.60286\n",
      "Epoch 050: | Train Loss: 0.57416 | Test Loss: 0.60399\n",
      "Epoch 051: | Train Loss: 0.57367 | Test Loss: 0.60549\n",
      "Epoch 052: | Train Loss: 0.57415 | Test Loss: 0.60332\n",
      "Epoch 053: | Train Loss: 0.57357 | Test Loss: 0.60336\n",
      "Epoch 054: | Train Loss: 0.57280 | Test Loss: 0.60301\n",
      "Epoch 055: | Train Loss: 0.57142 | Test Loss: 0.61228\n",
      "Epoch 056: | Train Loss: 0.54943 | Test Loss: 0.60201\n",
      "Epoch 057: | Train Loss: 0.48810 | Test Loss: 0.42826\n",
      "Epoch 058: | Train Loss: 0.41439 | Test Loss: 0.42743\n",
      "Epoch 059: | Train Loss: 0.39354 | Test Loss: 0.41352\n",
      "Epoch 060: | Train Loss: 0.38018 | Test Loss: 0.41174\n",
      "Epoch 061: | Train Loss: 0.37699 | Test Loss: 0.40814\n",
      "Epoch 062: | Train Loss: 0.36406 | Test Loss: 0.41900\n",
      "Epoch 063: | Train Loss: 0.35486 | Test Loss: 0.37365\n",
      "Epoch 064: | Train Loss: 0.33770 | Test Loss: 0.37053\n",
      "Epoch 065: | Train Loss: 0.31835 | Test Loss: 0.33911\n",
      "Epoch 066: | Train Loss: 0.31213 | Test Loss: 0.32838\n",
      "Epoch 067: | Train Loss: 0.30842 | Test Loss: 0.32324\n",
      "Epoch 068: | Train Loss: 0.29649 | Test Loss: 0.31512\n",
      "Epoch 069: | Train Loss: 0.29381 | Test Loss: 0.31171\n",
      "Epoch 070: | Train Loss: 0.29717 | Test Loss: 0.34556\n",
      "Epoch 071: | Train Loss: 0.29822 | Test Loss: 0.31969\n",
      "Epoch 072: | Train Loss: 0.29153 | Test Loss: 0.32880\n",
      "Epoch 073: | Train Loss: 0.30159 | Test Loss: 0.32386\n",
      "Epoch 074: | Train Loss: 0.28998 | Test Loss: 0.31712\n",
      "Epoch 075: | Train Loss: 0.29313 | Test Loss: 0.29825\n",
      "Epoch 076: | Train Loss: 0.27630 | Test Loss: 0.32129\n",
      "Epoch 077: | Train Loss: 0.28351 | Test Loss: 0.33188\n",
      "Epoch 078: | Train Loss: 0.26620 | Test Loss: 0.29102\n",
      "Epoch 079: | Train Loss: 0.26313 | Test Loss: 0.30018\n",
      "Epoch 080: | Train Loss: 0.26970 | Test Loss: 0.28965\n",
      "Epoch 081: | Train Loss: 0.25425 | Test Loss: 0.28094\n",
      "Epoch 082: | Train Loss: 0.26362 | Test Loss: 0.28715\n",
      "Epoch 083: | Train Loss: 0.26495 | Test Loss: 0.28590\n",
      "Epoch 084: | Train Loss: 0.26411 | Test Loss: 0.28515\n",
      "Epoch 085: | Train Loss: 0.24569 | Test Loss: 0.25636\n",
      "Epoch 086: | Train Loss: 0.24707 | Test Loss: 0.25847\n",
      "Epoch 087: | Train Loss: 0.24604 | Test Loss: 0.25157\n",
      "Epoch 088: | Train Loss: 0.25112 | Test Loss: 0.25695\n",
      "Epoch 089: | Train Loss: 0.23576 | Test Loss: 0.24671\n",
      "Epoch 090: | Train Loss: 0.23052 | Test Loss: 0.30197\n",
      "Epoch 091: | Train Loss: 0.23199 | Test Loss: 0.24845\n",
      "Epoch 092: | Train Loss: 0.22983 | Test Loss: 0.24672\n",
      "Epoch 093: | Train Loss: 0.22292 | Test Loss: 0.25135\n",
      "Epoch 094: | Train Loss: 0.22802 | Test Loss: 0.24910\n",
      "Epoch 095: | Train Loss: 0.21870 | Test Loss: 0.23867\n",
      "Epoch 096: | Train Loss: 0.21767 | Test Loss: 0.24193\n",
      "Epoch 097: | Train Loss: 0.22442 | Test Loss: 0.23403\n",
      "Epoch 098: | Train Loss: 0.21582 | Test Loss: 0.24381\n",
      "Epoch 099: | Train Loss: 0.21743 | Test Loss: 0.23699\n",
      "Epoch 100: | Train Loss: 0.22156 | Test Loss: 0.23937\n",
      "stats of l2reg of  0.01 are [0.94681 0.94062 0.2061  0.23937]\n",
      "running reg of 0.03\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7354/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475d1c897a05445386a0bb7e9abda618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 25.40148 | Test Loss: 29.07366\n",
      "Epoch 002: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 003: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 004: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 005: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 006: | Train Loss: 18.40362 | Test Loss: 0.58268\n",
      "Epoch 007: | Train Loss: 0.48716 | Test Loss: 0.45691\n",
      "Epoch 008: | Train Loss: 0.37295 | Test Loss: 0.48901\n",
      "Epoch 009: | Train Loss: 0.31355 | Test Loss: 0.26517\n",
      "Epoch 010: | Train Loss: 0.24882 | Test Loss: 0.26673\n",
      "Epoch 011: | Train Loss: 0.23503 | Test Loss: 0.23348\n",
      "Epoch 012: | Train Loss: 0.25046 | Test Loss: 0.21467\n",
      "Epoch 013: | Train Loss: 0.21651 | Test Loss: 0.21482\n",
      "Epoch 014: | Train Loss: 0.22453 | Test Loss: 0.21701\n",
      "Epoch 015: | Train Loss: 0.19486 | Test Loss: 0.20144\n",
      "Epoch 016: | Train Loss: 0.19812 | Test Loss: 0.19882\n",
      "Epoch 017: | Train Loss: 0.19776 | Test Loss: 0.21919\n",
      "Epoch 018: | Train Loss: 0.20300 | Test Loss: 0.26643\n",
      "Epoch 019: | Train Loss: 0.20761 | Test Loss: 0.25868\n",
      "Epoch 020: | Train Loss: 0.21024 | Test Loss: 0.22550\n",
      "Epoch 021: | Train Loss: 0.21276 | Test Loss: 0.23933\n",
      "Epoch 022: | Train Loss: 0.18769 | Test Loss: 0.20593\n",
      "Epoch 023: | Train Loss: 0.18169 | Test Loss: 0.19923\n",
      "Epoch 024: | Train Loss: 0.17672 | Test Loss: 0.19853\n",
      "Epoch 025: | Train Loss: 0.17196 | Test Loss: 0.18930\n",
      "Epoch 026: | Train Loss: 0.21513 | Test Loss: 0.19289\n",
      "Epoch 027: | Train Loss: 0.17499 | Test Loss: 0.19454\n",
      "Epoch 028: | Train Loss: 0.17044 | Test Loss: 0.19410\n",
      "Epoch 029: | Train Loss: 0.16574 | Test Loss: 0.24327\n",
      "Epoch 030: | Train Loss: 0.16514 | Test Loss: 0.21602\n",
      "Epoch 031: | Train Loss: 0.16487 | Test Loss: 0.33878\n",
      "Epoch 032: | Train Loss: 0.16383 | Test Loss: 0.32369\n",
      "Epoch 033: | Train Loss: 0.18223 | Test Loss: 0.48145\n",
      "Epoch 034: | Train Loss: 0.17675 | Test Loss: 0.23639\n",
      "Epoch 035: | Train Loss: 0.15663 | Test Loss: 0.18610\n",
      "Epoch 036: | Train Loss: 0.16096 | Test Loss: 0.24097\n",
      "Epoch 037: | Train Loss: 0.17399 | Test Loss: 0.20443\n",
      "Epoch 038: | Train Loss: 0.16479 | Test Loss: 0.26341\n",
      "Epoch 039: | Train Loss: 0.15587 | Test Loss: 0.24030\n",
      "Epoch 040: | Train Loss: 0.16467 | Test Loss: 0.20873\n",
      "Epoch 041: | Train Loss: 0.17429 | Test Loss: 0.21390\n",
      "Epoch 042: | Train Loss: 0.15366 | Test Loss: 0.25147\n",
      "Epoch 043: | Train Loss: 0.15555 | Test Loss: 0.18808\n",
      "Epoch 044: | Train Loss: 0.17356 | Test Loss: 0.20737\n",
      "Epoch 045: | Train Loss: 0.16964 | Test Loss: 0.23145\n",
      "Epoch 046: | Train Loss: 0.19193 | Test Loss: 0.30567\n",
      "Epoch 047: | Train Loss: 0.16041 | Test Loss: 0.18827\n",
      "Epoch 048: | Train Loss: 0.16983 | Test Loss: 0.23272\n",
      "Epoch 049: | Train Loss: 0.14535 | Test Loss: 0.18638\n",
      "Epoch 050: | Train Loss: 0.21916 | Test Loss: 0.55447\n",
      "Epoch 051: | Train Loss: 0.22896 | Test Loss: 0.26037\n",
      "Epoch 052: | Train Loss: 0.16614 | Test Loss: 0.20340\n",
      "Epoch 053: | Train Loss: 0.14892 | Test Loss: 0.23912\n",
      "Epoch 054: | Train Loss: 0.15141 | Test Loss: 0.18265\n",
      "Epoch 055: | Train Loss: 0.14954 | Test Loss: 0.19191\n",
      "Epoch 056: | Train Loss: 0.14697 | Test Loss: 0.18401\n",
      "Epoch 057: | Train Loss: 0.14139 | Test Loss: 0.24016\n",
      "Epoch 058: | Train Loss: 0.16392 | Test Loss: 0.22158\n",
      "Epoch 059: | Train Loss: 0.15354 | Test Loss: 0.29717\n",
      "Epoch 060: | Train Loss: 0.15576 | Test Loss: 0.28705\n",
      "Epoch 061: | Train Loss: 0.14779 | Test Loss: 0.29516\n",
      "Epoch 062: | Train Loss: 0.14134 | Test Loss: 0.19094\n",
      "Epoch 063: | Train Loss: 0.14002 | Test Loss: 0.18092\n",
      "Epoch 064: | Train Loss: 0.14248 | Test Loss: 0.23934\n",
      "Epoch 065: | Train Loss: 0.20647 | Test Loss: 0.18591\n",
      "Epoch 066: | Train Loss: 0.14115 | Test Loss: 0.17906\n",
      "Epoch 067: | Train Loss: 0.15699 | Test Loss: 0.25088\n",
      "Epoch 068: | Train Loss: 0.16568 | Test Loss: 0.34816\n",
      "Epoch 069: | Train Loss: 0.15938 | Test Loss: 0.36366\n",
      "Epoch 070: | Train Loss: 0.20831 | Test Loss: 0.24774\n",
      "Epoch 071: | Train Loss: 0.16140 | Test Loss: 0.30020\n",
      "Epoch 072: | Train Loss: 0.14474 | Test Loss: 0.23766\n",
      "Epoch 073: | Train Loss: 0.13862 | Test Loss: 0.18328\n",
      "Epoch 074: | Train Loss: 0.15217 | Test Loss: 0.24852\n",
      "Epoch 075: | Train Loss: 0.16191 | Test Loss: 0.22764\n",
      "Epoch 076: | Train Loss: 0.13683 | Test Loss: 0.18366\n",
      "Epoch 077: | Train Loss: 0.15992 | Test Loss: 0.27226\n",
      "Epoch 078: | Train Loss: 0.13589 | Test Loss: 0.18025\n",
      "Epoch 079: | Train Loss: 0.14585 | Test Loss: 0.18854\n",
      "Epoch 080: | Train Loss: 0.14700 | Test Loss: 0.17953\n",
      "Epoch 081: | Train Loss: 0.14716 | Test Loss: 0.18969\n",
      "Epoch 082: | Train Loss: 0.13653 | Test Loss: 0.19067\n",
      "Epoch 083: | Train Loss: 0.13881 | Test Loss: 0.18298\n",
      "Epoch 084: | Train Loss: 0.13932 | Test Loss: 0.27872\n",
      "Epoch 085: | Train Loss: 0.13894 | Test Loss: 0.18113\n",
      "Epoch 086: | Train Loss: 0.14759 | Test Loss: 0.17242\n",
      "Epoch 087: | Train Loss: 0.13274 | Test Loss: 0.17575\n",
      "Epoch 088: | Train Loss: 0.13153 | Test Loss: 0.21736\n",
      "Epoch 089: | Train Loss: 0.13825 | Test Loss: 0.26358\n",
      "Epoch 090: | Train Loss: 0.13874 | Test Loss: 0.17319\n",
      "Epoch 091: | Train Loss: 0.12691 | Test Loss: 0.23071\n",
      "Epoch 092: | Train Loss: 0.12848 | Test Loss: 0.22225\n",
      "Epoch 093: | Train Loss: 0.14928 | Test Loss: 0.18798\n",
      "Epoch 094: | Train Loss: 0.15698 | Test Loss: 0.19353\n",
      "Epoch 095: | Train Loss: 0.13776 | Test Loss: 0.38085\n",
      "Epoch 096: | Train Loss: 0.13709 | Test Loss: 0.17813\n",
      "Epoch 097: | Train Loss: 0.13191 | Test Loss: 0.19010\n",
      "Epoch 098: | Train Loss: 0.13227 | Test Loss: 0.17251\n",
      "Epoch 099: | Train Loss: 0.12975 | Test Loss: 0.18290\n",
      "Epoch 100: | Train Loss: 0.13308 | Test Loss: 0.29846\n",
      "stats of l2reg of  0.03 are [0.96768 0.95742 0.1331  0.2254 ]\n",
      "running reg of 0.1\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7354/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91929cd5d6a5420684dbfa62172a6e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 25.84004 | Test Loss: 29.07366\n",
      "Epoch 002: | Train Loss: 25.95238 | Test Loss: 29.07366\n",
      "Epoch 003: | Train Loss: 25.94742 | Test Loss: 29.07366\n",
      "Epoch 004: | Train Loss: 25.94246 | Test Loss: 29.07366\n",
      "Epoch 005: | Train Loss: 25.94494 | Test Loss: 29.07366\n",
      "Epoch 006: | Train Loss: 25.94246 | Test Loss: 29.02675\n",
      "Epoch 007: | Train Loss: 15.43619 | Test Loss: 0.56144\n",
      "Epoch 008: | Train Loss: 0.47514 | Test Loss: 0.43651\n",
      "Epoch 009: | Train Loss: 0.43396 | Test Loss: 0.40796\n",
      "Epoch 010: | Train Loss: 0.40408 | Test Loss: 0.35545\n",
      "Epoch 011: | Train Loss: 0.42279 | Test Loss: 0.37019\n",
      "Epoch 012: | Train Loss: 0.39300 | Test Loss: 0.38045\n",
      "Epoch 013: | Train Loss: 0.39017 | Test Loss: 0.36099\n",
      "Epoch 014: | Train Loss: 0.38140 | Test Loss: 0.34716\n",
      "Epoch 015: | Train Loss: 0.39298 | Test Loss: 0.34541\n",
      "Epoch 016: | Train Loss: 0.37137 | Test Loss: 0.32291\n",
      "Epoch 017: | Train Loss: 0.41941 | Test Loss: 0.32451\n",
      "Epoch 018: | Train Loss: 0.36609 | Test Loss: 0.40017\n",
      "Epoch 019: | Train Loss: 0.37839 | Test Loss: 0.34763\n",
      "Epoch 020: | Train Loss: 0.38815 | Test Loss: 0.32880\n",
      "Epoch 021: | Train Loss: 0.35790 | Test Loss: 0.31344\n",
      "Epoch 022: | Train Loss: 0.35824 | Test Loss: 0.32640\n",
      "Epoch 023: | Train Loss: 0.36914 | Test Loss: 0.31340\n",
      "Epoch 024: | Train Loss: 0.34252 | Test Loss: 0.34214\n",
      "Epoch 025: | Train Loss: 0.35062 | Test Loss: 0.30952\n",
      "Epoch 026: | Train Loss: 0.33632 | Test Loss: 0.34653\n",
      "Epoch 027: | Train Loss: 0.33905 | Test Loss: 0.30151\n",
      "Epoch 028: | Train Loss: 0.35028 | Test Loss: 0.34793\n",
      "Epoch 029: | Train Loss: 0.35705 | Test Loss: 0.29818\n",
      "Epoch 030: | Train Loss: 0.34362 | Test Loss: 0.35940\n",
      "Epoch 031: | Train Loss: 0.37392 | Test Loss: 0.32906\n",
      "Epoch 032: | Train Loss: 0.32730 | Test Loss: 0.35525\n",
      "Epoch 033: | Train Loss: 0.32721 | Test Loss: 0.31723\n",
      "Epoch 034: | Train Loss: 0.35725 | Test Loss: 0.34563\n",
      "Epoch 035: | Train Loss: 0.33269 | Test Loss: 0.31449\n",
      "Epoch 036: | Train Loss: 0.31371 | Test Loss: 0.32867\n",
      "Epoch 037: | Train Loss: 0.33166 | Test Loss: 0.30022\n",
      "Epoch 038: | Train Loss: 0.32333 | Test Loss: 0.29611\n",
      "Epoch 039: | Train Loss: 0.33664 | Test Loss: 0.32203\n",
      "Epoch 040: | Train Loss: 0.32831 | Test Loss: 0.34360\n",
      "Epoch 041: | Train Loss: 0.31811 | Test Loss: 0.34531\n",
      "Epoch 042: | Train Loss: 0.31555 | Test Loss: 0.31859\n",
      "Epoch 043: | Train Loss: 0.30701 | Test Loss: 0.34287\n",
      "Epoch 044: | Train Loss: 0.32252 | Test Loss: 0.34691\n",
      "Epoch 045: | Train Loss: 0.32986 | Test Loss: 0.34466\n",
      "Epoch 046: | Train Loss: 0.33470 | Test Loss: 0.34234\n",
      "Epoch 047: | Train Loss: 0.35478 | Test Loss: 0.39068\n",
      "Epoch 048: | Train Loss: 0.30339 | Test Loss: 0.34934\n",
      "Epoch 049: | Train Loss: 0.31732 | Test Loss: 0.30797\n",
      "Epoch 050: | Train Loss: 0.30171 | Test Loss: 0.33912\n",
      "Epoch 051: | Train Loss: 0.29768 | Test Loss: 0.34152\n",
      "Epoch 052: | Train Loss: 0.30229 | Test Loss: 0.34449\n",
      "Epoch 053: | Train Loss: 0.30565 | Test Loss: 0.30060\n",
      "Epoch 054: | Train Loss: 0.29602 | Test Loss: 0.32109\n",
      "Epoch 055: | Train Loss: 0.31421 | Test Loss: 0.39837\n",
      "Epoch 056: | Train Loss: 0.32595 | Test Loss: 0.34903\n",
      "Epoch 057: | Train Loss: 0.32386 | Test Loss: 0.29416\n",
      "Epoch 058: | Train Loss: 0.30008 | Test Loss: 0.28290\n",
      "Epoch 059: | Train Loss: 0.31462 | Test Loss: 0.29913\n",
      "Epoch 060: | Train Loss: 0.29280 | Test Loss: 0.37833\n",
      "Epoch 061: | Train Loss: 0.28706 | Test Loss: 0.28235\n",
      "Epoch 062: | Train Loss: 0.29465 | Test Loss: 0.32877\n",
      "Epoch 063: | Train Loss: 0.31235 | Test Loss: 0.54232\n",
      "Epoch 064: | Train Loss: 0.29627 | Test Loss: 0.32387\n",
      "Epoch 065: | Train Loss: 0.29807 | Test Loss: 0.32483\n",
      "Epoch 066: | Train Loss: 0.29119 | Test Loss: 0.33637\n",
      "Epoch 067: | Train Loss: 0.30045 | Test Loss: 0.30263\n",
      "Epoch 068: | Train Loss: 0.28768 | Test Loss: 0.34124\n",
      "Epoch 069: | Train Loss: 0.28794 | Test Loss: 0.45331\n",
      "Epoch 070: | Train Loss: 0.32684 | Test Loss: 0.39078\n",
      "Epoch 071: | Train Loss: 0.31384 | Test Loss: 0.33283\n",
      "Epoch 072: | Train Loss: 0.29373 | Test Loss: 0.27738\n",
      "Epoch 073: | Train Loss: 0.29495 | Test Loss: 0.29520\n",
      "Epoch 074: | Train Loss: 0.30708 | Test Loss: 0.28634\n",
      "Epoch 075: | Train Loss: 0.28621 | Test Loss: 0.33578\n",
      "Epoch 076: | Train Loss: 0.30576 | Test Loss: 0.34821\n",
      "Epoch 077: | Train Loss: 0.28612 | Test Loss: 0.37406\n",
      "Epoch 078: | Train Loss: 0.27976 | Test Loss: 0.33388\n",
      "Epoch 079: | Train Loss: 0.31249 | Test Loss: 0.30501\n",
      "Epoch 080: | Train Loss: 0.30099 | Test Loss: 0.29289\n",
      "Epoch 081: | Train Loss: 0.29355 | Test Loss: 0.33903\n",
      "Epoch 082: | Train Loss: 0.28480 | Test Loss: 0.33149\n",
      "Epoch 083: | Train Loss: 0.29619 | Test Loss: 0.29025\n",
      "Epoch 084: | Train Loss: 0.29748 | Test Loss: 0.33063\n",
      "Epoch 085: | Train Loss: 0.30958 | Test Loss: 0.32176\n",
      "Epoch 086: | Train Loss: 0.31831 | Test Loss: 0.32599\n",
      "Epoch 087: | Train Loss: 0.28869 | Test Loss: 0.35477\n",
      "Epoch 088: | Train Loss: 0.29655 | Test Loss: 0.30386\n",
      "Epoch 089: | Train Loss: 0.28757 | Test Loss: 0.28421\n",
      "Epoch 090: | Train Loss: 0.29166 | Test Loss: 0.28103\n",
      "Epoch 091: | Train Loss: 0.28931 | Test Loss: 0.32841\n",
      "Epoch 092: | Train Loss: 0.27739 | Test Loss: 0.33742\n",
      "Epoch 093: | Train Loss: 0.28313 | Test Loss: 0.27955\n",
      "Epoch 094: | Train Loss: 0.28979 | Test Loss: 0.29368\n",
      "Epoch 095: | Train Loss: 0.28330 | Test Loss: 0.38307\n",
      "Epoch 096: | Train Loss: 0.27422 | Test Loss: 0.31544\n",
      "Epoch 097: | Train Loss: 0.28308 | Test Loss: 0.32980\n",
      "Epoch 098: | Train Loss: 0.28076 | Test Loss: 0.32275\n",
      "Epoch 099: | Train Loss: 0.29331 | Test Loss: 0.47271\n",
      "Epoch 100: | Train Loss: 0.28361 | Test Loss: 0.28174\n",
      "stats of l2reg of  0.1 are [0.94051 0.93793 0.25334 0.28174]\n",
      "running reg of 0.3\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7354/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993f37c1ddd04c73beda1c26eedfba71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 25.79260 | Test Loss: 29.07366\n",
      "Epoch 002: | Train Loss: 25.54990 | Test Loss: 10.04900\n",
      "Epoch 003: | Train Loss: 0.94811 | Test Loss: 0.54735\n",
      "Epoch 004: | Train Loss: 0.52408 | Test Loss: 0.49357\n",
      "Epoch 005: | Train Loss: 0.58657 | Test Loss: 0.57352\n",
      "Epoch 006: | Train Loss: 0.53532 | Test Loss: 0.51367\n",
      "Epoch 007: | Train Loss: 0.50068 | Test Loss: 0.49159\n",
      "Epoch 008: | Train Loss: 0.47992 | Test Loss: 0.48967\n",
      "Epoch 009: | Train Loss: 0.46870 | Test Loss: 0.46737\n",
      "Epoch 010: | Train Loss: 0.45523 | Test Loss: 0.46873\n",
      "Epoch 011: | Train Loss: 0.46068 | Test Loss: 0.46332\n",
      "Epoch 012: | Train Loss: 0.50645 | Test Loss: 0.47917\n",
      "Epoch 013: | Train Loss: 0.45674 | Test Loss: 0.47425\n",
      "Epoch 014: | Train Loss: 0.48812 | Test Loss: 0.45866\n",
      "Epoch 015: | Train Loss: 0.48696 | Test Loss: 0.44552\n",
      "Epoch 016: | Train Loss: 0.45721 | Test Loss: 0.44271\n",
      "Epoch 017: | Train Loss: 0.46357 | Test Loss: 0.44395\n",
      "Epoch 018: | Train Loss: 0.48709 | Test Loss: 0.44128\n",
      "Epoch 019: | Train Loss: 0.49030 | Test Loss: 0.43199\n",
      "Epoch 020: | Train Loss: 0.45085 | Test Loss: 0.45533\n",
      "Epoch 021: | Train Loss: 0.45619 | Test Loss: 0.42998\n",
      "Epoch 022: | Train Loss: 0.43440 | Test Loss: 0.52979\n",
      "Epoch 023: | Train Loss: 0.42594 | Test Loss: 0.40512\n",
      "Epoch 024: | Train Loss: 0.43546 | Test Loss: 0.42499\n",
      "Epoch 025: | Train Loss: 0.44505 | Test Loss: 0.40164\n",
      "Epoch 026: | Train Loss: 0.44540 | Test Loss: 0.47849\n",
      "Epoch 027: | Train Loss: 0.41513 | Test Loss: 0.41135\n",
      "Epoch 028: | Train Loss: 0.42424 | Test Loss: 0.39360\n",
      "Epoch 029: | Train Loss: 0.40402 | Test Loss: 0.39637\n",
      "Epoch 030: | Train Loss: 0.38729 | Test Loss: 0.37874\n",
      "Epoch 031: | Train Loss: 0.40206 | Test Loss: 0.37897\n",
      "Epoch 032: | Train Loss: 0.38465 | Test Loss: 0.37116\n",
      "Epoch 033: | Train Loss: 0.39759 | Test Loss: 0.38161\n",
      "Epoch 034: | Train Loss: 0.39946 | Test Loss: 0.37685\n",
      "Epoch 035: | Train Loss: 0.38875 | Test Loss: 0.38154\n",
      "Epoch 036: | Train Loss: 0.37342 | Test Loss: 0.42199\n",
      "Epoch 037: | Train Loss: 0.37555 | Test Loss: 0.35886\n",
      "Epoch 038: | Train Loss: 0.38540 | Test Loss: 0.38719\n",
      "Epoch 039: | Train Loss: 0.38101 | Test Loss: 0.42864\n",
      "Epoch 040: | Train Loss: 0.38394 | Test Loss: 0.42341\n",
      "Epoch 041: | Train Loss: 0.42898 | Test Loss: 0.51769\n",
      "Epoch 042: | Train Loss: 0.38355 | Test Loss: 0.43060\n",
      "Epoch 043: | Train Loss: 0.37470 | Test Loss: 0.36467\n",
      "Epoch 044: | Train Loss: 0.37946 | Test Loss: 0.36100\n",
      "Epoch 045: | Train Loss: 0.38492 | Test Loss: 0.35795\n",
      "Epoch 046: | Train Loss: 0.38382 | Test Loss: 0.39723\n",
      "Epoch 047: | Train Loss: 0.42350 | Test Loss: 0.38144\n",
      "Epoch 048: | Train Loss: 0.38220 | Test Loss: 0.47363\n",
      "Epoch 049: | Train Loss: 0.41824 | Test Loss: 0.35996\n",
      "Epoch 050: | Train Loss: 0.36450 | Test Loss: 0.40309\n",
      "Epoch 051: | Train Loss: 0.36210 | Test Loss: 0.41686\n",
      "Epoch 052: | Train Loss: 0.36603 | Test Loss: 0.40748\n",
      "Epoch 053: | Train Loss: 0.36502 | Test Loss: 0.40430\n",
      "Epoch 054: | Train Loss: 0.37898 | Test Loss: 0.45970\n",
      "Epoch 055: | Train Loss: 0.37259 | Test Loss: 0.35830\n",
      "Epoch 056: | Train Loss: 0.36168 | Test Loss: 0.39579\n",
      "Epoch 057: | Train Loss: 0.35893 | Test Loss: 0.46286\n",
      "Epoch 058: | Train Loss: 0.36478 | Test Loss: 0.39435\n",
      "Epoch 059: | Train Loss: 0.35745 | Test Loss: 0.36484\n",
      "Epoch 060: | Train Loss: 0.38295 | Test Loss: 0.46131\n",
      "Epoch 061: | Train Loss: 0.37291 | Test Loss: 0.36478\n",
      "Epoch 062: | Train Loss: 0.37004 | Test Loss: 0.45697\n",
      "Epoch 063: | Train Loss: 0.37010 | Test Loss: 0.41523\n",
      "Epoch 064: | Train Loss: 0.37784 | Test Loss: 0.37323\n",
      "Epoch 065: | Train Loss: 0.37775 | Test Loss: 0.36297\n",
      "Epoch 066: | Train Loss: 0.36508 | Test Loss: 0.40205\n",
      "Epoch 067: | Train Loss: 0.37309 | Test Loss: 0.35579\n",
      "Epoch 068: | Train Loss: 0.36326 | Test Loss: 0.44002\n",
      "Epoch 069: | Train Loss: 0.38286 | Test Loss: 0.37472\n",
      "Epoch 070: | Train Loss: 0.37487 | Test Loss: 0.36546\n",
      "Epoch 071: | Train Loss: 0.44682 | Test Loss: 0.35848\n",
      "Epoch 072: | Train Loss: 0.36473 | Test Loss: 0.41472\n",
      "Epoch 073: | Train Loss: 0.36274 | Test Loss: 0.35403\n",
      "Epoch 074: | Train Loss: 0.37070 | Test Loss: 0.41348\n",
      "Epoch 075: | Train Loss: 0.35864 | Test Loss: 0.42135\n",
      "Epoch 076: | Train Loss: 0.36223 | Test Loss: 0.41404\n",
      "Epoch 077: | Train Loss: 0.37083 | Test Loss: 0.41527\n",
      "Epoch 078: | Train Loss: 0.37306 | Test Loss: 0.37559\n",
      "Epoch 079: | Train Loss: 0.36203 | Test Loss: 0.45885\n",
      "Epoch 080: | Train Loss: 0.36458 | Test Loss: 0.49798\n",
      "Epoch 081: | Train Loss: 0.37038 | Test Loss: 0.36480\n",
      "Epoch 082: | Train Loss: 0.35986 | Test Loss: 0.41259\n",
      "Epoch 083: | Train Loss: 0.36746 | Test Loss: 0.34939\n",
      "Epoch 084: | Train Loss: 0.36852 | Test Loss: 0.45010\n",
      "Epoch 085: | Train Loss: 0.35560 | Test Loss: 0.35992\n",
      "Epoch 086: | Train Loss: 0.35745 | Test Loss: 0.40303\n",
      "Epoch 087: | Train Loss: 0.36352 | Test Loss: 0.52222\n",
      "Epoch 088: | Train Loss: 0.36873 | Test Loss: 0.41807\n",
      "Epoch 089: | Train Loss: 0.36659 | Test Loss: 0.35963\n",
      "Epoch 090: | Train Loss: 0.36725 | Test Loss: 0.45800\n",
      "Epoch 091: | Train Loss: 0.36175 | Test Loss: 0.44726\n",
      "Epoch 092: | Train Loss: 0.36175 | Test Loss: 0.40517\n",
      "Epoch 093: | Train Loss: 0.36874 | Test Loss: 0.36359\n",
      "Epoch 094: | Train Loss: 0.36411 | Test Loss: 0.39043\n",
      "Epoch 095: | Train Loss: 0.34758 | Test Loss: 0.38726\n",
      "Epoch 096: | Train Loss: 0.36176 | Test Loss: 0.40553\n",
      "Epoch 097: | Train Loss: 0.35424 | Test Loss: 0.47501\n",
      "Epoch 098: | Train Loss: 0.36349 | Test Loss: 0.34629\n",
      "Epoch 099: | Train Loss: 0.35843 | Test Loss: 0.35189\n",
      "Epoch 100: | Train Loss: 0.35791 | Test Loss: 0.35833\n",
      "stats of l2reg of  0.3 are [0.90657 0.90478 0.34364 0.35833]\n",
      "running reg of 1\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7354/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de64c63846404db288f4b04e1bc1cd59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 25.80839 | Test Loss: 25.84713\n",
      "Epoch 002: | Train Loss: 1.82224 | Test Loss: 0.58842\n",
      "Epoch 003: | Train Loss: 0.57560 | Test Loss: 0.63237\n",
      "Epoch 004: | Train Loss: 0.59934 | Test Loss: 0.60675\n",
      "Epoch 005: | Train Loss: 0.61033 | Test Loss: 0.62189\n",
      "Epoch 006: | Train Loss: 0.61746 | Test Loss: 0.63183\n",
      "Epoch 007: | Train Loss: 0.61832 | Test Loss: 0.63568\n",
      "Epoch 008: | Train Loss: 0.63660 | Test Loss: 0.65553\n",
      "Epoch 009: | Train Loss: 0.64716 | Test Loss: 0.65795\n",
      "Epoch 010: | Train Loss: 0.65225 | Test Loss: 0.65827\n",
      "Epoch 011: | Train Loss: 0.65189 | Test Loss: 0.65785\n",
      "Epoch 012: | Train Loss: 0.65199 | Test Loss: 0.65747\n",
      "Epoch 013: | Train Loss: 0.65104 | Test Loss: 0.65737\n",
      "Epoch 014: | Train Loss: 0.65174 | Test Loss: 0.65792\n",
      "Epoch 015: | Train Loss: 0.65181 | Test Loss: 0.65732\n",
      "Epoch 016: | Train Loss: 0.65090 | Test Loss: 0.65791\n",
      "Epoch 017: | Train Loss: 0.65170 | Test Loss: 0.65742\n",
      "Epoch 018: | Train Loss: 0.65178 | Test Loss: 0.65742\n",
      "Epoch 019: | Train Loss: 0.65140 | Test Loss: 0.65792\n",
      "Epoch 020: | Train Loss: 0.65184 | Test Loss: 0.65715\n",
      "Epoch 021: | Train Loss: 0.65159 | Test Loss: 0.65707\n",
      "Epoch 022: | Train Loss: 0.65149 | Test Loss: 0.65716\n",
      "Epoch 023: | Train Loss: 0.65127 | Test Loss: 0.65742\n",
      "Epoch 024: | Train Loss: 0.65091 | Test Loss: 0.65786\n",
      "Epoch 025: | Train Loss: 0.65194 | Test Loss: 0.65742\n",
      "Epoch 026: | Train Loss: 0.65156 | Test Loss: 0.65728\n",
      "Epoch 027: | Train Loss: 0.65143 | Test Loss: 0.65757\n",
      "Epoch 028: | Train Loss: 0.65149 | Test Loss: 0.65787\n",
      "Epoch 029: | Train Loss: 0.65167 | Test Loss: 0.65757\n",
      "Epoch 030: | Train Loss: 0.65164 | Test Loss: 0.65716\n",
      "Epoch 031: | Train Loss: 0.65107 | Test Loss: 0.65733\n",
      "Epoch 032: | Train Loss: 0.65113 | Test Loss: 0.65768\n",
      "Epoch 033: | Train Loss: 0.65176 | Test Loss: 0.65751\n",
      "Epoch 034: | Train Loss: 0.65159 | Test Loss: 0.65738\n",
      "Epoch 035: | Train Loss: 0.65170 | Test Loss: 0.65754\n",
      "Epoch 036: | Train Loss: 0.65109 | Test Loss: 0.65715\n",
      "Epoch 037: | Train Loss: 0.65106 | Test Loss: 0.65755\n",
      "Epoch 038: | Train Loss: 0.65216 | Test Loss: 0.65768\n",
      "Epoch 039: | Train Loss: 0.65180 | Test Loss: 0.65704\n",
      "Epoch 040: | Train Loss: 0.65062 | Test Loss: 0.65783\n",
      "Epoch 041: | Train Loss: 0.65210 | Test Loss: 0.65753\n",
      "Epoch 042: | Train Loss: 0.65131 | Test Loss: 0.65789\n",
      "Epoch 043: | Train Loss: 0.65153 | Test Loss: 0.65801\n",
      "Epoch 044: | Train Loss: 0.65218 | Test Loss: 0.65740\n",
      "Epoch 045: | Train Loss: 0.65112 | Test Loss: 0.65776\n",
      "Epoch 046: | Train Loss: 0.65171 | Test Loss: 0.65720\n",
      "Epoch 047: | Train Loss: 0.65087 | Test Loss: 0.65767\n",
      "Epoch 048: | Train Loss: 0.65170 | Test Loss: 0.65760\n",
      "Epoch 049: | Train Loss: 0.65108 | Test Loss: 0.65749\n",
      "Epoch 050: | Train Loss: 0.65216 | Test Loss: 0.65755\n",
      "Epoch 051: | Train Loss: 0.65104 | Test Loss: 0.65752\n",
      "Epoch 052: | Train Loss: 0.65198 | Test Loss: 0.65764\n",
      "Epoch 053: | Train Loss: 0.65109 | Test Loss: 0.65725\n",
      "Epoch 054: | Train Loss: 0.65188 | Test Loss: 0.65744\n",
      "Epoch 055: | Train Loss: 0.65124 | Test Loss: 0.65769\n",
      "Epoch 056: | Train Loss: 0.65168 | Test Loss: 0.65768\n",
      "Epoch 057: | Train Loss: 0.65087 | Test Loss: 0.65773\n",
      "Epoch 058: | Train Loss: 0.65247 | Test Loss: 0.65724\n",
      "Epoch 059: | Train Loss: 0.65139 | Test Loss: 0.65672\n",
      "Epoch 060: | Train Loss: 0.65024 | Test Loss: 0.65779\n",
      "Epoch 061: | Train Loss: 0.65239 | Test Loss: 0.65778\n",
      "Epoch 062: | Train Loss: 0.65072 | Test Loss: 0.65771\n",
      "Epoch 063: | Train Loss: 0.65221 | Test Loss: 0.65738\n",
      "Epoch 064: | Train Loss: 0.65192 | Test Loss: 0.65707\n",
      "Epoch 065: | Train Loss: 0.65116 | Test Loss: 0.65731\n",
      "Epoch 066: | Train Loss: 0.65130 | Test Loss: 0.65752\n",
      "Epoch 067: | Train Loss: 0.65126 | Test Loss: 0.65782\n",
      "Epoch 068: | Train Loss: 0.65160 | Test Loss: 0.65788\n",
      "Epoch 069: | Train Loss: 0.65185 | Test Loss: 0.65757\n",
      "Epoch 070: | Train Loss: 0.65128 | Test Loss: 0.65761\n",
      "Epoch 071: | Train Loss: 0.65144 | Test Loss: 0.65740\n",
      "Epoch 072: | Train Loss: 0.65205 | Test Loss: 0.65787\n",
      "Epoch 073: | Train Loss: 0.65115 | Test Loss: 0.65763\n",
      "Epoch 074: | Train Loss: 0.65162 | Test Loss: 0.65735\n",
      "Epoch 075: | Train Loss: 0.65116 | Test Loss: 0.65726\n",
      "Epoch 076: | Train Loss: 0.65197 | Test Loss: 0.65715\n",
      "Epoch 077: | Train Loss: 0.65154 | Test Loss: 0.65797\n",
      "Epoch 078: | Train Loss: 0.65101 | Test Loss: 0.65725\n",
      "Epoch 079: | Train Loss: 0.65172 | Test Loss: 0.65755\n",
      "Epoch 080: | Train Loss: 0.65146 | Test Loss: 0.65719\n",
      "Epoch 081: | Train Loss: 0.65156 | Test Loss: 0.65787\n",
      "Epoch 082: | Train Loss: 0.65152 | Test Loss: 0.65722\n",
      "Epoch 083: | Train Loss: 0.65083 | Test Loss: 0.65784\n",
      "Epoch 084: | Train Loss: 0.65108 | Test Loss: 0.65801\n",
      "Epoch 085: | Train Loss: 0.65316 | Test Loss: 0.65706\n",
      "Epoch 086: | Train Loss: 0.65041 | Test Loss: 0.65695\n",
      "Epoch 087: | Train Loss: 0.65195 | Test Loss: 0.65805\n",
      "Epoch 088: | Train Loss: 0.65143 | Test Loss: 0.65711\n",
      "Epoch 089: | Train Loss: 0.65189 | Test Loss: 0.65708\n",
      "Epoch 090: | Train Loss: 0.65159 | Test Loss: 0.65707\n",
      "Epoch 091: | Train Loss: 0.65036 | Test Loss: 0.65738\n",
      "Epoch 092: | Train Loss: 0.65229 | Test Loss: 0.65803\n",
      "Epoch 093: | Train Loss: 0.65183 | Test Loss: 0.65697\n",
      "Epoch 094: | Train Loss: 0.65086 | Test Loss: 0.65765\n",
      "Epoch 095: | Train Loss: 0.65112 | Test Loss: 0.65779\n",
      "Epoch 096: | Train Loss: 0.65172 | Test Loss: 0.65791\n",
      "Epoch 097: | Train Loss: 0.65138 | Test Loss: 0.65772\n",
      "Epoch 098: | Train Loss: 0.65193 | Test Loss: 0.65766\n",
      "Epoch 099: | Train Loss: 0.65156 | Test Loss: 0.65782\n",
      "Epoch 100: | Train Loss: 0.65145 | Test Loss: 0.65721\n",
      "stats of l2reg of  1 are [0.85091 0.82991 0.65114 0.65721]\n",
      "full stats are [[1.000000e-04 8.509100e-01 8.299100e-01 8.962800e+00 1.004192e+01]\n",
      " [3.000000e-04 8.509100e-01 8.299100e-01 5.725400e-01 6.057300e-01]\n",
      " [1.000000e-03 8.990900e-01 8.771100e-01 3.397800e-01 4.136900e-01]\n",
      " [3.000000e-03 9.405900e-01 9.329700e-01 2.263600e-01 2.568400e-01]\n",
      " [1.000000e-02 9.468100e-01 9.406200e-01 2.061000e-01 2.393700e-01]\n",
      " [3.000000e-02 9.676800e-01 9.574200e-01 1.331000e-01 2.254000e-01]\n",
      " [1.000000e-01 9.405100e-01 9.379300e-01 2.533400e-01 2.817400e-01]\n",
      " [3.000000e-01 9.065700e-01 9.047800e-01 3.436400e-01 3.583300e-01]\n",
      " [1.000000e+00 8.509100e-01 8.299100e-01 6.511400e-01 6.572100e-01]]\n"
     ]
    }
   ],
   "source": [
    "regs=[0.0001,0.0003,0.001,0.003,0.01,0.03,0.1,0.3,1]\n",
    "stats_4cn=run_loop_torch(CNNBinary4,train_im_loader,test_im_loader,train_im_loader_pred,target_train,target_test,200,64,0.001,regs)\n",
    "np.savetxt(\"conv2d_4n_v1_gal_200.txt\",stats_4cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2200cdc",
   "metadata": {},
   "source": [
    "It now works sometimes (in run with 10), but lots of chance and not often. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cb08b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_4n_10=np.loadtxt(\"conv2d_4n_v1_gal_10.txt\")\n",
    "stats_4n_20=np.loadtxt(\"conv2d_4n_v1_gal_20.txt\")\n",
    "stats_4n_30=np.loadtxt(\"conv2d_4n_v1_gal_30.txt\")\n",
    "stats_4n_40=np.loadtxt(\"conv2d_4n_v1_gal_40.txt\")\n",
    "stats_4n_60=np.loadtxt(\"conv2d_4n_v1_gal_60.txt\")\n",
    "stats_4n_100=np.loadtxt(\"conv2d_4n_v1_gal_100.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "42e47699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stats_4n_10[0],stats_4n_10[1],label='conv2D train 10 epochs')\n",
    "plt.plot(stats_4n_10[0],stats_4n_10[2],label='conv2D test 10 epochs')\n",
    "plt.plot(stats_4n_20[0],stats_4n_20[1],label='conv2D train 20 epochs')\n",
    "plt.plot(stats_4n_20[0],stats_4n_20[2],label='conv2D test 20 epochs')\n",
    "plt.plot(stats_4n_30[0],stats_4n_30[1],label='conv2D train 30 epochs')\n",
    "plt.plot(stats_4n_30[0],stats_4n_30[2],label='conv2D test 30 epochs')\n",
    "plt.plot(stats_4n_40[0],stats_4n_40[1],label='conv2D train 40 epochs')\n",
    "plt.plot(stats_4n_40[0],stats_4n_40[2],label='conv2D test 40 epochs')\n",
    "plt.plot(stats_4n_60[0],stats_4n_60[1],label='conv2D train 60 epochs')\n",
    "plt.plot(stats_4n_60[0],stats_4n_60[2],label='conv2D test 60 epochs')\n",
    "#plt.plot(per_stats[0],per_stats[1],label='perceptron train')\n",
    "#plt.plot(per_stats[0],per_stats[2],label='perceptron test')\n",
    "#plt.plot(stats_xgb[0],stats_xgb[1],label='xgboost train')\n",
    "#plt.plot(stats_xgb[0],stats_xgb[2],label='xgboost test')\n",
    "#plt.plot(stats_log[0],stats_log[1],label='logistic train')\n",
    "#plt.plot(stats_log[0],stats_log[2],label='logistic test')\n",
    "plt.legend(loc=\"best\")\n",
    "#plt.title('Loss vs Epochs')\n",
    "plt.xlabel('l2 regularization')\n",
    "plt.ylabel('F1 score')\n",
    "#plt.ylim(0,0.7)\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "239d7c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stats_4n_10[0],stats_4n_10[3],label='conv2D train 10 epochs')\n",
    "plt.plot(stats_4n_10[0],stats_4n_10[4],label='conv2D test 10 epochs')\n",
    "plt.plot(stats_4n_20[0],stats_4n_20[3],label='conv2D train 20 epochs')\n",
    "plt.plot(stats_4n_20[0],stats_4n_20[4],label='conv2D test 20 epochs')\n",
    "plt.plot(stats_4n_30[0],stats_4n_30[3],label='conv2D train 30 epochs')\n",
    "plt.plot(stats_4n_30[0],stats_4n_30[4],label='conv2D test 30 epochs')\n",
    "plt.plot(stats_4n_40[0],stats_4n_40[3],label='conv2D train 40 epochs')\n",
    "plt.plot(stats_4n_40[0],stats_4n_40[4],label='conv2D test 40 epochs')\n",
    "plt.plot(stats_4n_60[0],stats_4n_60[3],label='conv2D train 60 epochs')\n",
    "plt.plot(stats_4n_60[0],stats_4n_60[4],label='conv2D test 60 epochs')\n",
    "#plt.plot(per_stats[0],per_stats[1],label='perceptron train')\n",
    "#plt.plot(per_stats[0],per_stats[2],label='perceptron test')\n",
    "#plt.plot(stats_xgb[0],stats_xgb[1],label='xgboost train')\n",
    "#plt.plot(stats_xgb[0],stats_xgb[2],label='xgboost test')\n",
    "#plt.plot(stats_log[0],stats_log[1],label='logistic train')\n",
    "#plt.plot(stats_log[0],stats_log[2],label='logistic test')\n",
    "plt.legend(loc=\"best\")\n",
    "#plt.title('Loss vs Epochs')\n",
    "plt.xlabel('l2 regularization')\n",
    "plt.ylabel('log loss')\n",
    "#plt.ylim(0,0.7)\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bfa99aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stats_4n_10[0],stats_4n_10[3],label='conv2D train 10 epochs')\n",
    "plt.plot(stats_4n_10[0],stats_4n_10[4],label='conv2D test 10 epochs')\n",
    "plt.plot(stats_4n_20[0],stats_4n_20[3],label='conv2D train 20 epochs')\n",
    "plt.plot(stats_4n_20[0],stats_4n_20[4],label='conv2D test 20 epochs')\n",
    "plt.plot(stats_4n_30[0],stats_4n_30[3],label='conv2D train 30 epochs')\n",
    "plt.plot(stats_4n_30[0],stats_4n_30[4],label='conv2D test 30 epochs')\n",
    "plt.plot(stats_4n_40[0],stats_4n_40[3],label='conv2D train 40 epochs')\n",
    "plt.plot(stats_4n_40[0],stats_4n_40[4],label='conv2D test 40 epochs')\n",
    "plt.plot(stats_4n_60[0],stats_4n_60[3],label='conv2D train 60 epochs')\n",
    "plt.plot(stats_4n_60[0],stats_4n_60[4],label='conv2D test 60 epochs')\n",
    "#plt.plot(per_stats[0],per_stats[1],label='perceptron train')\n",
    "#plt.plot(per_stats[0],per_stats[2],label='perceptron test')\n",
    "#plt.plot(stats_xgb[0],stats_xgb[1],label='xgboost train')\n",
    "#plt.plot(stats_xgb[0],stats_xgb[2],label='xgboost test')\n",
    "#plt.plot(stats_log[0],stats_log[1],label='logistic train')\n",
    "#plt.plot(stats_log[0],stats_log[2],label='logistic test')\n",
    "plt.legend(loc=\"best\")\n",
    "#plt.title('Loss vs Epochs')\n",
    "plt.xlabel('l2 regularization')\n",
    "plt.ylabel('log loss')\n",
    "plt.ylim(0,0.7)\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e2340e",
   "metadata": {},
   "source": [
    "Larger regularizations seem easier. Could I first converge them and then do lower regularization after them? \n",
    "Or just enough iterations? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9549db1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNBinary4(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=576, out_features=128, bias=True)\n",
      "  (layer4): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7354/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa9d55b2690473a871c35ed7ca1a029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 25.65726 | Test Loss: 29.07366\n",
      "Epoch 002: | Train Loss: 25.95486 | Test Loss: 29.07366\n",
      "Epoch 003: | Train Loss: 25.94246 | Test Loss: 28.88298\n",
      "Epoch 004: | Train Loss: 5.47718 | Test Loss: 0.59840\n",
      "Epoch 005: | Train Loss: 0.53514 | Test Loss: 0.64067\n",
      "Epoch 006: | Train Loss: 0.50466 | Test Loss: 0.48764\n",
      "Epoch 007: | Train Loss: 0.48186 | Test Loss: 0.47579\n",
      "Epoch 008: | Train Loss: 0.48006 | Test Loss: 0.44913\n",
      "Epoch 009: | Train Loss: 0.48922 | Test Loss: 0.44529\n",
      "Epoch 010: | Train Loss: 0.43970 | Test Loss: 0.43822\n",
      "Epoch 011: | Train Loss: 0.42329 | Test Loss: 0.46944\n",
      "Epoch 012: | Train Loss: 0.42354 | Test Loss: 0.45990\n",
      "Epoch 013: | Train Loss: 0.40717 | Test Loss: 0.41859\n",
      "Epoch 014: | Train Loss: 0.42246 | Test Loss: 0.56069\n",
      "Epoch 015: | Train Loss: 0.40527 | Test Loss: 0.55910\n",
      "Epoch 016: | Train Loss: 0.41832 | Test Loss: 0.41758\n",
      "Epoch 017: | Train Loss: 0.41731 | Test Loss: 0.52758\n",
      "Epoch 018: | Train Loss: 0.42020 | Test Loss: 0.39783\n",
      "Epoch 019: | Train Loss: 0.37445 | Test Loss: 0.44175\n",
      "Epoch 020: | Train Loss: 0.39780 | Test Loss: 0.40929\n"
     ]
    }
   ],
   "source": [
    "keep_prob=1\n",
    "model2d =CNNBinary4()\n",
    "model2d.to(device)\n",
    "print(model2d)\n",
    "loss_stats_st13c = {\n",
    "    'train': [], 'test': []\n",
    "}\n",
    "torch_fit(model2d,train_im_loader,test_im_loader,20,32,0.001,loss_stats_st13c,l2reg=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0fe35ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a2e4859f5b40db95ecb2ade9aa4d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.34432 | Test Loss: 0.38405\n",
      "Epoch 002: | Train Loss: 0.29512 | Test Loss: 0.35253\n",
      "Epoch 003: | Train Loss: 0.28508 | Test Loss: 0.35266\n",
      "Epoch 004: | Train Loss: 0.28737 | Test Loss: 0.33186\n",
      "Epoch 005: | Train Loss: 0.26562 | Test Loss: 0.38826\n",
      "Epoch 006: | Train Loss: 0.26077 | Test Loss: 0.33396\n",
      "Epoch 007: | Train Loss: 0.24928 | Test Loss: 0.31533\n",
      "Epoch 008: | Train Loss: 0.24441 | Test Loss: 0.35679\n",
      "Epoch 009: | Train Loss: 0.25514 | Test Loss: 0.33250\n",
      "Epoch 010: | Train Loss: 0.26221 | Test Loss: 0.25874\n",
      "Epoch 011: | Train Loss: 0.23147 | Test Loss: 0.25127\n",
      "Epoch 012: | Train Loss: 0.22445 | Test Loss: 0.23774\n",
      "Epoch 013: | Train Loss: 0.23151 | Test Loss: 0.24768\n",
      "Epoch 014: | Train Loss: 0.23545 | Test Loss: 0.22776\n",
      "Epoch 015: | Train Loss: 0.20923 | Test Loss: 0.26603\n",
      "Epoch 016: | Train Loss: 0.19086 | Test Loss: 0.21809\n",
      "Epoch 017: | Train Loss: 0.18970 | Test Loss: 0.21018\n",
      "Epoch 018: | Train Loss: 0.19626 | Test Loss: 0.21812\n",
      "Epoch 019: | Train Loss: 0.21395 | Test Loss: 0.27972\n",
      "Epoch 020: | Train Loss: 0.19461 | Test Loss: 0.23804\n"
     ]
    }
   ],
   "source": [
    "torch_fit(model2d,train_im_loader,test_im_loader,20,32,0.001,loss_stats_st13c,l2reg=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aaf790",
   "metadata": {},
   "outputs": [],
   "source": [
    "That works, thus I should implement that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a7810976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_loop_torch2(model,train,test,train_for_pred,train_target,test_target,epochs,batch,alpha,regs,num_features=0):\n",
    "    stats=np.zeros((5,len(regs)))\n",
    "    for i in range(len(regs)):\n",
    "        print(f\"running reg of {regs[i]}\")\n",
    "        keep_prob=1\n",
    "        if num_features==0:\n",
    "            model3 =model()\n",
    "        else:\n",
    "            #num_features partlz needed\n",
    "            model3 =model(num_features)            \n",
    "        model3.to(device)\n",
    "        loss_stats_test3 = {\n",
    "        'train': [], 'test': []\n",
    "        }\n",
    "        #first with large regularization \n",
    "        print(f\"initial run of high regularization\")\n",
    "        torch_fit(model3,train,test,20,batch,alpha,loss_stats_test3,l2reg=max(regs))\n",
    "        print(f\"run with given regularization\")\n",
    "        torch_fit(model3,train,test,epochs,batch,alpha,loss_stats_test3,l2reg=regs[i])\n",
    "        test_pred=pred_torch(model3,test)\n",
    "        train_pred=pred_torch(model3,train_for_pred)\n",
    "        stats[0,i]=regs[i]\n",
    "        stats[1,i]=f1_score(train_target,np.round(train_pred))\n",
    "        stats[2,i]=f1_score(test_target,np.round(test_pred))\n",
    "        stats[3,i]=log_loss(train_target,(train_pred))\n",
    "        stats[4,i]=log_loss(test_target,(test_pred))   \n",
    "        print(f\"stats of l2reg of  {regs[i]} are {np.round(stats[1:5,i],5)}\")\n",
    "    print(f\"full stats are {np.round(stats[:,:].T,5)}\")\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "76851470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running reg of 3e-05\n",
      "initial run of high regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16878/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b7d91ef8ed4cecb9b78872efab5498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 26.23077 | Test Loss: 27.61905\n",
      "Epoch 002: | Train Loss: 26.26086 | Test Loss: 27.61905\n",
      "Epoch 003: | Train Loss: 10.11268 | Test Loss: 0.52785\n",
      "Epoch 004: | Train Loss: 0.53887 | Test Loss: 0.60373\n",
      "Epoch 005: | Train Loss: 0.51998 | Test Loss: 0.50025\n",
      "Epoch 006: | Train Loss: 0.51324 | Test Loss: 0.47651\n",
      "Epoch 007: | Train Loss: 0.50408 | Test Loss: 0.49629\n",
      "Epoch 008: | Train Loss: 0.51884 | Test Loss: 0.47991\n",
      "Epoch 009: | Train Loss: 0.47978 | Test Loss: 0.49130\n",
      "Epoch 010: | Train Loss: 0.47841 | Test Loss: 0.58048\n",
      "Epoch 011: | Train Loss: 0.48058 | Test Loss: 0.48478\n",
      "Epoch 012: | Train Loss: 0.46706 | Test Loss: 0.47868\n",
      "Epoch 013: | Train Loss: 0.46301 | Test Loss: 0.46613\n",
      "Epoch 014: | Train Loss: 0.49075 | Test Loss: 0.52079\n",
      "Epoch 015: | Train Loss: 0.46417 | Test Loss: 0.46890\n",
      "Epoch 016: | Train Loss: 0.49001 | Test Loss: 0.46590\n",
      "Epoch 017: | Train Loss: 0.47945 | Test Loss: 0.43405\n",
      "Epoch 018: | Train Loss: 0.44392 | Test Loss: 0.45932\n",
      "Epoch 019: | Train Loss: 0.48397 | Test Loss: 0.51465\n",
      "Epoch 020: | Train Loss: 0.44960 | Test Loss: 0.43476\n",
      "run with given regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2aa6c91118427c8ae28505bb15c16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.48285 | Test Loss: 0.44416\n",
      "Epoch 002: | Train Loss: 0.37211 | Test Loss: 0.36691\n",
      "Epoch 003: | Train Loss: 0.33850 | Test Loss: 0.37037\n",
      "Epoch 004: | Train Loss: 0.32067 | Test Loss: 0.36935\n",
      "Epoch 005: | Train Loss: 0.31134 | Test Loss: 0.35627\n",
      "Epoch 006: | Train Loss: 0.32201 | Test Loss: 0.33267\n",
      "Epoch 007: | Train Loss: 0.30454 | Test Loss: 0.33951\n",
      "Epoch 008: | Train Loss: 0.28374 | Test Loss: 0.33473\n",
      "Epoch 009: | Train Loss: 0.28723 | Test Loss: 0.36818\n",
      "Epoch 010: | Train Loss: 0.27842 | Test Loss: 0.30702\n",
      "Epoch 011: | Train Loss: 0.26738 | Test Loss: 0.32089\n",
      "Epoch 012: | Train Loss: 0.27828 | Test Loss: 0.33380\n",
      "Epoch 013: | Train Loss: 0.26989 | Test Loss: 0.31109\n",
      "Epoch 014: | Train Loss: 0.26653 | Test Loss: 0.29231\n",
      "Epoch 015: | Train Loss: 0.25878 | Test Loss: 0.32198\n",
      "Epoch 016: | Train Loss: 0.25171 | Test Loss: 0.31767\n",
      "Epoch 017: | Train Loss: 0.22951 | Test Loss: 0.25958\n",
      "Epoch 018: | Train Loss: 0.21803 | Test Loss: 0.28297\n",
      "Epoch 019: | Train Loss: 0.22349 | Test Loss: 0.31841\n",
      "Epoch 020: | Train Loss: 0.21061 | Test Loss: 0.27407\n",
      "Epoch 021: | Train Loss: 0.20460 | Test Loss: 0.26678\n",
      "Epoch 022: | Train Loss: 0.20536 | Test Loss: 0.40603\n",
      "Epoch 023: | Train Loss: 0.20715 | Test Loss: 0.28918\n",
      "Epoch 024: | Train Loss: 0.21489 | Test Loss: 0.31292\n",
      "Epoch 025: | Train Loss: 0.19671 | Test Loss: 0.30233\n",
      "Epoch 026: | Train Loss: 0.19899 | Test Loss: 0.26960\n",
      "Epoch 027: | Train Loss: 0.19288 | Test Loss: 0.29112\n",
      "Epoch 028: | Train Loss: 0.19447 | Test Loss: 0.25959\n",
      "Epoch 029: | Train Loss: 0.18658 | Test Loss: 0.28918\n",
      "Epoch 030: | Train Loss: 0.18504 | Test Loss: 0.25823\n",
      "Epoch 031: | Train Loss: 0.18737 | Test Loss: 0.25856\n",
      "Epoch 032: | Train Loss: 0.18183 | Test Loss: 0.24326\n",
      "Epoch 033: | Train Loss: 0.17994 | Test Loss: 0.26877\n",
      "Epoch 034: | Train Loss: 0.17942 | Test Loss: 0.26251\n",
      "Epoch 035: | Train Loss: 0.17165 | Test Loss: 0.25556\n",
      "Epoch 036: | Train Loss: 0.17208 | Test Loss: 0.24886\n",
      "Epoch 037: | Train Loss: 0.17036 | Test Loss: 0.27487\n",
      "Epoch 038: | Train Loss: 0.17641 | Test Loss: 0.23917\n",
      "Epoch 039: | Train Loss: 0.16935 | Test Loss: 0.26427\n",
      "Epoch 040: | Train Loss: 0.16945 | Test Loss: 0.24526\n",
      "Epoch 041: | Train Loss: 0.16560 | Test Loss: 0.23316\n",
      "Epoch 042: | Train Loss: 0.15641 | Test Loss: 0.37281\n",
      "Epoch 043: | Train Loss: 0.16005 | Test Loss: 0.24629\n",
      "Epoch 044: | Train Loss: 0.14905 | Test Loss: 0.24083\n",
      "Epoch 045: | Train Loss: 0.14010 | Test Loss: 0.24833\n",
      "Epoch 046: | Train Loss: 0.13881 | Test Loss: 0.24107\n",
      "Epoch 047: | Train Loss: 0.13288 | Test Loss: 0.23157\n",
      "Epoch 048: | Train Loss: 0.17421 | Test Loss: 0.27536\n",
      "Epoch 049: | Train Loss: 0.13614 | Test Loss: 0.22519\n",
      "Epoch 050: | Train Loss: 0.13216 | Test Loss: 0.25403\n",
      "Epoch 051: | Train Loss: 0.13348 | Test Loss: 0.28619\n",
      "Epoch 052: | Train Loss: 0.13747 | Test Loss: 0.25854\n",
      "Epoch 053: | Train Loss: 0.13455 | Test Loss: 0.27541\n",
      "Epoch 054: | Train Loss: 0.12612 | Test Loss: 0.24236\n",
      "Epoch 055: | Train Loss: 0.12663 | Test Loss: 0.24149\n",
      "Epoch 056: | Train Loss: 0.16354 | Test Loss: 0.26992\n",
      "Epoch 057: | Train Loss: 0.14145 | Test Loss: 0.27592\n",
      "Epoch 058: | Train Loss: 0.12535 | Test Loss: 0.28655\n",
      "Epoch 059: | Train Loss: 0.13695 | Test Loss: 0.25676\n",
      "Epoch 060: | Train Loss: 0.12135 | Test Loss: 0.26917\n",
      "Epoch 061: | Train Loss: 0.12138 | Test Loss: 0.29598\n",
      "Epoch 062: | Train Loss: 0.12681 | Test Loss: 0.25089\n",
      "Epoch 063: | Train Loss: 0.11741 | Test Loss: 0.24867\n",
      "Epoch 064: | Train Loss: 0.12467 | Test Loss: 0.31848\n",
      "Epoch 065: | Train Loss: 0.12200 | Test Loss: 0.26828\n",
      "Epoch 066: | Train Loss: 0.11980 | Test Loss: 0.31592\n",
      "Epoch 067: | Train Loss: 0.11603 | Test Loss: 0.28763\n",
      "Epoch 068: | Train Loss: 0.11136 | Test Loss: 0.29150\n",
      "Epoch 069: | Train Loss: 0.11443 | Test Loss: 0.28853\n",
      "Epoch 070: | Train Loss: 0.11535 | Test Loss: 0.33856\n",
      "Epoch 071: | Train Loss: 0.11782 | Test Loss: 0.31149\n",
      "Epoch 072: | Train Loss: 0.12087 | Test Loss: 0.29559\n",
      "Epoch 073: | Train Loss: 0.11381 | Test Loss: 0.32859\n",
      "Epoch 074: | Train Loss: 0.11632 | Test Loss: 0.28315\n",
      "Epoch 075: | Train Loss: 0.11364 | Test Loss: 0.24895\n",
      "Epoch 076: | Train Loss: 0.12198 | Test Loss: 0.30584\n",
      "Epoch 077: | Train Loss: 0.11457 | Test Loss: 0.29394\n",
      "Epoch 078: | Train Loss: 0.11204 | Test Loss: 0.29228\n",
      "Epoch 079: | Train Loss: 0.11574 | Test Loss: 0.27050\n",
      "Epoch 080: | Train Loss: 0.11466 | Test Loss: 0.28634\n",
      "Epoch 081: | Train Loss: 0.10500 | Test Loss: 0.28014\n",
      "Epoch 082: | Train Loss: 0.10127 | Test Loss: 0.25631\n",
      "Epoch 083: | Train Loss: 0.09752 | Test Loss: 0.25649\n",
      "Epoch 084: | Train Loss: 0.09807 | Test Loss: 0.28118\n",
      "Epoch 085: | Train Loss: 0.09539 | Test Loss: 0.26093\n",
      "Epoch 086: | Train Loss: 0.10410 | Test Loss: 0.22758\n",
      "Epoch 087: | Train Loss: 0.10363 | Test Loss: 0.28037\n",
      "Epoch 088: | Train Loss: 0.10158 | Test Loss: 0.22571\n",
      "Epoch 089: | Train Loss: 0.10114 | Test Loss: 0.23842\n",
      "Epoch 090: | Train Loss: 0.10620 | Test Loss: 0.34542\n",
      "Epoch 091: | Train Loss: 0.09355 | Test Loss: 0.25956\n",
      "Epoch 092: | Train Loss: 0.09006 | Test Loss: 0.30555\n",
      "Epoch 093: | Train Loss: 0.18580 | Test Loss: 0.31880\n",
      "Epoch 094: | Train Loss: 0.12661 | Test Loss: 0.35520\n",
      "Epoch 095: | Train Loss: 0.10323 | Test Loss: 0.36786\n",
      "Epoch 096: | Train Loss: 0.09465 | Test Loss: 0.31748\n",
      "Epoch 097: | Train Loss: 0.09412 | Test Loss: 0.35565\n",
      "Epoch 098: | Train Loss: 0.08883 | Test Loss: 0.31311\n",
      "Epoch 099: | Train Loss: 0.08333 | Test Loss: 0.36668\n",
      "Epoch 100: | Train Loss: 0.08882 | Test Loss: 0.37017\n",
      "Epoch 101: | Train Loss: 0.08483 | Test Loss: 0.35589\n",
      "Epoch 102: | Train Loss: 0.11469 | Test Loss: 0.34790\n",
      "Epoch 103: | Train Loss: 0.09282 | Test Loss: 0.36449\n",
      "Epoch 104: | Train Loss: 0.10590 | Test Loss: 0.32451\n",
      "Epoch 105: | Train Loss: 0.08744 | Test Loss: 0.30051\n",
      "Epoch 106: | Train Loss: 0.08265 | Test Loss: 0.34065\n",
      "Epoch 107: | Train Loss: 0.08745 | Test Loss: 0.31769\n",
      "Epoch 108: | Train Loss: 0.09296 | Test Loss: 0.36137\n",
      "Epoch 109: | Train Loss: 0.08786 | Test Loss: 0.34351\n",
      "Epoch 110: | Train Loss: 0.08764 | Test Loss: 0.40797\n",
      "Epoch 111: | Train Loss: 0.08057 | Test Loss: 0.35485\n",
      "Epoch 112: | Train Loss: 0.08879 | Test Loss: 0.38730\n",
      "Epoch 113: | Train Loss: 0.10182 | Test Loss: 0.37766\n",
      "Epoch 114: | Train Loss: 0.08300 | Test Loss: 0.35097\n",
      "Epoch 115: | Train Loss: 0.08053 | Test Loss: 0.36400\n",
      "Epoch 116: | Train Loss: 0.08451 | Test Loss: 0.34072\n",
      "Epoch 117: | Train Loss: 0.08837 | Test Loss: 0.31290\n",
      "Epoch 118: | Train Loss: 0.07961 | Test Loss: 0.35353\n",
      "Epoch 119: | Train Loss: 0.08072 | Test Loss: 0.33998\n",
      "Epoch 120: | Train Loss: 0.08061 | Test Loss: 0.47896\n",
      "Epoch 121: | Train Loss: 0.15833 | Test Loss: 0.59872\n",
      "Epoch 122: | Train Loss: 0.07839 | Test Loss: 0.36120\n",
      "Epoch 123: | Train Loss: 0.07467 | Test Loss: 0.35190\n",
      "Epoch 124: | Train Loss: 0.06861 | Test Loss: 0.38298\n",
      "Epoch 125: | Train Loss: 0.07812 | Test Loss: 0.39297\n",
      "Epoch 126: | Train Loss: 0.08587 | Test Loss: 0.58858\n",
      "Epoch 127: | Train Loss: 0.07313 | Test Loss: 0.40135\n",
      "Epoch 128: | Train Loss: 0.07442 | Test Loss: 0.42231\n",
      "Epoch 129: | Train Loss: 0.07358 | Test Loss: 0.37794\n",
      "Epoch 130: | Train Loss: 0.07219 | Test Loss: 0.53702\n",
      "Epoch 131: | Train Loss: 0.07557 | Test Loss: 0.39582\n",
      "Epoch 132: | Train Loss: 0.08856 | Test Loss: 0.49672\n",
      "Epoch 133: | Train Loss: 0.07304 | Test Loss: 0.41686\n",
      "Epoch 134: | Train Loss: 0.06645 | Test Loss: 0.38778\n",
      "Epoch 135: | Train Loss: 0.07184 | Test Loss: 0.42829\n",
      "Epoch 136: | Train Loss: 0.07306 | Test Loss: 0.44654\n",
      "Epoch 137: | Train Loss: 0.07233 | Test Loss: 0.42262\n",
      "Epoch 138: | Train Loss: 0.07552 | Test Loss: 0.40997\n",
      "Epoch 139: | Train Loss: 0.08985 | Test Loss: 0.40322\n",
      "Epoch 140: | Train Loss: 0.06929 | Test Loss: 0.55771\n",
      "Epoch 141: | Train Loss: 0.07490 | Test Loss: 0.43650\n",
      "Epoch 142: | Train Loss: 0.06802 | Test Loss: 0.54532\n",
      "Epoch 143: | Train Loss: 0.06200 | Test Loss: 0.43655\n",
      "Epoch 144: | Train Loss: 0.07534 | Test Loss: 0.51751\n",
      "Epoch 145: | Train Loss: 0.06521 | Test Loss: 0.47134\n",
      "Epoch 146: | Train Loss: 0.06914 | Test Loss: 0.54543\n",
      "Epoch 147: | Train Loss: 0.06786 | Test Loss: 0.47655\n",
      "Epoch 148: | Train Loss: 0.13461 | Test Loss: 0.55281\n",
      "Epoch 149: | Train Loss: 0.09466 | Test Loss: 0.41577\n",
      "Epoch 150: | Train Loss: 0.06219 | Test Loss: 0.42920\n",
      "Epoch 151: | Train Loss: 0.06085 | Test Loss: 0.44734\n",
      "Epoch 152: | Train Loss: 0.06960 | Test Loss: 0.42195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: | Train Loss: 0.06052 | Test Loss: 0.55266\n",
      "Epoch 154: | Train Loss: 0.07337 | Test Loss: 0.46639\n",
      "Epoch 155: | Train Loss: 0.06823 | Test Loss: 0.46294\n",
      "Epoch 156: | Train Loss: 0.06158 | Test Loss: 0.47825\n",
      "Epoch 157: | Train Loss: 0.05891 | Test Loss: 0.47399\n",
      "Epoch 158: | Train Loss: 0.09166 | Test Loss: 0.52859\n",
      "Epoch 159: | Train Loss: 0.06898 | Test Loss: 0.50762\n",
      "Epoch 160: | Train Loss: 0.06915 | Test Loss: 0.46080\n",
      "Epoch 161: | Train Loss: 0.06226 | Test Loss: 0.51195\n",
      "Epoch 162: | Train Loss: 0.05957 | Test Loss: 0.50572\n",
      "Epoch 163: | Train Loss: 0.05830 | Test Loss: 0.45982\n",
      "Epoch 164: | Train Loss: 0.06382 | Test Loss: 0.54876\n",
      "Epoch 165: | Train Loss: 0.07820 | Test Loss: 0.54963\n",
      "Epoch 166: | Train Loss: 0.05773 | Test Loss: 0.52635\n",
      "Epoch 167: | Train Loss: 0.06454 | Test Loss: 0.49443\n",
      "Epoch 168: | Train Loss: 0.05483 | Test Loss: 0.54140\n",
      "Epoch 169: | Train Loss: 0.04877 | Test Loss: 0.59817\n",
      "Epoch 170: | Train Loss: 0.05913 | Test Loss: 0.59992\n",
      "Epoch 171: | Train Loss: 0.06881 | Test Loss: 0.39670\n",
      "Epoch 172: | Train Loss: 0.06781 | Test Loss: 0.39809\n",
      "Epoch 173: | Train Loss: 0.05902 | Test Loss: 0.55407\n",
      "Epoch 174: | Train Loss: 0.06293 | Test Loss: 0.58075\n",
      "Epoch 175: | Train Loss: 0.06536 | Test Loss: 0.46122\n",
      "Epoch 176: | Train Loss: 0.10167 | Test Loss: 0.61183\n",
      "Epoch 177: | Train Loss: 0.08650 | Test Loss: 0.46370\n",
      "Epoch 178: | Train Loss: 0.05864 | Test Loss: 0.46028\n",
      "Epoch 179: | Train Loss: 0.05993 | Test Loss: 0.50174\n",
      "Epoch 180: | Train Loss: 0.06293 | Test Loss: 0.56303\n",
      "Epoch 181: | Train Loss: 0.22187 | Test Loss: 0.55563\n",
      "Epoch 182: | Train Loss: 0.15281 | Test Loss: 0.38739\n",
      "Epoch 183: | Train Loss: 0.07157 | Test Loss: 0.46409\n",
      "Epoch 184: | Train Loss: 0.05817 | Test Loss: 0.50766\n",
      "Epoch 185: | Train Loss: 0.06595 | Test Loss: 0.68627\n",
      "Epoch 186: | Train Loss: 0.06440 | Test Loss: 0.50514\n",
      "Epoch 187: | Train Loss: 0.05424 | Test Loss: 0.55552\n",
      "Epoch 188: | Train Loss: 0.07478 | Test Loss: 0.50185\n",
      "Epoch 189: | Train Loss: 0.05371 | Test Loss: 0.54180\n",
      "Epoch 190: | Train Loss: 0.05090 | Test Loss: 0.60244\n",
      "Epoch 191: | Train Loss: 0.05143 | Test Loss: 0.63982\n",
      "Epoch 192: | Train Loss: 0.06586 | Test Loss: 0.72805\n",
      "Epoch 193: | Train Loss: 0.05153 | Test Loss: 0.56751\n",
      "Epoch 194: | Train Loss: 0.06005 | Test Loss: 0.55589\n",
      "Epoch 195: | Train Loss: 0.05040 | Test Loss: 0.58728\n",
      "Epoch 196: | Train Loss: 0.04667 | Test Loss: 0.64499\n",
      "Epoch 197: | Train Loss: 0.04984 | Test Loss: 0.68549\n",
      "Epoch 198: | Train Loss: 0.05056 | Test Loss: 0.61151\n",
      "Epoch 199: | Train Loss: 0.06481 | Test Loss: 0.71067\n",
      "Epoch 200: | Train Loss: 0.07635 | Test Loss: 0.49773\n",
      "Epoch 201: | Train Loss: 0.05555 | Test Loss: 0.53303\n",
      "Epoch 202: | Train Loss: 0.05224 | Test Loss: 0.62893\n",
      "Epoch 203: | Train Loss: 0.05700 | Test Loss: 0.63202\n",
      "Epoch 204: | Train Loss: 0.04829 | Test Loss: 0.64702\n",
      "Epoch 205: | Train Loss: 0.04707 | Test Loss: 0.72076\n",
      "Epoch 206: | Train Loss: 0.05239 | Test Loss: 0.79058\n",
      "Epoch 207: | Train Loss: 0.06931 | Test Loss: 0.63257\n",
      "Epoch 208: | Train Loss: 0.05560 | Test Loss: 0.58237\n",
      "Epoch 209: | Train Loss: 0.04874 | Test Loss: 0.59291\n",
      "Epoch 210: | Train Loss: 0.04961 | Test Loss: 0.77450\n",
      "Epoch 211: | Train Loss: 0.05990 | Test Loss: 0.60737\n",
      "Epoch 212: | Train Loss: 0.07049 | Test Loss: 0.66840\n",
      "Epoch 213: | Train Loss: 0.05548 | Test Loss: 0.63897\n",
      "Epoch 214: | Train Loss: 0.04817 | Test Loss: 0.66834\n",
      "Epoch 215: | Train Loss: 0.05792 | Test Loss: 0.57949\n",
      "Epoch 216: | Train Loss: 0.05516 | Test Loss: 0.67993\n",
      "Epoch 217: | Train Loss: 0.05385 | Test Loss: 0.68468\n",
      "Epoch 218: | Train Loss: 0.04563 | Test Loss: 0.71308\n",
      "Epoch 219: | Train Loss: 0.06517 | Test Loss: 0.85225\n",
      "Epoch 220: | Train Loss: 0.06280 | Test Loss: 0.67978\n",
      "Epoch 221: | Train Loss: 0.12302 | Test Loss: 0.61893\n",
      "Epoch 222: | Train Loss: 0.05462 | Test Loss: 0.63304\n",
      "Epoch 223: | Train Loss: 0.04994 | Test Loss: 0.63096\n",
      "Epoch 224: | Train Loss: 0.05173 | Test Loss: 0.69921\n",
      "Epoch 225: | Train Loss: 0.05776 | Test Loss: 0.74077\n",
      "Epoch 226: | Train Loss: 0.09783 | Test Loss: 0.62696\n",
      "Epoch 227: | Train Loss: 0.05755 | Test Loss: 0.68506\n",
      "Epoch 228: | Train Loss: 0.05591 | Test Loss: 0.71150\n",
      "Epoch 229: | Train Loss: 0.05916 | Test Loss: 0.74773\n",
      "Epoch 230: | Train Loss: 0.04905 | Test Loss: 0.79936\n",
      "Epoch 231: | Train Loss: 0.04735 | Test Loss: 0.77932\n",
      "Epoch 232: | Train Loss: 0.04610 | Test Loss: 0.88068\n",
      "Epoch 233: | Train Loss: 0.04326 | Test Loss: 0.81893\n",
      "Epoch 234: | Train Loss: 0.05619 | Test Loss: 0.82163\n",
      "Epoch 235: | Train Loss: 0.05921 | Test Loss: 0.65617\n",
      "Epoch 236: | Train Loss: 0.04633 | Test Loss: 0.73868\n",
      "Epoch 237: | Train Loss: 0.06377 | Test Loss: 0.69589\n",
      "Epoch 238: | Train Loss: 0.04723 | Test Loss: 0.72673\n",
      "Epoch 239: | Train Loss: 0.04910 | Test Loss: 0.72015\n",
      "Epoch 240: | Train Loss: 0.04487 | Test Loss: 0.77072\n",
      "stats of l2reg of  3e-05 are [0.99484 0.95057 0.02578 0.47746]\n",
      "running reg of 0.0001\n",
      "initial run of high regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16878/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e36259cf7d44e28943d88e9cb571598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 23.91195 | Test Loss: 0.77251\n",
      "Epoch 002: | Train Loss: 0.56933 | Test Loss: 0.51865\n",
      "Epoch 003: | Train Loss: 0.50357 | Test Loss: 0.48463\n",
      "Epoch 004: | Train Loss: 0.49805 | Test Loss: 0.47916\n",
      "Epoch 005: | Train Loss: 0.48823 | Test Loss: 0.47345\n",
      "Epoch 006: | Train Loss: 0.51314 | Test Loss: 0.46663\n",
      "Epoch 007: | Train Loss: 0.48762 | Test Loss: 0.50045\n",
      "Epoch 008: | Train Loss: 0.51011 | Test Loss: 0.44490\n",
      "Epoch 009: | Train Loss: 0.50252 | Test Loss: 0.43290\n",
      "Epoch 010: | Train Loss: 0.52906 | Test Loss: 0.47268\n",
      "Epoch 011: | Train Loss: 0.49535 | Test Loss: 0.44634\n",
      "Epoch 012: | Train Loss: 0.47883 | Test Loss: 0.50001\n",
      "Epoch 013: | Train Loss: 0.53189 | Test Loss: 0.67776\n",
      "Epoch 014: | Train Loss: 0.46601 | Test Loss: 0.46720\n",
      "Epoch 015: | Train Loss: 0.49420 | Test Loss: 0.47580\n",
      "Epoch 016: | Train Loss: 0.49603 | Test Loss: 0.54808\n",
      "Epoch 017: | Train Loss: 0.47412 | Test Loss: 0.40805\n",
      "Epoch 018: | Train Loss: 0.48926 | Test Loss: 0.90131\n",
      "Epoch 019: | Train Loss: 0.48797 | Test Loss: 0.45694\n",
      "Epoch 020: | Train Loss: 0.47362 | Test Loss: 0.43000\n",
      "run with given regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4184a2f0e4f1401e917da4ae5dbc814d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.49448 | Test Loss: 0.39597\n",
      "Epoch 002: | Train Loss: 0.41990 | Test Loss: 0.36687\n",
      "Epoch 003: | Train Loss: 0.35902 | Test Loss: 0.35594\n",
      "Epoch 004: | Train Loss: 0.37297 | Test Loss: 0.37037\n",
      "Epoch 005: | Train Loss: 0.34665 | Test Loss: 0.36055\n",
      "Epoch 006: | Train Loss: 0.34744 | Test Loss: 0.33530\n",
      "Epoch 007: | Train Loss: 0.34932 | Test Loss: 0.45234\n",
      "Epoch 008: | Train Loss: 0.31475 | Test Loss: 0.35904\n",
      "Epoch 009: | Train Loss: 0.30715 | Test Loss: 0.38146\n",
      "Epoch 010: | Train Loss: 0.30405 | Test Loss: 0.33672\n",
      "Epoch 011: | Train Loss: 0.30903 | Test Loss: 0.34489\n",
      "Epoch 012: | Train Loss: 0.31918 | Test Loss: 0.33338\n",
      "Epoch 013: | Train Loss: 0.27639 | Test Loss: 0.28479\n",
      "Epoch 014: | Train Loss: 0.24772 | Test Loss: 0.23064\n",
      "Epoch 015: | Train Loss: 0.25314 | Test Loss: 0.24044\n",
      "Epoch 016: | Train Loss: 0.24396 | Test Loss: 0.21789\n",
      "Epoch 017: | Train Loss: 0.22588 | Test Loss: 0.20750\n",
      "Epoch 018: | Train Loss: 0.20319 | Test Loss: 0.21934\n",
      "Epoch 019: | Train Loss: 0.19167 | Test Loss: 0.18355\n",
      "Epoch 020: | Train Loss: 0.19272 | Test Loss: 0.19521\n",
      "Epoch 021: | Train Loss: 0.16434 | Test Loss: 0.19331\n",
      "Epoch 022: | Train Loss: 0.14563 | Test Loss: 0.18258\n",
      "Epoch 023: | Train Loss: 0.20791 | Test Loss: 0.18683\n",
      "Epoch 024: | Train Loss: 0.16379 | Test Loss: 0.18968\n",
      "Epoch 025: | Train Loss: 0.15918 | Test Loss: 0.19773\n",
      "Epoch 026: | Train Loss: 0.14706 | Test Loss: 0.17738\n",
      "Epoch 027: | Train Loss: 0.13798 | Test Loss: 0.16653\n",
      "Epoch 028: | Train Loss: 0.13041 | Test Loss: 0.16751\n",
      "Epoch 029: | Train Loss: 0.12619 | Test Loss: 0.16656\n",
      "Epoch 030: | Train Loss: 0.13452 | Test Loss: 0.17601\n",
      "Epoch 031: | Train Loss: 0.12883 | Test Loss: 0.16954\n",
      "Epoch 032: | Train Loss: 0.12429 | Test Loss: 0.18429\n",
      "Epoch 033: | Train Loss: 0.11263 | Test Loss: 0.17035\n",
      "Epoch 034: | Train Loss: 0.11450 | Test Loss: 0.19221\n",
      "Epoch 035: | Train Loss: 0.13175 | Test Loss: 0.17034\n",
      "Epoch 036: | Train Loss: 0.12090 | Test Loss: 0.14760\n",
      "Epoch 037: | Train Loss: 0.13232 | Test Loss: 0.17582\n",
      "Epoch 038: | Train Loss: 0.12668 | Test Loss: 0.15406\n",
      "Epoch 039: | Train Loss: 0.10685 | Test Loss: 0.16303\n",
      "Epoch 040: | Train Loss: 0.10823 | Test Loss: 0.16423\n",
      "Epoch 041: | Train Loss: 0.11714 | Test Loss: 0.15218\n",
      "Epoch 042: | Train Loss: 0.10730 | Test Loss: 0.16128\n",
      "Epoch 043: | Train Loss: 0.11064 | Test Loss: 0.16557\n",
      "Epoch 044: | Train Loss: 0.11501 | Test Loss: 0.37026\n",
      "Epoch 045: | Train Loss: 0.10866 | Test Loss: 0.15810\n",
      "Epoch 046: | Train Loss: 0.12475 | Test Loss: 0.18043\n",
      "Epoch 047: | Train Loss: 0.11070 | Test Loss: 0.14118\n",
      "Epoch 048: | Train Loss: 0.09796 | Test Loss: 0.15393\n",
      "Epoch 049: | Train Loss: 0.09645 | Test Loss: 0.15057\n",
      "Epoch 050: | Train Loss: 0.10936 | Test Loss: 0.14145\n",
      "Epoch 051: | Train Loss: 0.10260 | Test Loss: 0.14937\n",
      "Epoch 052: | Train Loss: 0.11853 | Test Loss: 0.16575\n",
      "Epoch 053: | Train Loss: 0.10659 | Test Loss: 0.14238\n",
      "Epoch 054: | Train Loss: 0.09353 | Test Loss: 0.15343\n",
      "Epoch 055: | Train Loss: 0.09624 | Test Loss: 0.15033\n",
      "Epoch 056: | Train Loss: 0.10319 | Test Loss: 0.17447\n",
      "Epoch 057: | Train Loss: 0.09883 | Test Loss: 0.18434\n",
      "Epoch 058: | Train Loss: 0.11388 | Test Loss: 0.13722\n",
      "Epoch 059: | Train Loss: 0.08548 | Test Loss: 0.14153\n",
      "Epoch 060: | Train Loss: 0.08503 | Test Loss: 0.17484\n",
      "Epoch 061: | Train Loss: 0.08359 | Test Loss: 0.15922\n",
      "Epoch 062: | Train Loss: 0.07686 | Test Loss: 0.15103\n",
      "Epoch 063: | Train Loss: 0.08082 | Test Loss: 0.15635\n",
      "Epoch 064: | Train Loss: 0.08014 | Test Loss: 0.15760\n",
      "Epoch 065: | Train Loss: 0.10269 | Test Loss: 0.22111\n",
      "Epoch 066: | Train Loss: 0.09554 | Test Loss: 0.15417\n",
      "Epoch 067: | Train Loss: 0.08197 | Test Loss: 0.16120\n",
      "Epoch 068: | Train Loss: 0.08458 | Test Loss: 0.17454\n",
      "Epoch 069: | Train Loss: 0.07752 | Test Loss: 0.17082\n",
      "Epoch 070: | Train Loss: 0.08494 | Test Loss: 0.15036\n",
      "Epoch 071: | Train Loss: 0.09261 | Test Loss: 0.20380\n",
      "Epoch 072: | Train Loss: 0.07855 | Test Loss: 0.15100\n",
      "Epoch 073: | Train Loss: 0.07498 | Test Loss: 0.15108\n",
      "Epoch 074: | Train Loss: 0.07396 | Test Loss: 0.15163\n",
      "Epoch 075: | Train Loss: 0.06615 | Test Loss: 0.16603\n",
      "Epoch 076: | Train Loss: 0.07084 | Test Loss: 0.16857\n",
      "Epoch 077: | Train Loss: 0.06505 | Test Loss: 0.16994\n",
      "Epoch 078: | Train Loss: 0.06536 | Test Loss: 0.20195\n",
      "Epoch 079: | Train Loss: 0.06988 | Test Loss: 0.15537\n",
      "Epoch 080: | Train Loss: 0.06458 | Test Loss: 0.16477\n",
      "Epoch 081: | Train Loss: 0.09710 | Test Loss: 0.17000\n",
      "Epoch 082: | Train Loss: 0.06947 | Test Loss: 0.15776\n",
      "Epoch 083: | Train Loss: 0.07062 | Test Loss: 0.18048\n",
      "Epoch 084: | Train Loss: 0.07199 | Test Loss: 0.16667\n",
      "Epoch 085: | Train Loss: 0.06897 | Test Loss: 0.20821\n",
      "Epoch 086: | Train Loss: 0.05191 | Test Loss: 0.23282\n",
      "Epoch 087: | Train Loss: 0.05370 | Test Loss: 0.19945\n",
      "Epoch 088: | Train Loss: 0.06855 | Test Loss: 0.19990\n",
      "Epoch 089: | Train Loss: 0.05127 | Test Loss: 0.19726\n",
      "Epoch 090: | Train Loss: 0.05635 | Test Loss: 0.20862\n",
      "Epoch 091: | Train Loss: 0.05218 | Test Loss: 0.21256\n",
      "Epoch 092: | Train Loss: 0.04636 | Test Loss: 0.24203\n",
      "Epoch 093: | Train Loss: 0.05094 | Test Loss: 0.21909\n",
      "Epoch 094: | Train Loss: 0.04839 | Test Loss: 0.36249\n",
      "Epoch 095: | Train Loss: 0.10736 | Test Loss: 0.21348\n",
      "Epoch 096: | Train Loss: 0.05724 | Test Loss: 0.18208\n",
      "Epoch 097: | Train Loss: 0.05037 | Test Loss: 0.19897\n",
      "Epoch 098: | Train Loss: 0.04737 | Test Loss: 0.20492\n",
      "Epoch 099: | Train Loss: 0.04498 | Test Loss: 0.20049\n",
      "Epoch 100: | Train Loss: 0.04906 | Test Loss: 0.20957\n",
      "Epoch 101: | Train Loss: 0.08180 | Test Loss: 0.22675\n",
      "Epoch 102: | Train Loss: 0.05655 | Test Loss: 0.28407\n",
      "Epoch 103: | Train Loss: 0.05319 | Test Loss: 0.17364\n",
      "Epoch 104: | Train Loss: 0.05284 | Test Loss: 0.17758\n",
      "Epoch 105: | Train Loss: 0.04597 | Test Loss: 0.20594\n",
      "Epoch 106: | Train Loss: 0.04453 | Test Loss: 0.20112\n",
      "Epoch 107: | Train Loss: 0.04802 | Test Loss: 0.25201\n",
      "Epoch 108: | Train Loss: 0.05472 | Test Loss: 0.22062\n",
      "Epoch 109: | Train Loss: 0.03733 | Test Loss: 0.21338\n",
      "Epoch 110: | Train Loss: 0.03532 | Test Loss: 0.25344\n",
      "Epoch 111: | Train Loss: 0.05311 | Test Loss: 0.24043\n",
      "Epoch 112: | Train Loss: 0.04576 | Test Loss: 0.21007\n",
      "Epoch 113: | Train Loss: 0.05460 | Test Loss: 0.20038\n",
      "Epoch 114: | Train Loss: 0.05500 | Test Loss: 0.20005\n",
      "Epoch 115: | Train Loss: 0.03564 | Test Loss: 0.20052\n",
      "Epoch 116: | Train Loss: 0.04361 | Test Loss: 0.20680\n",
      "Epoch 117: | Train Loss: 0.04889 | Test Loss: 0.21172\n",
      "Epoch 118: | Train Loss: 0.03122 | Test Loss: 0.23508\n",
      "Epoch 119: | Train Loss: 0.02972 | Test Loss: 0.23509\n",
      "Epoch 120: | Train Loss: 0.02794 | Test Loss: 0.25072\n",
      "Epoch 121: | Train Loss: 0.02687 | Test Loss: 0.29865\n",
      "Epoch 122: | Train Loss: 0.08833 | Test Loss: 0.26020\n",
      "Epoch 123: | Train Loss: 0.04292 | Test Loss: 0.26129\n",
      "Epoch 124: | Train Loss: 0.03114 | Test Loss: 0.24381\n",
      "Epoch 125: | Train Loss: 0.03321 | Test Loss: 0.27192\n",
      "Epoch 126: | Train Loss: 0.05396 | Test Loss: 0.26426\n",
      "Epoch 127: | Train Loss: 0.03791 | Test Loss: 0.31115\n",
      "Epoch 128: | Train Loss: 0.02693 | Test Loss: 0.29302\n",
      "Epoch 129: | Train Loss: 0.02923 | Test Loss: 0.40988\n",
      "Epoch 130: | Train Loss: 0.03731 | Test Loss: 0.24748\n",
      "Epoch 131: | Train Loss: 0.02495 | Test Loss: 0.24940\n",
      "Epoch 132: | Train Loss: 0.02257 | Test Loss: 0.32478\n",
      "Epoch 133: | Train Loss: 0.02372 | Test Loss: 0.85866\n",
      "Epoch 134: | Train Loss: 0.03839 | Test Loss: 0.40107\n",
      "Epoch 135: | Train Loss: 0.20075 | Test Loss: 0.25334\n",
      "Epoch 136: | Train Loss: 0.05199 | Test Loss: 0.30365\n",
      "Epoch 137: | Train Loss: 0.06315 | Test Loss: 0.25264\n",
      "Epoch 138: | Train Loss: 0.02800 | Test Loss: 0.27756\n",
      "Epoch 139: | Train Loss: 0.03497 | Test Loss: 0.22564\n",
      "Epoch 140: | Train Loss: 0.01927 | Test Loss: 0.28833\n",
      "Epoch 141: | Train Loss: 0.02093 | Test Loss: 0.25192\n",
      "Epoch 142: | Train Loss: 0.02423 | Test Loss: 0.30331\n",
      "Epoch 143: | Train Loss: 0.02495 | Test Loss: 0.36472\n",
      "Epoch 144: | Train Loss: 0.01949 | Test Loss: 0.37234\n",
      "Epoch 145: | Train Loss: 0.02152 | Test Loss: 0.37192\n",
      "Epoch 146: | Train Loss: 0.03390 | Test Loss: 0.39648\n",
      "Epoch 147: | Train Loss: 0.05197 | Test Loss: 0.34022\n",
      "Epoch 148: | Train Loss: 0.05885 | Test Loss: 0.24569\n",
      "Epoch 149: | Train Loss: 0.02521 | Test Loss: 0.24684\n",
      "Epoch 150: | Train Loss: 0.01464 | Test Loss: 0.28398\n",
      "Epoch 151: | Train Loss: 0.02177 | Test Loss: 0.29864\n",
      "Epoch 152: | Train Loss: 0.01541 | Test Loss: 0.41276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: | Train Loss: 0.01506 | Test Loss: 0.34073\n",
      "Epoch 154: | Train Loss: 0.04895 | Test Loss: 0.52345\n",
      "Epoch 155: | Train Loss: 0.05269 | Test Loss: 0.29384\n",
      "Epoch 156: | Train Loss: 0.03073 | Test Loss: 0.56788\n",
      "Epoch 157: | Train Loss: 0.02544 | Test Loss: 0.33872\n",
      "Epoch 158: | Train Loss: 0.03684 | Test Loss: 0.32201\n",
      "Epoch 159: | Train Loss: 0.02476 | Test Loss: 0.54290\n",
      "Epoch 160: | Train Loss: 0.02519 | Test Loss: 0.34897\n",
      "Epoch 161: | Train Loss: 0.01949 | Test Loss: 0.33454\n",
      "Epoch 162: | Train Loss: 0.01556 | Test Loss: 0.31469\n",
      "Epoch 163: | Train Loss: 0.04231 | Test Loss: 0.45965\n",
      "Epoch 164: | Train Loss: 0.04253 | Test Loss: 0.47917\n",
      "Epoch 165: | Train Loss: 0.02596 | Test Loss: 0.31768\n",
      "Epoch 166: | Train Loss: 0.01793 | Test Loss: 0.32013\n",
      "Epoch 167: | Train Loss: 0.03374 | Test Loss: 0.40846\n",
      "Epoch 168: | Train Loss: 0.01876 | Test Loss: 0.46266\n",
      "Epoch 169: | Train Loss: 0.02464 | Test Loss: 0.37820\n",
      "Epoch 170: | Train Loss: 0.03316 | Test Loss: 0.36891\n",
      "Epoch 171: | Train Loss: 0.02265 | Test Loss: 0.34495\n",
      "Epoch 172: | Train Loss: 0.01501 | Test Loss: 0.31426\n",
      "Epoch 173: | Train Loss: 0.01123 | Test Loss: 0.46461\n",
      "Epoch 174: | Train Loss: 0.06189 | Test Loss: 0.29288\n",
      "Epoch 175: | Train Loss: 0.01366 | Test Loss: 0.38879\n",
      "Epoch 176: | Train Loss: 0.01695 | Test Loss: 0.52645\n",
      "Epoch 177: | Train Loss: 0.09242 | Test Loss: 0.25247\n",
      "Epoch 178: | Train Loss: 0.02909 | Test Loss: 0.29448\n",
      "Epoch 179: | Train Loss: 0.01751 | Test Loss: 0.36908\n",
      "Epoch 180: | Train Loss: 0.01118 | Test Loss: 0.37968\n",
      "Epoch 181: | Train Loss: 0.00966 | Test Loss: 0.42029\n",
      "Epoch 182: | Train Loss: 0.00984 | Test Loss: 0.37853\n",
      "Epoch 183: | Train Loss: 0.00665 | Test Loss: 0.45587\n",
      "Epoch 184: | Train Loss: 0.02085 | Test Loss: 0.48415\n",
      "Epoch 185: | Train Loss: 0.11430 | Test Loss: 0.37343\n",
      "Epoch 186: | Train Loss: 0.05244 | Test Loss: 0.30721\n",
      "Epoch 187: | Train Loss: 0.01775 | Test Loss: 0.27224\n",
      "Epoch 188: | Train Loss: 0.03457 | Test Loss: 0.37502\n",
      "Epoch 189: | Train Loss: 0.07438 | Test Loss: 0.29003\n",
      "Epoch 190: | Train Loss: 0.02618 | Test Loss: 0.30315\n",
      "Epoch 191: | Train Loss: 0.05416 | Test Loss: 0.27262\n",
      "Epoch 192: | Train Loss: 0.02298 | Test Loss: 0.30315\n",
      "Epoch 193: | Train Loss: 0.01374 | Test Loss: 0.34785\n",
      "Epoch 194: | Train Loss: 0.00902 | Test Loss: 0.37655\n",
      "Epoch 195: | Train Loss: 0.01185 | Test Loss: 0.39856\n",
      "Epoch 196: | Train Loss: 0.03061 | Test Loss: 0.33849\n",
      "Epoch 197: | Train Loss: 0.02029 | Test Loss: 0.53715\n",
      "Epoch 198: | Train Loss: 0.03831 | Test Loss: 0.35076\n",
      "Epoch 199: | Train Loss: 0.05505 | Test Loss: 0.52533\n",
      "Epoch 200: | Train Loss: 0.04532 | Test Loss: 0.32388\n",
      "Epoch 201: | Train Loss: 0.01137 | Test Loss: 0.30386\n",
      "Epoch 202: | Train Loss: 0.01149 | Test Loss: 0.33442\n",
      "Epoch 203: | Train Loss: 0.00670 | Test Loss: 0.35741\n",
      "Epoch 204: | Train Loss: 0.00678 | Test Loss: 0.37187\n",
      "Epoch 205: | Train Loss: 0.21548 | Test Loss: 0.24810\n",
      "Epoch 206: | Train Loss: 0.05276 | Test Loss: 0.24320\n",
      "Epoch 207: | Train Loss: 0.04394 | Test Loss: 0.24224\n",
      "Epoch 208: | Train Loss: 0.04075 | Test Loss: 0.28129\n",
      "Epoch 209: | Train Loss: 0.03286 | Test Loss: 0.26950\n",
      "Epoch 210: | Train Loss: 0.03062 | Test Loss: 0.30122\n",
      "Epoch 211: | Train Loss: 0.01183 | Test Loss: 0.56721\n",
      "Epoch 212: | Train Loss: 0.01249 | Test Loss: 0.36397\n",
      "Epoch 213: | Train Loss: 0.01076 | Test Loss: 0.32924\n",
      "Epoch 214: | Train Loss: 0.00647 | Test Loss: 0.53755\n",
      "Epoch 215: | Train Loss: 0.01798 | Test Loss: 0.99853\n",
      "Epoch 216: | Train Loss: 0.10219 | Test Loss: 0.25221\n",
      "Epoch 217: | Train Loss: 0.02696 | Test Loss: 0.25194\n",
      "Epoch 218: | Train Loss: 0.01490 | Test Loss: 0.25716\n",
      "Epoch 219: | Train Loss: 0.00917 | Test Loss: 0.26259\n",
      "Epoch 220: | Train Loss: 0.00812 | Test Loss: 0.34999\n",
      "Epoch 221: | Train Loss: 0.00714 | Test Loss: 0.31697\n",
      "Epoch 222: | Train Loss: 0.01170 | Test Loss: 0.55938\n",
      "Epoch 223: | Train Loss: 0.02692 | Test Loss: 0.31989\n",
      "Epoch 224: | Train Loss: 0.03287 | Test Loss: 0.38297\n",
      "Epoch 225: | Train Loss: 0.00891 | Test Loss: 0.33783\n",
      "Epoch 226: | Train Loss: 0.01334 | Test Loss: 0.37986\n",
      "Epoch 227: | Train Loss: 0.00772 | Test Loss: 0.64158\n",
      "Epoch 228: | Train Loss: 0.00649 | Test Loss: 0.48461\n",
      "Epoch 229: | Train Loss: 0.01136 | Test Loss: 0.55469\n",
      "Epoch 230: | Train Loss: 0.09026 | Test Loss: 0.31915\n",
      "Epoch 231: | Train Loss: 0.03991 | Test Loss: 0.26777\n",
      "Epoch 232: | Train Loss: 0.02570 | Test Loss: 0.28569\n",
      "Epoch 233: | Train Loss: 0.01691 | Test Loss: 0.30994\n",
      "Epoch 234: | Train Loss: 0.01139 | Test Loss: 0.34297\n",
      "Epoch 235: | Train Loss: 0.01200 | Test Loss: 0.32295\n",
      "Epoch 236: | Train Loss: 0.05876 | Test Loss: 0.40258\n",
      "Epoch 237: | Train Loss: 0.03977 | Test Loss: 0.43887\n",
      "Epoch 238: | Train Loss: 0.04211 | Test Loss: 0.48659\n",
      "Epoch 239: | Train Loss: 0.03566 | Test Loss: 0.51632\n",
      "Epoch 240: | Train Loss: 0.03534 | Test Loss: 0.34911\n",
      "stats of l2reg of  0.0001 are [0.99828 0.96614 0.01513 0.28561]\n",
      "running reg of 0.0003\n",
      "initial run of high regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16878/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512337a45bd4476f98a53718f0e90ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 26.12576 | Test Loss: 27.61905\n",
      "Epoch 002: | Train Loss: 6.90554 | Test Loss: 0.55893\n",
      "Epoch 003: | Train Loss: 0.50555 | Test Loss: 0.50964\n",
      "Epoch 004: | Train Loss: 0.52986 | Test Loss: 0.69915\n",
      "Epoch 005: | Train Loss: 0.54807 | Test Loss: 0.56254\n",
      "Epoch 006: | Train Loss: 0.49906 | Test Loss: 0.47013\n",
      "Epoch 007: | Train Loss: 0.49844 | Test Loss: 0.52186\n",
      "Epoch 008: | Train Loss: 0.55548 | Test Loss: 0.49484\n",
      "Epoch 009: | Train Loss: 0.49000 | Test Loss: 0.45572\n",
      "Epoch 010: | Train Loss: 0.50753 | Test Loss: 0.71128\n",
      "Epoch 011: | Train Loss: 0.48592 | Test Loss: 0.43534\n",
      "Epoch 012: | Train Loss: 0.50324 | Test Loss: 0.44418\n",
      "Epoch 013: | Train Loss: 0.48480 | Test Loss: 0.42170\n",
      "Epoch 014: | Train Loss: 0.48815 | Test Loss: 0.44349\n",
      "Epoch 015: | Train Loss: 0.47275 | Test Loss: 0.42115\n",
      "Epoch 016: | Train Loss: 0.47222 | Test Loss: 0.43051\n",
      "Epoch 017: | Train Loss: 0.48644 | Test Loss: 0.42924\n",
      "Epoch 018: | Train Loss: 0.46068 | Test Loss: 0.42059\n",
      "Epoch 019: | Train Loss: 0.45555 | Test Loss: 0.40598\n",
      "Epoch 020: | Train Loss: 0.44895 | Test Loss: 0.39830\n",
      "run with given regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa3db558e6f4e66a8c5fe87abe64c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.46672 | Test Loss: 0.38467\n",
      "Epoch 002: | Train Loss: 0.43127 | Test Loss: 0.38492\n",
      "Epoch 003: | Train Loss: 0.39928 | Test Loss: 0.35829\n",
      "Epoch 004: | Train Loss: 0.37884 | Test Loss: 0.39703\n",
      "Epoch 005: | Train Loss: 0.36335 | Test Loss: 0.33864\n",
      "Epoch 006: | Train Loss: 0.35174 | Test Loss: 0.32787\n",
      "Epoch 007: | Train Loss: 0.35117 | Test Loss: 0.38087\n",
      "Epoch 008: | Train Loss: 0.30404 | Test Loss: 0.32008\n",
      "Epoch 009: | Train Loss: 0.30467 | Test Loss: 0.33830\n",
      "Epoch 010: | Train Loss: 0.32308 | Test Loss: 0.30729\n",
      "Epoch 011: | Train Loss: 0.28049 | Test Loss: 0.30025\n",
      "Epoch 012: | Train Loss: 0.27173 | Test Loss: 0.26198\n",
      "Epoch 013: | Train Loss: 0.26114 | Test Loss: 0.27122\n",
      "Epoch 014: | Train Loss: 0.23998 | Test Loss: 0.23358\n",
      "Epoch 015: | Train Loss: 0.20623 | Test Loss: 0.26460\n",
      "Epoch 016: | Train Loss: 0.25096 | Test Loss: 0.23119\n",
      "Epoch 017: | Train Loss: 0.19792 | Test Loss: 0.20863\n",
      "Epoch 018: | Train Loss: 0.21741 | Test Loss: 0.19684\n",
      "Epoch 019: | Train Loss: 0.18203 | Test Loss: 0.18726\n",
      "Epoch 020: | Train Loss: 0.19749 | Test Loss: 0.20295\n",
      "Epoch 021: | Train Loss: 0.17590 | Test Loss: 0.17962\n",
      "Epoch 022: | Train Loss: 0.16996 | Test Loss: 0.18543\n",
      "Epoch 023: | Train Loss: 0.20252 | Test Loss: 0.31840\n",
      "Epoch 024: | Train Loss: 0.19257 | Test Loss: 0.17413\n",
      "Epoch 025: | Train Loss: 0.16280 | Test Loss: 0.16975\n",
      "Epoch 026: | Train Loss: 0.16786 | Test Loss: 0.17128\n",
      "Epoch 027: | Train Loss: 0.16310 | Test Loss: 0.18370\n",
      "Epoch 028: | Train Loss: 0.16022 | Test Loss: 0.17641\n",
      "Epoch 029: | Train Loss: 0.15615 | Test Loss: 0.17237\n",
      "Epoch 030: | Train Loss: 0.15424 | Test Loss: 0.16927\n",
      "Epoch 031: | Train Loss: 0.15439 | Test Loss: 0.16962\n",
      "Epoch 032: | Train Loss: 0.14782 | Test Loss: 0.22131\n",
      "Epoch 033: | Train Loss: 0.15026 | Test Loss: 0.17185\n",
      "Epoch 034: | Train Loss: 0.13216 | Test Loss: 0.16823\n",
      "Epoch 035: | Train Loss: 0.13885 | Test Loss: 0.17117\n",
      "Epoch 036: | Train Loss: 0.14558 | Test Loss: 0.17205\n",
      "Epoch 037: | Train Loss: 0.14605 | Test Loss: 0.18242\n",
      "Epoch 038: | Train Loss: 0.15090 | Test Loss: 0.16637\n",
      "Epoch 039: | Train Loss: 0.14193 | Test Loss: 0.16477\n",
      "Epoch 040: | Train Loss: 0.15053 | Test Loss: 0.18247\n",
      "Epoch 041: | Train Loss: 0.11870 | Test Loss: 0.16232\n",
      "Epoch 042: | Train Loss: 0.12520 | Test Loss: 0.17255\n",
      "Epoch 043: | Train Loss: 0.14206 | Test Loss: 0.16664\n",
      "Epoch 044: | Train Loss: 0.13323 | Test Loss: 0.16583\n",
      "Epoch 045: | Train Loss: 0.13588 | Test Loss: 0.14404\n",
      "Epoch 046: | Train Loss: 0.15059 | Test Loss: 0.16876\n",
      "Epoch 047: | Train Loss: 0.14160 | Test Loss: 0.14737\n",
      "Epoch 048: | Train Loss: 0.10971 | Test Loss: 0.16194\n",
      "Epoch 049: | Train Loss: 0.12774 | Test Loss: 0.16508\n",
      "Epoch 050: | Train Loss: 0.12409 | Test Loss: 0.15408\n",
      "Epoch 051: | Train Loss: 0.13633 | Test Loss: 0.14703\n",
      "Epoch 052: | Train Loss: 0.13262 | Test Loss: 0.16169\n",
      "Epoch 053: | Train Loss: 0.18222 | Test Loss: 0.17960\n",
      "Epoch 054: | Train Loss: 0.13824 | Test Loss: 0.16947\n",
      "Epoch 055: | Train Loss: 0.11839 | Test Loss: 0.15181\n",
      "Epoch 056: | Train Loss: 0.13703 | Test Loss: 0.15229\n",
      "Epoch 057: | Train Loss: 0.11160 | Test Loss: 0.15235\n",
      "Epoch 058: | Train Loss: 0.10071 | Test Loss: 0.16039\n",
      "Epoch 059: | Train Loss: 0.09866 | Test Loss: 0.14783\n",
      "Epoch 060: | Train Loss: 0.11082 | Test Loss: 0.16382\n",
      "Epoch 061: | Train Loss: 0.10036 | Test Loss: 0.14928\n",
      "Epoch 062: | Train Loss: 0.10624 | Test Loss: 0.15695\n",
      "Epoch 063: | Train Loss: 0.11519 | Test Loss: 0.15312\n",
      "Epoch 064: | Train Loss: 0.10438 | Test Loss: 0.15614\n",
      "Epoch 065: | Train Loss: 0.09087 | Test Loss: 0.14520\n",
      "Epoch 066: | Train Loss: 0.09342 | Test Loss: 0.14694\n",
      "Epoch 067: | Train Loss: 0.11321 | Test Loss: 0.16496\n",
      "Epoch 068: | Train Loss: 0.09396 | Test Loss: 0.14964\n",
      "Epoch 069: | Train Loss: 0.09037 | Test Loss: 0.17247\n",
      "Epoch 070: | Train Loss: 0.08869 | Test Loss: 0.16347\n",
      "Epoch 071: | Train Loss: 0.08728 | Test Loss: 0.14866\n",
      "Epoch 072: | Train Loss: 0.07736 | Test Loss: 0.15440\n",
      "Epoch 073: | Train Loss: 0.07591 | Test Loss: 0.14547\n",
      "Epoch 074: | Train Loss: 0.08292 | Test Loss: 0.14940\n",
      "Epoch 075: | Train Loss: 0.08606 | Test Loss: 0.14444\n",
      "Epoch 076: | Train Loss: 0.07647 | Test Loss: 0.15254\n",
      "Epoch 077: | Train Loss: 0.06742 | Test Loss: 0.15534\n",
      "Epoch 078: | Train Loss: 0.08565 | Test Loss: 0.18598\n",
      "Epoch 079: | Train Loss: 0.07393 | Test Loss: 0.18206\n",
      "Epoch 080: | Train Loss: 0.08212 | Test Loss: 0.16083\n",
      "Epoch 081: | Train Loss: 0.07973 | Test Loss: 0.16712\n",
      "Epoch 082: | Train Loss: 0.07774 | Test Loss: 0.19559\n",
      "Epoch 083: | Train Loss: 0.12303 | Test Loss: 0.16388\n",
      "Epoch 084: | Train Loss: 0.07301 | Test Loss: 0.19685\n",
      "Epoch 085: | Train Loss: 0.07461 | Test Loss: 0.16035\n",
      "Epoch 086: | Train Loss: 0.07644 | Test Loss: 0.17547\n",
      "Epoch 087: | Train Loss: 0.06744 | Test Loss: 0.16615\n",
      "Epoch 088: | Train Loss: 0.06078 | Test Loss: 0.15892\n",
      "Epoch 089: | Train Loss: 0.07126 | Test Loss: 0.17621\n",
      "Epoch 090: | Train Loss: 0.05953 | Test Loss: 0.18101\n",
      "Epoch 091: | Train Loss: 0.05914 | Test Loss: 0.17741\n",
      "Epoch 092: | Train Loss: 0.07324 | Test Loss: 0.16511\n",
      "Epoch 093: | Train Loss: 0.05946 | Test Loss: 0.17733\n",
      "Epoch 094: | Train Loss: 0.05292 | Test Loss: 0.18044\n",
      "Epoch 095: | Train Loss: 0.05370 | Test Loss: 0.17499\n",
      "Epoch 096: | Train Loss: 0.05198 | Test Loss: 0.18795\n",
      "Epoch 097: | Train Loss: 0.06317 | Test Loss: 0.16733\n",
      "Epoch 098: | Train Loss: 0.05269 | Test Loss: 0.17253\n",
      "Epoch 099: | Train Loss: 0.04734 | Test Loss: 0.19105\n",
      "Epoch 100: | Train Loss: 0.07697 | Test Loss: 0.17759\n",
      "Epoch 101: | Train Loss: 0.11846 | Test Loss: 0.19910\n",
      "Epoch 102: | Train Loss: 0.07021 | Test Loss: 0.18319\n",
      "Epoch 103: | Train Loss: 0.06606 | Test Loss: 0.18154\n",
      "Epoch 104: | Train Loss: 0.05886 | Test Loss: 0.17355\n",
      "Epoch 105: | Train Loss: 0.05395 | Test Loss: 0.17267\n",
      "Epoch 106: | Train Loss: 0.04873 | Test Loss: 0.17424\n",
      "Epoch 107: | Train Loss: 0.04226 | Test Loss: 0.17618\n",
      "Epoch 108: | Train Loss: 0.04767 | Test Loss: 0.20011\n",
      "Epoch 109: | Train Loss: 0.05143 | Test Loss: 0.17783\n",
      "Epoch 110: | Train Loss: 0.04583 | Test Loss: 0.20396\n",
      "Epoch 111: | Train Loss: 0.07321 | Test Loss: 0.22647\n",
      "Epoch 112: | Train Loss: 0.06548 | Test Loss: 0.18463\n",
      "Epoch 113: | Train Loss: 0.05406 | Test Loss: 0.25410\n",
      "Epoch 114: | Train Loss: 0.07576 | Test Loss: 0.22223\n",
      "Epoch 115: | Train Loss: 0.07013 | Test Loss: 0.20527\n",
      "Epoch 116: | Train Loss: 0.05997 | Test Loss: 0.20809\n",
      "Epoch 117: | Train Loss: 0.05544 | Test Loss: 0.22600\n",
      "Epoch 118: | Train Loss: 0.05878 | Test Loss: 0.19784\n",
      "Epoch 119: | Train Loss: 0.05245 | Test Loss: 0.20569\n",
      "Epoch 120: | Train Loss: 0.05069 | Test Loss: 0.22985\n",
      "Epoch 121: | Train Loss: 0.05189 | Test Loss: 0.20824\n",
      "Epoch 122: | Train Loss: 0.07309 | Test Loss: 0.26776\n",
      "Epoch 123: | Train Loss: 0.06102 | Test Loss: 0.23422\n",
      "Epoch 124: | Train Loss: 0.06085 | Test Loss: 0.23493\n",
      "Epoch 125: | Train Loss: 0.06155 | Test Loss: 0.22934\n",
      "Epoch 126: | Train Loss: 0.06610 | Test Loss: 0.22193\n",
      "Epoch 127: | Train Loss: 0.06174 | Test Loss: 0.23321\n",
      "Epoch 128: | Train Loss: 0.06819 | Test Loss: 0.19449\n",
      "Epoch 129: | Train Loss: 0.04491 | Test Loss: 0.20747\n",
      "Epoch 130: | Train Loss: 0.05193 | Test Loss: 0.21139\n",
      "Epoch 131: | Train Loss: 0.03854 | Test Loss: 0.25481\n",
      "Epoch 132: | Train Loss: 0.02726 | Test Loss: 0.22349\n",
      "Epoch 133: | Train Loss: 0.09160 | Test Loss: 0.24616\n",
      "Epoch 134: | Train Loss: 0.04984 | Test Loss: 0.21981\n",
      "Epoch 135: | Train Loss: 0.03985 | Test Loss: 0.19930\n",
      "Epoch 136: | Train Loss: 0.02788 | Test Loss: 0.22698\n",
      "Epoch 137: | Train Loss: 0.03247 | Test Loss: 0.21500\n",
      "Epoch 138: | Train Loss: 0.03652 | Test Loss: 0.21831\n",
      "Epoch 139: | Train Loss: 0.03028 | Test Loss: 0.23680\n",
      "Epoch 140: | Train Loss: 0.04068 | Test Loss: 0.24005\n",
      "Epoch 141: | Train Loss: 0.11571 | Test Loss: 0.30028\n",
      "Epoch 142: | Train Loss: 0.10691 | Test Loss: 0.21142\n",
      "Epoch 143: | Train Loss: 0.04400 | Test Loss: 0.21967\n",
      "Epoch 144: | Train Loss: 0.02706 | Test Loss: 0.20883\n",
      "Epoch 145: | Train Loss: 0.03274 | Test Loss: 0.21944\n",
      "Epoch 146: | Train Loss: 0.02346 | Test Loss: 0.21855\n",
      "Epoch 147: | Train Loss: 0.02303 | Test Loss: 0.25387\n",
      "Epoch 148: | Train Loss: 0.02783 | Test Loss: 0.27514\n",
      "Epoch 149: | Train Loss: 0.02724 | Test Loss: 0.26222\n",
      "Epoch 150: | Train Loss: 0.03194 | Test Loss: 0.23739\n",
      "Epoch 151: | Train Loss: 0.03644 | Test Loss: 0.25751\n",
      "Epoch 152: | Train Loss: 0.02657 | Test Loss: 0.20434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: | Train Loss: 0.02628 | Test Loss: 0.25158\n",
      "Epoch 154: | Train Loss: 0.07879 | Test Loss: 0.38323\n",
      "Epoch 155: | Train Loss: 0.09173 | Test Loss: 0.23885\n",
      "Epoch 156: | Train Loss: 0.04918 | Test Loss: 0.23717\n",
      "Epoch 157: | Train Loss: 0.03109 | Test Loss: 0.24024\n",
      "Epoch 158: | Train Loss: 0.04316 | Test Loss: 0.20800\n",
      "Epoch 159: | Train Loss: 0.02581 | Test Loss: 0.27884\n",
      "Epoch 160: | Train Loss: 0.02614 | Test Loss: 0.22842\n",
      "Epoch 161: | Train Loss: 0.03405 | Test Loss: 0.24438\n",
      "Epoch 162: | Train Loss: 0.02315 | Test Loss: 0.26136\n",
      "Epoch 163: | Train Loss: 0.02359 | Test Loss: 0.27067\n",
      "Epoch 164: | Train Loss: 0.02824 | Test Loss: 0.32294\n",
      "Epoch 165: | Train Loss: 0.02547 | Test Loss: 0.23054\n",
      "Epoch 166: | Train Loss: 0.02834 | Test Loss: 0.26255\n",
      "Epoch 167: | Train Loss: 0.02144 | Test Loss: 0.25501\n",
      "Epoch 168: | Train Loss: 0.02306 | Test Loss: 0.25428\n",
      "Epoch 169: | Train Loss: 0.01539 | Test Loss: 0.26246\n",
      "Epoch 170: | Train Loss: 0.01817 | Test Loss: 0.28153\n",
      "Epoch 171: | Train Loss: 0.01528 | Test Loss: 0.35428\n",
      "Epoch 172: | Train Loss: 0.02641 | Test Loss: 0.29084\n",
      "Epoch 173: | Train Loss: 0.04650 | Test Loss: 0.29667\n",
      "Epoch 174: | Train Loss: 0.04215 | Test Loss: 0.25154\n",
      "Epoch 175: | Train Loss: 0.01501 | Test Loss: 0.28606\n",
      "Epoch 176: | Train Loss: 0.01563 | Test Loss: 0.27493\n",
      "Epoch 177: | Train Loss: 0.04080 | Test Loss: 0.27490\n",
      "Epoch 178: | Train Loss: 0.01275 | Test Loss: 0.28408\n",
      "Epoch 179: | Train Loss: 0.03384 | Test Loss: 0.25046\n",
      "Epoch 180: | Train Loss: 0.03194 | Test Loss: 0.47173\n",
      "Epoch 181: | Train Loss: 0.03065 | Test Loss: 0.25758\n",
      "Epoch 182: | Train Loss: 0.01363 | Test Loss: 0.29868\n",
      "Epoch 183: | Train Loss: 0.01431 | Test Loss: 0.27060\n",
      "Epoch 184: | Train Loss: 0.01756 | Test Loss: 0.27434\n",
      "Epoch 185: | Train Loss: 0.01718 | Test Loss: 0.35931\n",
      "Epoch 186: | Train Loss: 0.06464 | Test Loss: 0.24507\n",
      "Epoch 187: | Train Loss: 0.03329 | Test Loss: 0.28887\n",
      "Epoch 188: | Train Loss: 0.01526 | Test Loss: 0.29181\n",
      "Epoch 189: | Train Loss: 0.01164 | Test Loss: 0.29210\n",
      "Epoch 190: | Train Loss: 0.01524 | Test Loss: 0.28051\n",
      "Epoch 191: | Train Loss: 0.01595 | Test Loss: 0.31936\n",
      "Epoch 192: | Train Loss: 0.01309 | Test Loss: 0.33892\n",
      "Epoch 193: | Train Loss: 0.01247 | Test Loss: 0.28672\n",
      "Epoch 194: | Train Loss: 0.01787 | Test Loss: 0.40838\n",
      "Epoch 195: | Train Loss: 0.03303 | Test Loss: 0.42876\n",
      "Epoch 196: | Train Loss: 0.03884 | Test Loss: 0.27409\n",
      "Epoch 197: | Train Loss: 0.01969 | Test Loss: 0.34084\n",
      "Epoch 198: | Train Loss: 0.03336 | Test Loss: 0.31257\n",
      "Epoch 199: | Train Loss: 0.01523 | Test Loss: 0.44902\n",
      "Epoch 200: | Train Loss: 0.01718 | Test Loss: 0.30605\n",
      "Epoch 201: | Train Loss: 0.02514 | Test Loss: 0.40199\n",
      "Epoch 202: | Train Loss: 0.01648 | Test Loss: 0.43619\n",
      "Epoch 203: | Train Loss: 0.01942 | Test Loss: 0.28365\n",
      "Epoch 204: | Train Loss: 0.00866 | Test Loss: 0.36820\n",
      "Epoch 205: | Train Loss: 0.02182 | Test Loss: 0.28977\n",
      "Epoch 206: | Train Loss: 0.01289 | Test Loss: 0.40785\n",
      "Epoch 207: | Train Loss: 0.05339 | Test Loss: 0.32379\n",
      "Epoch 208: | Train Loss: 0.04201 | Test Loss: 0.39884\n",
      "Epoch 209: | Train Loss: 0.02861 | Test Loss: 0.32337\n",
      "Epoch 210: | Train Loss: 0.01057 | Test Loss: 0.32532\n",
      "Epoch 211: | Train Loss: 0.02743 | Test Loss: 0.31807\n",
      "Epoch 212: | Train Loss: 0.01784 | Test Loss: 0.29201\n",
      "Epoch 213: | Train Loss: 0.02975 | Test Loss: 0.48590\n",
      "Epoch 214: | Train Loss: 0.03829 | Test Loss: 0.29634\n",
      "Epoch 215: | Train Loss: 0.01141 | Test Loss: 0.28302\n",
      "Epoch 216: | Train Loss: 0.01571 | Test Loss: 0.31990\n",
      "Epoch 217: | Train Loss: 0.02801 | Test Loss: 0.37873\n",
      "Epoch 218: | Train Loss: 0.01496 | Test Loss: 0.34281\n",
      "Epoch 219: | Train Loss: 0.00887 | Test Loss: 0.38355\n",
      "Epoch 220: | Train Loss: 0.01898 | Test Loss: 0.42270\n",
      "Epoch 221: | Train Loss: 0.01562 | Test Loss: 0.45157\n",
      "Epoch 222: | Train Loss: 0.00780 | Test Loss: 0.37107\n",
      "Epoch 223: | Train Loss: 0.01609 | Test Loss: 0.33875\n",
      "Epoch 224: | Train Loss: 0.03604 | Test Loss: 0.40255\n",
      "Epoch 225: | Train Loss: 0.01420 | Test Loss: 0.36038\n",
      "Epoch 226: | Train Loss: 0.02747 | Test Loss: 0.27963\n",
      "Epoch 227: | Train Loss: 0.01311 | Test Loss: 0.37623\n",
      "Epoch 228: | Train Loss: 0.00963 | Test Loss: 0.34856\n",
      "Epoch 229: | Train Loss: 0.00758 | Test Loss: 0.31976\n",
      "Epoch 230: | Train Loss: 0.00658 | Test Loss: 0.37463\n",
      "Epoch 231: | Train Loss: 0.00628 | Test Loss: 0.33241\n",
      "Epoch 232: | Train Loss: 0.00382 | Test Loss: 0.36456\n",
      "Epoch 233: | Train Loss: 0.01504 | Test Loss: 0.52076\n",
      "Epoch 234: | Train Loss: 0.01912 | Test Loss: 0.32091\n",
      "Epoch 235: | Train Loss: 0.06196 | Test Loss: 0.36072\n",
      "Epoch 236: | Train Loss: 0.03531 | Test Loss: 0.30304\n",
      "Epoch 237: | Train Loss: 0.04614 | Test Loss: 0.33606\n",
      "Epoch 238: | Train Loss: 0.01059 | Test Loss: 0.29200\n",
      "Epoch 239: | Train Loss: 0.00602 | Test Loss: 0.32607\n",
      "Epoch 240: | Train Loss: 0.00558 | Test Loss: 0.34564\n",
      "stats of l2reg of  0.0003 are [0.99943 0.96558 0.00475 0.30086]\n",
      "running reg of 0.001\n",
      "initial run of high regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16878/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1595cba46be407a8b5a0bba4f67f89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 26.05023 | Test Loss: 27.61905\n",
      "Epoch 002: | Train Loss: 14.43427 | Test Loss: 0.53948\n",
      "Epoch 003: | Train Loss: 0.54662 | Test Loss: 0.52566\n",
      "Epoch 004: | Train Loss: 0.47726 | Test Loss: 0.47601\n",
      "Epoch 005: | Train Loss: 0.47781 | Test Loss: 0.47692\n",
      "Epoch 006: | Train Loss: 0.47723 | Test Loss: 0.52340\n",
      "Epoch 007: | Train Loss: 0.43586 | Test Loss: 0.61149\n",
      "Epoch 008: | Train Loss: 0.44552 | Test Loss: 0.60275\n",
      "Epoch 009: | Train Loss: 0.43525 | Test Loss: 0.46807\n",
      "Epoch 010: | Train Loss: 0.46820 | Test Loss: 0.43697\n",
      "Epoch 011: | Train Loss: 0.45896 | Test Loss: 0.46525\n",
      "Epoch 012: | Train Loss: 0.42096 | Test Loss: 0.71531\n",
      "Epoch 013: | Train Loss: 0.45678 | Test Loss: 0.46298\n",
      "Epoch 014: | Train Loss: 0.43035 | Test Loss: 0.38999\n",
      "Epoch 015: | Train Loss: 0.40506 | Test Loss: 0.40039\n",
      "Epoch 016: | Train Loss: 0.41352 | Test Loss: 0.38769\n",
      "Epoch 017: | Train Loss: 0.39360 | Test Loss: 0.56662\n",
      "Epoch 018: | Train Loss: 0.38102 | Test Loss: 0.37266\n",
      "Epoch 019: | Train Loss: 0.38520 | Test Loss: 0.44165\n",
      "Epoch 020: | Train Loss: 0.37088 | Test Loss: 0.42561\n",
      "run with given regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2caa47ea18a445b963ff7372a771312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.48463 | Test Loss: 0.37013\n",
      "Epoch 002: | Train Loss: 0.39279 | Test Loss: 0.30822\n",
      "Epoch 003: | Train Loss: 0.37805 | Test Loss: 0.30284\n",
      "Epoch 004: | Train Loss: 0.41169 | Test Loss: 0.36249\n",
      "Epoch 005: | Train Loss: 0.39000 | Test Loss: 0.38706\n",
      "Epoch 006: | Train Loss: 0.33033 | Test Loss: 0.29885\n",
      "Epoch 007: | Train Loss: 0.30191 | Test Loss: 0.32686\n",
      "Epoch 008: | Train Loss: 0.28090 | Test Loss: 0.30406\n",
      "Epoch 009: | Train Loss: 0.30200 | Test Loss: 0.27678\n",
      "Epoch 010: | Train Loss: 0.25609 | Test Loss: 0.25347\n",
      "Epoch 011: | Train Loss: 0.27058 | Test Loss: 0.28014\n",
      "Epoch 012: | Train Loss: 0.25650 | Test Loss: 0.24753\n",
      "Epoch 013: | Train Loss: 0.25186 | Test Loss: 0.26323\n",
      "Epoch 014: | Train Loss: 0.23515 | Test Loss: 0.23910\n",
      "Epoch 015: | Train Loss: 0.22572 | Test Loss: 0.24259\n",
      "Epoch 016: | Train Loss: 0.21423 | Test Loss: 0.23422\n",
      "Epoch 017: | Train Loss: 0.19396 | Test Loss: 0.23494\n",
      "Epoch 018: | Train Loss: 0.23464 | Test Loss: 0.25020\n",
      "Epoch 019: | Train Loss: 0.19438 | Test Loss: 0.23005\n",
      "Epoch 020: | Train Loss: 0.20562 | Test Loss: 0.27833\n",
      "Epoch 021: | Train Loss: 0.19156 | Test Loss: 0.21223\n",
      "Epoch 022: | Train Loss: 0.15957 | Test Loss: 0.36518\n",
      "Epoch 023: | Train Loss: 0.17275 | Test Loss: 0.19862\n",
      "Epoch 024: | Train Loss: 0.20804 | Test Loss: 0.22302\n",
      "Epoch 025: | Train Loss: 0.17027 | Test Loss: 0.20861\n",
      "Epoch 026: | Train Loss: 0.16774 | Test Loss: 0.21219\n",
      "Epoch 027: | Train Loss: 0.16804 | Test Loss: 0.17480\n",
      "Epoch 028: | Train Loss: 0.16366 | Test Loss: 0.21480\n",
      "Epoch 029: | Train Loss: 0.16692 | Test Loss: 0.20959\n",
      "Epoch 030: | Train Loss: 0.15180 | Test Loss: 0.22062\n",
      "Epoch 031: | Train Loss: 0.19325 | Test Loss: 0.20009\n",
      "Epoch 032: | Train Loss: 0.15582 | Test Loss: 0.22052\n",
      "Epoch 033: | Train Loss: 0.14885 | Test Loss: 0.16235\n",
      "Epoch 034: | Train Loss: 0.16750 | Test Loss: 0.17405\n",
      "Epoch 035: | Train Loss: 0.16443 | Test Loss: 0.20614\n",
      "Epoch 036: | Train Loss: 0.13515 | Test Loss: 0.17771\n",
      "Epoch 037: | Train Loss: 0.13620 | Test Loss: 0.15753\n",
      "Epoch 038: | Train Loss: 0.13568 | Test Loss: 0.21104\n",
      "Epoch 039: | Train Loss: 0.16163 | Test Loss: 0.18973\n",
      "Epoch 040: | Train Loss: 0.13684 | Test Loss: 0.16794\n",
      "Epoch 041: | Train Loss: 0.14000 | Test Loss: 0.14281\n",
      "Epoch 042: | Train Loss: 0.13330 | Test Loss: 0.15776\n",
      "Epoch 043: | Train Loss: 0.14512 | Test Loss: 0.17022\n",
      "Epoch 044: | Train Loss: 0.14154 | Test Loss: 0.15302\n",
      "Epoch 045: | Train Loss: 0.12457 | Test Loss: 0.15400\n",
      "Epoch 046: | Train Loss: 0.11607 | Test Loss: 0.14771\n",
      "Epoch 047: | Train Loss: 0.10395 | Test Loss: 0.18437\n",
      "Epoch 048: | Train Loss: 0.10307 | Test Loss: 0.14799\n",
      "Epoch 049: | Train Loss: 0.10598 | Test Loss: 0.15585\n",
      "Epoch 050: | Train Loss: 0.10470 | Test Loss: 0.17589\n",
      "Epoch 051: | Train Loss: 0.11805 | Test Loss: 0.17806\n",
      "Epoch 052: | Train Loss: 0.13683 | Test Loss: 0.20073\n",
      "Epoch 053: | Train Loss: 0.15889 | Test Loss: 0.17405\n",
      "Epoch 054: | Train Loss: 0.15041 | Test Loss: 0.39403\n",
      "Epoch 055: | Train Loss: 0.16085 | Test Loss: 0.17630\n",
      "Epoch 056: | Train Loss: 0.12284 | Test Loss: 0.14612\n",
      "Epoch 057: | Train Loss: 0.12277 | Test Loss: 0.20694\n",
      "Epoch 058: | Train Loss: 0.13015 | Test Loss: 0.14586\n",
      "Epoch 059: | Train Loss: 0.13041 | Test Loss: 0.14102\n",
      "Epoch 060: | Train Loss: 0.12131 | Test Loss: 0.13567\n",
      "Epoch 061: | Train Loss: 0.12563 | Test Loss: 0.17206\n",
      "Epoch 062: | Train Loss: 0.13068 | Test Loss: 0.14533\n",
      "Epoch 063: | Train Loss: 0.12934 | Test Loss: 0.14288\n",
      "Epoch 064: | Train Loss: 0.13050 | Test Loss: 0.15922\n",
      "Epoch 065: | Train Loss: 0.11954 | Test Loss: 0.14951\n",
      "Epoch 066: | Train Loss: 0.13327 | Test Loss: 0.15430\n",
      "Epoch 067: | Train Loss: 0.11844 | Test Loss: 0.14664\n",
      "Epoch 068: | Train Loss: 0.12652 | Test Loss: 0.15580\n",
      "Epoch 069: | Train Loss: 0.11253 | Test Loss: 0.15470\n",
      "Epoch 070: | Train Loss: 0.11578 | Test Loss: 0.13653\n",
      "Epoch 071: | Train Loss: 0.17050 | Test Loss: 0.17663\n",
      "Epoch 072: | Train Loss: 0.11080 | Test Loss: 0.16447\n",
      "Epoch 073: | Train Loss: 0.10538 | Test Loss: 0.17223\n",
      "Epoch 074: | Train Loss: 0.10025 | Test Loss: 0.14873\n",
      "Epoch 075: | Train Loss: 0.09648 | Test Loss: 0.19565\n",
      "Epoch 076: | Train Loss: 0.09599 | Test Loss: 0.15234\n",
      "Epoch 077: | Train Loss: 0.09169 | Test Loss: 0.16633\n",
      "Epoch 078: | Train Loss: 0.09556 | Test Loss: 0.16485\n",
      "Epoch 079: | Train Loss: 0.08864 | Test Loss: 0.17000\n",
      "Epoch 080: | Train Loss: 0.09456 | Test Loss: 0.16441\n",
      "Epoch 081: | Train Loss: 0.10295 | Test Loss: 0.15147\n",
      "Epoch 082: | Train Loss: 0.09041 | Test Loss: 0.16518\n",
      "Epoch 083: | Train Loss: 0.09569 | Test Loss: 0.15978\n",
      "Epoch 084: | Train Loss: 0.08239 | Test Loss: 0.14376\n",
      "Epoch 085: | Train Loss: 0.08538 | Test Loss: 0.15024\n",
      "Epoch 086: | Train Loss: 0.08393 | Test Loss: 0.14280\n",
      "Epoch 087: | Train Loss: 0.07586 | Test Loss: 0.19149\n",
      "Epoch 088: | Train Loss: 0.08267 | Test Loss: 0.14881\n",
      "Epoch 089: | Train Loss: 0.07883 | Test Loss: 0.14791\n",
      "Epoch 090: | Train Loss: 0.08576 | Test Loss: 0.15587\n",
      "Epoch 091: | Train Loss: 0.08415 | Test Loss: 0.24151\n",
      "Epoch 092: | Train Loss: 0.08520 | Test Loss: 0.15641\n",
      "Epoch 093: | Train Loss: 0.08860 | Test Loss: 0.14553\n",
      "Epoch 094: | Train Loss: 0.07719 | Test Loss: 0.17114\n",
      "Epoch 095: | Train Loss: 0.08247 | Test Loss: 0.26133\n",
      "Epoch 096: | Train Loss: 0.07634 | Test Loss: 0.15847\n",
      "Epoch 097: | Train Loss: 0.06587 | Test Loss: 0.15819\n",
      "Epoch 098: | Train Loss: 0.09274 | Test Loss: 0.15862\n",
      "Epoch 099: | Train Loss: 0.08273 | Test Loss: 0.13997\n",
      "Epoch 100: | Train Loss: 0.07831 | Test Loss: 0.17810\n",
      "Epoch 101: | Train Loss: 0.07176 | Test Loss: 0.15449\n",
      "Epoch 102: | Train Loss: 0.07567 | Test Loss: 0.19215\n",
      "Epoch 103: | Train Loss: 0.10627 | Test Loss: 0.14775\n",
      "Epoch 104: | Train Loss: 0.07686 | Test Loss: 0.16391\n",
      "Epoch 105: | Train Loss: 0.07598 | Test Loss: 0.15021\n",
      "Epoch 106: | Train Loss: 0.06568 | Test Loss: 0.22533\n",
      "Epoch 107: | Train Loss: 0.06634 | Test Loss: 0.19585\n",
      "Epoch 108: | Train Loss: 0.06899 | Test Loss: 0.23474\n",
      "Epoch 109: | Train Loss: 0.06778 | Test Loss: 0.21919\n",
      "Epoch 110: | Train Loss: 0.13038 | Test Loss: 0.15770\n",
      "Epoch 111: | Train Loss: 0.12536 | Test Loss: 0.15055\n",
      "Epoch 112: | Train Loss: 0.08582 | Test Loss: 0.20068\n",
      "Epoch 113: | Train Loss: 0.08472 | Test Loss: 0.18664\n",
      "Epoch 114: | Train Loss: 0.09091 | Test Loss: 0.15120\n",
      "Epoch 115: | Train Loss: 0.08015 | Test Loss: 0.15066\n",
      "Epoch 116: | Train Loss: 0.08517 | Test Loss: 0.14743\n",
      "Epoch 117: | Train Loss: 0.07535 | Test Loss: 0.18445\n",
      "Epoch 118: | Train Loss: 0.08074 | Test Loss: 0.14079\n",
      "Epoch 119: | Train Loss: 0.07161 | Test Loss: 0.18872\n",
      "Epoch 120: | Train Loss: 0.07364 | Test Loss: 0.14926\n",
      "Epoch 121: | Train Loss: 0.08693 | Test Loss: 0.16025\n",
      "Epoch 122: | Train Loss: 0.08874 | Test Loss: 0.18072\n",
      "Epoch 123: | Train Loss: 0.14000 | Test Loss: 0.20150\n",
      "Epoch 124: | Train Loss: 0.14540 | Test Loss: 0.15685\n",
      "Epoch 125: | Train Loss: 0.10565 | Test Loss: 0.14172\n",
      "Epoch 126: | Train Loss: 0.08726 | Test Loss: 0.15344\n",
      "Epoch 127: | Train Loss: 0.07136 | Test Loss: 0.16731\n",
      "Epoch 128: | Train Loss: 0.08244 | Test Loss: 0.15503\n",
      "Epoch 129: | Train Loss: 0.07239 | Test Loss: 0.15149\n",
      "Epoch 130: | Train Loss: 0.06841 | Test Loss: 0.15320\n",
      "Epoch 131: | Train Loss: 0.12126 | Test Loss: 0.15706\n",
      "Epoch 132: | Train Loss: 0.08462 | Test Loss: 0.15219\n",
      "Epoch 133: | Train Loss: 0.08066 | Test Loss: 0.15497\n",
      "Epoch 134: | Train Loss: 0.08449 | Test Loss: 0.15891\n",
      "Epoch 135: | Train Loss: 0.07290 | Test Loss: 0.23661\n",
      "Epoch 136: | Train Loss: 0.07245 | Test Loss: 0.18036\n",
      "Epoch 137: | Train Loss: 0.06766 | Test Loss: 0.16874\n",
      "Epoch 138: | Train Loss: 0.06779 | Test Loss: 0.17072\n",
      "Epoch 139: | Train Loss: 0.06823 | Test Loss: 0.20129\n",
      "Epoch 140: | Train Loss: 0.12224 | Test Loss: 0.21987\n",
      "Epoch 141: | Train Loss: 0.07320 | Test Loss: 0.15340\n",
      "Epoch 142: | Train Loss: 0.07475 | Test Loss: 0.18556\n",
      "Epoch 143: | Train Loss: 0.09238 | Test Loss: 0.21923\n",
      "Epoch 144: | Train Loss: 0.08055 | Test Loss: 0.20199\n",
      "Epoch 145: | Train Loss: 0.07488 | Test Loss: 0.16576\n",
      "Epoch 146: | Train Loss: 0.06271 | Test Loss: 0.16106\n",
      "Epoch 147: | Train Loss: 0.06596 | Test Loss: 0.26410\n",
      "Epoch 148: | Train Loss: 0.07821 | Test Loss: 0.17789\n",
      "Epoch 149: | Train Loss: 0.07267 | Test Loss: 0.19321\n",
      "Epoch 150: | Train Loss: 0.08858 | Test Loss: 0.16319\n",
      "Epoch 151: | Train Loss: 0.06163 | Test Loss: 0.18074\n",
      "Epoch 152: | Train Loss: 0.07084 | Test Loss: 0.17345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: | Train Loss: 0.08239 | Test Loss: 0.24540\n",
      "Epoch 154: | Train Loss: 0.07010 | Test Loss: 0.25039\n",
      "Epoch 155: | Train Loss: 0.07868 | Test Loss: 0.17072\n",
      "Epoch 156: | Train Loss: 0.08104 | Test Loss: 0.19162\n",
      "Epoch 157: | Train Loss: 0.08028 | Test Loss: 0.21899\n",
      "Epoch 158: | Train Loss: 0.09705 | Test Loss: 0.21915\n",
      "Epoch 159: | Train Loss: 0.11259 | Test Loss: 0.16363\n",
      "Epoch 160: | Train Loss: 0.05197 | Test Loss: 0.16088\n",
      "Epoch 161: | Train Loss: 0.04710 | Test Loss: 0.16267\n",
      "Epoch 162: | Train Loss: 0.04845 | Test Loss: 0.16786\n",
      "Epoch 163: | Train Loss: 0.05425 | Test Loss: 0.17821\n",
      "Epoch 164: | Train Loss: 0.03956 | Test Loss: 0.17403\n",
      "Epoch 165: | Train Loss: 0.04660 | Test Loss: 0.21900\n",
      "Epoch 166: | Train Loss: 0.06065 | Test Loss: 0.17759\n",
      "Epoch 167: | Train Loss: 0.03869 | Test Loss: 0.18218\n",
      "Epoch 168: | Train Loss: 0.07426 | Test Loss: 0.21680\n",
      "Epoch 169: | Train Loss: 0.04596 | Test Loss: 0.21656\n",
      "Epoch 170: | Train Loss: 0.05001 | Test Loss: 0.16380\n",
      "Epoch 171: | Train Loss: 0.03815 | Test Loss: 0.17764\n",
      "Epoch 172: | Train Loss: 0.04677 | Test Loss: 0.20408\n",
      "Epoch 173: | Train Loss: 0.04135 | Test Loss: 0.20283\n",
      "Epoch 174: | Train Loss: 0.03470 | Test Loss: 0.23521\n",
      "Epoch 175: | Train Loss: 0.04398 | Test Loss: 0.29578\n",
      "Epoch 176: | Train Loss: 0.05487 | Test Loss: 0.17249\n",
      "Epoch 177: | Train Loss: 0.03594 | Test Loss: 0.20135\n",
      "Epoch 178: | Train Loss: 0.06144 | Test Loss: 0.17756\n",
      "Epoch 179: | Train Loss: 0.04069 | Test Loss: 0.27498\n",
      "Epoch 180: | Train Loss: 0.03644 | Test Loss: 0.24048\n",
      "Epoch 181: | Train Loss: 0.04847 | Test Loss: 0.20247\n",
      "Epoch 182: | Train Loss: 0.03789 | Test Loss: 0.18836\n",
      "Epoch 183: | Train Loss: 0.08168 | Test Loss: 0.21184\n",
      "Epoch 184: | Train Loss: 0.05006 | Test Loss: 0.21661\n",
      "Epoch 185: | Train Loss: 0.05156 | Test Loss: 0.37368\n",
      "Epoch 186: | Train Loss: 0.12129 | Test Loss: 0.20929\n",
      "Epoch 187: | Train Loss: 0.09942 | Test Loss: 0.30157\n",
      "Epoch 188: | Train Loss: 0.05531 | Test Loss: 0.27261\n",
      "Epoch 189: | Train Loss: 0.04277 | Test Loss: 0.24212\n",
      "Epoch 190: | Train Loss: 0.03929 | Test Loss: 0.18661\n",
      "Epoch 191: | Train Loss: 0.03862 | Test Loss: 0.23746\n",
      "Epoch 192: | Train Loss: 0.04242 | Test Loss: 0.17398\n",
      "Epoch 193: | Train Loss: 0.03781 | Test Loss: 0.23545\n",
      "Epoch 194: | Train Loss: 0.03347 | Test Loss: 0.20520\n",
      "Epoch 195: | Train Loss: 0.03146 | Test Loss: 0.22646\n",
      "Epoch 196: | Train Loss: 0.03881 | Test Loss: 0.23279\n",
      "Epoch 197: | Train Loss: 0.05048 | Test Loss: 0.21876\n",
      "Epoch 198: | Train Loss: 0.04128 | Test Loss: 0.20274\n",
      "Epoch 199: | Train Loss: 0.04851 | Test Loss: 0.23925\n",
      "Epoch 200: | Train Loss: 0.03996 | Test Loss: 0.22644\n",
      "Epoch 201: | Train Loss: 0.08187 | Test Loss: 0.18406\n",
      "Epoch 202: | Train Loss: 0.04851 | Test Loss: 0.17947\n",
      "Epoch 203: | Train Loss: 0.03317 | Test Loss: 0.21601\n",
      "Epoch 204: | Train Loss: 0.04028 | Test Loss: 0.27523\n",
      "Epoch 205: | Train Loss: 0.02975 | Test Loss: 0.23829\n",
      "Epoch 206: | Train Loss: 0.03945 | Test Loss: 0.26470\n",
      "Epoch 207: | Train Loss: 0.06564 | Test Loss: 0.19943\n",
      "Epoch 208: | Train Loss: 0.03051 | Test Loss: 0.20660\n",
      "Epoch 209: | Train Loss: 0.05099 | Test Loss: 0.23396\n",
      "Epoch 210: | Train Loss: 0.03367 | Test Loss: 0.21467\n",
      "Epoch 211: | Train Loss: 0.04609 | Test Loss: 0.17681\n",
      "Epoch 212: | Train Loss: 0.04915 | Test Loss: 0.30749\n",
      "Epoch 213: | Train Loss: 0.04366 | Test Loss: 0.22012\n",
      "Epoch 214: | Train Loss: 0.03373 | Test Loss: 0.21126\n",
      "Epoch 215: | Train Loss: 0.03253 | Test Loss: 0.24233\n",
      "Epoch 216: | Train Loss: 0.02162 | Test Loss: 0.24806\n",
      "Epoch 217: | Train Loss: 0.05687 | Test Loss: 0.27400\n",
      "Epoch 218: | Train Loss: 0.11525 | Test Loss: 0.20217\n",
      "Epoch 219: | Train Loss: 0.03919 | Test Loss: 0.25313\n",
      "Epoch 220: | Train Loss: 0.04787 | Test Loss: 0.23392\n",
      "Epoch 221: | Train Loss: 0.07575 | Test Loss: 0.24308\n",
      "Epoch 222: | Train Loss: 0.04071 | Test Loss: 0.31650\n",
      "Epoch 223: | Train Loss: 0.06076 | Test Loss: 0.29204\n",
      "Epoch 224: | Train Loss: 0.04627 | Test Loss: 0.26713\n",
      "Epoch 225: | Train Loss: 0.04690 | Test Loss: 0.27779\n",
      "Epoch 226: | Train Loss: 0.04229 | Test Loss: 0.27839\n",
      "Epoch 227: | Train Loss: 0.06239 | Test Loss: 0.28217\n",
      "Epoch 228: | Train Loss: 0.06889 | Test Loss: 0.26123\n",
      "Epoch 229: | Train Loss: 0.04643 | Test Loss: 0.31097\n",
      "Epoch 230: | Train Loss: 0.07412 | Test Loss: 0.43745\n",
      "Epoch 231: | Train Loss: 0.15852 | Test Loss: 0.27080\n",
      "Epoch 232: | Train Loss: 0.09224 | Test Loss: 0.16767\n",
      "Epoch 233: | Train Loss: 0.08745 | Test Loss: 0.18885\n",
      "Epoch 234: | Train Loss: 0.05691 | Test Loss: 0.22006\n",
      "Epoch 235: | Train Loss: 0.04661 | Test Loss: 0.23818\n",
      "Epoch 236: | Train Loss: 0.04492 | Test Loss: 0.24546\n",
      "Epoch 237: | Train Loss: 0.02248 | Test Loss: 0.29422\n",
      "Epoch 238: | Train Loss: 0.02013 | Test Loss: 0.24402\n",
      "Epoch 239: | Train Loss: 0.06450 | Test Loss: 0.24756\n",
      "Epoch 240: | Train Loss: 0.04301 | Test Loss: 0.20942\n",
      "stats of l2reg of  0.001 are [0.99382 0.9675  0.02929 0.18863]\n",
      "running reg of 0.003\n",
      "initial run of high regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16878/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62af1033eebe43e995ffaa0e8ad984c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 26.12403 | Test Loss: 27.61905\n",
      "Epoch 002: | Train Loss: 12.34756 | Test Loss: 0.54746\n",
      "Epoch 003: | Train Loss: 0.54094 | Test Loss: 0.45884\n",
      "Epoch 004: | Train Loss: 0.52018 | Test Loss: 0.43999\n",
      "Epoch 005: | Train Loss: 0.48778 | Test Loss: 0.43512\n",
      "Epoch 006: | Train Loss: 0.49189 | Test Loss: 0.69142\n",
      "Epoch 007: | Train Loss: 0.49727 | Test Loss: 0.39377\n",
      "Epoch 008: | Train Loss: 0.47417 | Test Loss: 0.45926\n",
      "Epoch 009: | Train Loss: 0.48179 | Test Loss: 0.41963\n",
      "Epoch 010: | Train Loss: 0.46525 | Test Loss: 0.37559\n",
      "Epoch 011: | Train Loss: 0.47222 | Test Loss: 0.39244\n",
      "Epoch 012: | Train Loss: 0.45968 | Test Loss: 0.44018\n",
      "Epoch 013: | Train Loss: 0.45623 | Test Loss: 0.39332\n",
      "Epoch 014: | Train Loss: 0.47426 | Test Loss: 0.37527\n",
      "Epoch 015: | Train Loss: 0.44938 | Test Loss: 0.37546\n",
      "Epoch 016: | Train Loss: 0.45396 | Test Loss: 0.39324\n",
      "Epoch 017: | Train Loss: 0.44360 | Test Loss: 0.36080\n",
      "Epoch 018: | Train Loss: 0.44305 | Test Loss: 0.36126\n",
      "Epoch 019: | Train Loss: 0.41875 | Test Loss: 0.36128\n",
      "Epoch 020: | Train Loss: 0.45246 | Test Loss: 0.38159\n",
      "run with given regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88d0ea6f2384b3dbd83f6e736066d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.45104 | Test Loss: 0.36461\n",
      "Epoch 002: | Train Loss: 0.43124 | Test Loss: 0.43912\n",
      "Epoch 003: | Train Loss: 0.42473 | Test Loss: 0.35015\n",
      "Epoch 004: | Train Loss: 0.41322 | Test Loss: 0.33488\n",
      "Epoch 005: | Train Loss: 0.39213 | Test Loss: 0.37510\n",
      "Epoch 006: | Train Loss: 0.40172 | Test Loss: 0.36052\n",
      "Epoch 007: | Train Loss: 0.41688 | Test Loss: 0.32737\n",
      "Epoch 008: | Train Loss: 0.42573 | Test Loss: 0.31799\n",
      "Epoch 009: | Train Loss: 0.36634 | Test Loss: 0.34910\n",
      "Epoch 010: | Train Loss: 0.38234 | Test Loss: 0.30635\n",
      "Epoch 011: | Train Loss: 0.33983 | Test Loss: 0.35712\n",
      "Epoch 012: | Train Loss: 0.38080 | Test Loss: 0.31363\n",
      "Epoch 013: | Train Loss: 0.32814 | Test Loss: 0.31890\n",
      "Epoch 014: | Train Loss: 0.32752 | Test Loss: 0.30581\n",
      "Epoch 015: | Train Loss: 0.32996 | Test Loss: 0.51234\n",
      "Epoch 016: | Train Loss: 0.32710 | Test Loss: 0.29464\n",
      "Epoch 017: | Train Loss: 0.31435 | Test Loss: 0.32573\n",
      "Epoch 018: | Train Loss: 0.29532 | Test Loss: 0.31795\n",
      "Epoch 019: | Train Loss: 0.29364 | Test Loss: 0.28835\n",
      "Epoch 020: | Train Loss: 0.29352 | Test Loss: 0.29881\n",
      "Epoch 021: | Train Loss: 0.27996 | Test Loss: 0.28712\n",
      "Epoch 022: | Train Loss: 0.27940 | Test Loss: 0.29284\n",
      "Epoch 023: | Train Loss: 0.29491 | Test Loss: 0.30841\n",
      "Epoch 024: | Train Loss: 0.28416 | Test Loss: 0.24358\n",
      "Epoch 025: | Train Loss: 0.27954 | Test Loss: 0.29866\n",
      "Epoch 026: | Train Loss: 0.27200 | Test Loss: 0.32216\n",
      "Epoch 027: | Train Loss: 0.27815 | Test Loss: 0.27062\n",
      "Epoch 028: | Train Loss: 0.26435 | Test Loss: 0.26280\n",
      "Epoch 029: | Train Loss: 0.26148 | Test Loss: 0.31298\n",
      "Epoch 030: | Train Loss: 0.27046 | Test Loss: 0.25982\n",
      "Epoch 031: | Train Loss: 0.29221 | Test Loss: 0.27512\n",
      "Epoch 032: | Train Loss: 0.28405 | Test Loss: 0.22782\n",
      "Epoch 033: | Train Loss: 0.25844 | Test Loss: 0.25332\n",
      "Epoch 034: | Train Loss: 0.27280 | Test Loss: 0.24645\n",
      "Epoch 035: | Train Loss: 0.25074 | Test Loss: 0.23760\n",
      "Epoch 036: | Train Loss: 0.26020 | Test Loss: 0.25765\n",
      "Epoch 037: | Train Loss: 0.25201 | Test Loss: 0.23428\n",
      "Epoch 038: | Train Loss: 0.25595 | Test Loss: 0.22635\n",
      "Epoch 039: | Train Loss: 0.25217 | Test Loss: 0.25041\n",
      "Epoch 040: | Train Loss: 0.23270 | Test Loss: 0.21689\n",
      "Epoch 041: | Train Loss: 0.23067 | Test Loss: 0.23945\n",
      "Epoch 042: | Train Loss: 0.22968 | Test Loss: 0.18109\n",
      "Epoch 043: | Train Loss: 0.22820 | Test Loss: 0.18668\n",
      "Epoch 044: | Train Loss: 0.22682 | Test Loss: 0.19703\n",
      "Epoch 045: | Train Loss: 0.22746 | Test Loss: 0.22349\n",
      "Epoch 046: | Train Loss: 0.23284 | Test Loss: 0.21814\n",
      "Epoch 047: | Train Loss: 0.21688 | Test Loss: 0.19812\n",
      "Epoch 048: | Train Loss: 0.22221 | Test Loss: 0.21142\n",
      "Epoch 049: | Train Loss: 0.23087 | Test Loss: 0.22937\n",
      "Epoch 050: | Train Loss: 0.21440 | Test Loss: 0.20726\n",
      "Epoch 051: | Train Loss: 0.19124 | Test Loss: 0.16628\n",
      "Epoch 052: | Train Loss: 0.20938 | Test Loss: 0.33060\n",
      "Epoch 053: | Train Loss: 0.17018 | Test Loss: 0.23278\n",
      "Epoch 054: | Train Loss: 0.15736 | Test Loss: 0.18650\n",
      "Epoch 055: | Train Loss: 0.14527 | Test Loss: 0.19134\n",
      "Epoch 056: | Train Loss: 0.16001 | Test Loss: 0.17987\n",
      "Epoch 057: | Train Loss: 0.15423 | Test Loss: 0.17800\n",
      "Epoch 058: | Train Loss: 0.14183 | Test Loss: 0.18849\n",
      "Epoch 059: | Train Loss: 0.14174 | Test Loss: 0.16870\n",
      "Epoch 060: | Train Loss: 0.15192 | Test Loss: 0.16771\n",
      "Epoch 061: | Train Loss: 0.16547 | Test Loss: 0.23152\n",
      "Epoch 062: | Train Loss: 0.14152 | Test Loss: 0.17205\n",
      "Epoch 063: | Train Loss: 0.17444 | Test Loss: 0.19942\n",
      "Epoch 064: | Train Loss: 0.14089 | Test Loss: 0.15792\n",
      "Epoch 065: | Train Loss: 0.14553 | Test Loss: 0.17068\n",
      "Epoch 066: | Train Loss: 0.13114 | Test Loss: 0.17573\n",
      "Epoch 067: | Train Loss: 0.14628 | Test Loss: 0.16312\n",
      "Epoch 068: | Train Loss: 0.13365 | Test Loss: 0.16429\n",
      "Epoch 069: | Train Loss: 0.12879 | Test Loss: 0.18286\n",
      "Epoch 070: | Train Loss: 0.14287 | Test Loss: 0.18661\n",
      "Epoch 071: | Train Loss: 0.14355 | Test Loss: 0.15839\n",
      "Epoch 072: | Train Loss: 0.15128 | Test Loss: 0.16217\n",
      "Epoch 073: | Train Loss: 0.14806 | Test Loss: 0.17417\n",
      "Epoch 074: | Train Loss: 0.14300 | Test Loss: 0.15601\n",
      "Epoch 075: | Train Loss: 0.13595 | Test Loss: 0.15452\n",
      "Epoch 076: | Train Loss: 0.12932 | Test Loss: 0.16441\n",
      "Epoch 077: | Train Loss: 0.12657 | Test Loss: 0.15031\n",
      "Epoch 078: | Train Loss: 0.13799 | Test Loss: 0.22770\n",
      "Epoch 079: | Train Loss: 0.12850 | Test Loss: 0.16173\n",
      "Epoch 080: | Train Loss: 0.13405 | Test Loss: 0.16018\n",
      "Epoch 081: | Train Loss: 0.13517 | Test Loss: 0.16337\n",
      "Epoch 082: | Train Loss: 0.12914 | Test Loss: 0.15763\n",
      "Epoch 083: | Train Loss: 0.13218 | Test Loss: 0.15786\n",
      "Epoch 084: | Train Loss: 0.12799 | Test Loss: 0.16555\n",
      "Epoch 085: | Train Loss: 0.12668 | Test Loss: 0.19092\n",
      "Epoch 086: | Train Loss: 0.13025 | Test Loss: 0.14837\n",
      "Epoch 087: | Train Loss: 0.14211 | Test Loss: 0.15367\n",
      "Epoch 088: | Train Loss: 0.12894 | Test Loss: 0.17023\n",
      "Epoch 089: | Train Loss: 0.12670 | Test Loss: 0.14934\n",
      "Epoch 090: | Train Loss: 0.13576 | Test Loss: 0.16706\n",
      "Epoch 091: | Train Loss: 0.12708 | Test Loss: 0.14969\n",
      "Epoch 092: | Train Loss: 0.12332 | Test Loss: 0.15572\n",
      "Epoch 093: | Train Loss: 0.12763 | Test Loss: 0.15315\n",
      "Epoch 094: | Train Loss: 0.12018 | Test Loss: 0.14607\n",
      "Epoch 095: | Train Loss: 0.12609 | Test Loss: 0.18919\n",
      "Epoch 096: | Train Loss: 0.15506 | Test Loss: 0.14110\n",
      "Epoch 097: | Train Loss: 0.12685 | Test Loss: 0.15131\n",
      "Epoch 098: | Train Loss: 0.12855 | Test Loss: 0.15496\n",
      "Epoch 099: | Train Loss: 0.14159 | Test Loss: 0.16257\n",
      "Epoch 100: | Train Loss: 0.13131 | Test Loss: 0.14610\n",
      "Epoch 101: | Train Loss: 0.12765 | Test Loss: 0.14602\n",
      "Epoch 102: | Train Loss: 0.12187 | Test Loss: 0.15451\n",
      "Epoch 103: | Train Loss: 0.12125 | Test Loss: 0.15259\n",
      "Epoch 104: | Train Loss: 0.12063 | Test Loss: 0.14032\n",
      "Epoch 105: | Train Loss: 0.12206 | Test Loss: 0.18609\n",
      "Epoch 106: | Train Loss: 0.11416 | Test Loss: 0.16323\n",
      "Epoch 107: | Train Loss: 0.11780 | Test Loss: 0.15400\n",
      "Epoch 108: | Train Loss: 0.14437 | Test Loss: 0.15344\n",
      "Epoch 109: | Train Loss: 0.14606 | Test Loss: 0.17876\n",
      "Epoch 110: | Train Loss: 0.13875 | Test Loss: 0.17554\n",
      "Epoch 111: | Train Loss: 0.14501 | Test Loss: 0.15454\n",
      "Epoch 112: | Train Loss: 0.12280 | Test Loss: 0.15322\n",
      "Epoch 113: | Train Loss: 0.12022 | Test Loss: 0.15693\n",
      "Epoch 114: | Train Loss: 0.14053 | Test Loss: 0.15352\n",
      "Epoch 115: | Train Loss: 0.13956 | Test Loss: 0.15720\n",
      "Epoch 116: | Train Loss: 0.11637 | Test Loss: 0.15985\n",
      "Epoch 117: | Train Loss: 0.12828 | Test Loss: 0.15468\n",
      "Epoch 118: | Train Loss: 0.11188 | Test Loss: 0.14434\n",
      "Epoch 119: | Train Loss: 0.12094 | Test Loss: 0.16331\n",
      "Epoch 120: | Train Loss: 0.12241 | Test Loss: 0.14362\n",
      "Epoch 121: | Train Loss: 0.12264 | Test Loss: 0.15170\n",
      "Epoch 122: | Train Loss: 0.11041 | Test Loss: 0.15424\n",
      "Epoch 123: | Train Loss: 0.11258 | Test Loss: 0.14310\n",
      "Epoch 124: | Train Loss: 0.12043 | Test Loss: 0.16555\n",
      "Epoch 125: | Train Loss: 0.11302 | Test Loss: 0.13436\n",
      "Epoch 126: | Train Loss: 0.10994 | Test Loss: 0.19503\n",
      "Epoch 127: | Train Loss: 0.12973 | Test Loss: 0.15029\n",
      "Epoch 128: | Train Loss: 0.15338 | Test Loss: 0.14285\n",
      "Epoch 129: | Train Loss: 0.11193 | Test Loss: 0.13558\n",
      "Epoch 130: | Train Loss: 0.10665 | Test Loss: 0.13576\n",
      "Epoch 131: | Train Loss: 0.12675 | Test Loss: 0.19424\n",
      "Epoch 132: | Train Loss: 0.13189 | Test Loss: 0.16819\n",
      "Epoch 133: | Train Loss: 0.12160 | Test Loss: 0.14318\n",
      "Epoch 134: | Train Loss: 0.11309 | Test Loss: 0.14515\n",
      "Epoch 135: | Train Loss: 0.11775 | Test Loss: 0.13207\n",
      "Epoch 136: | Train Loss: 0.11272 | Test Loss: 0.13482\n",
      "Epoch 137: | Train Loss: 0.10793 | Test Loss: 0.15014\n",
      "Epoch 138: | Train Loss: 0.13404 | Test Loss: 0.14631\n",
      "Epoch 139: | Train Loss: 0.11386 | Test Loss: 0.12962\n",
      "Epoch 140: | Train Loss: 0.11997 | Test Loss: 0.13481\n",
      "Epoch 141: | Train Loss: 0.10884 | Test Loss: 0.18201\n",
      "Epoch 142: | Train Loss: 0.12491 | Test Loss: 0.14538\n",
      "Epoch 143: | Train Loss: 0.16778 | Test Loss: 0.15070\n",
      "Epoch 144: | Train Loss: 0.11141 | Test Loss: 0.15258\n",
      "Epoch 145: | Train Loss: 0.11221 | Test Loss: 0.15828\n",
      "Epoch 146: | Train Loss: 0.11148 | Test Loss: 0.14455\n",
      "Epoch 147: | Train Loss: 0.11204 | Test Loss: 0.13335\n",
      "Epoch 148: | Train Loss: 0.11318 | Test Loss: 0.13718\n",
      "Epoch 149: | Train Loss: 0.10802 | Test Loss: 0.51856\n",
      "Epoch 150: | Train Loss: 0.11576 | Test Loss: 0.14272\n",
      "Epoch 151: | Train Loss: 0.11135 | Test Loss: 0.18647\n",
      "Epoch 152: | Train Loss: 0.13239 | Test Loss: 0.14743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: | Train Loss: 0.10562 | Test Loss: 0.12529\n",
      "Epoch 154: | Train Loss: 0.10273 | Test Loss: 0.14417\n",
      "Epoch 155: | Train Loss: 0.11026 | Test Loss: 0.13794\n",
      "Epoch 156: | Train Loss: 0.11469 | Test Loss: 0.13705\n",
      "Epoch 157: | Train Loss: 0.10621 | Test Loss: 0.14040\n",
      "Epoch 158: | Train Loss: 0.14130 | Test Loss: 0.17584\n",
      "Epoch 159: | Train Loss: 0.11716 | Test Loss: 0.18533\n",
      "Epoch 160: | Train Loss: 0.11403 | Test Loss: 0.15249\n",
      "Epoch 161: | Train Loss: 0.11210 | Test Loss: 0.14563\n",
      "Epoch 162: | Train Loss: 0.10988 | Test Loss: 0.14632\n",
      "Epoch 163: | Train Loss: 0.10630 | Test Loss: 0.16432\n",
      "Epoch 164: | Train Loss: 0.11296 | Test Loss: 0.14019\n",
      "Epoch 165: | Train Loss: 0.11120 | Test Loss: 0.15529\n",
      "Epoch 166: | Train Loss: 0.10464 | Test Loss: 0.14636\n",
      "Epoch 167: | Train Loss: 0.10245 | Test Loss: 0.15647\n",
      "Epoch 168: | Train Loss: 0.10597 | Test Loss: 0.15654\n",
      "Epoch 169: | Train Loss: 0.10207 | Test Loss: 0.19719\n",
      "Epoch 170: | Train Loss: 0.11672 | Test Loss: 0.15312\n",
      "Epoch 171: | Train Loss: 0.10805 | Test Loss: 0.15492\n",
      "Epoch 172: | Train Loss: 0.10944 | Test Loss: 0.18419\n",
      "Epoch 173: | Train Loss: 0.10438 | Test Loss: 0.15432\n",
      "Epoch 174: | Train Loss: 0.10339 | Test Loss: 0.17129\n",
      "Epoch 175: | Train Loss: 0.10408 | Test Loss: 0.14481\n",
      "Epoch 176: | Train Loss: 0.10650 | Test Loss: 0.17786\n",
      "Epoch 177: | Train Loss: 0.10589 | Test Loss: 0.18811\n",
      "Epoch 178: | Train Loss: 0.11439 | Test Loss: 0.22749\n",
      "Epoch 179: | Train Loss: 0.10320 | Test Loss: 0.16963\n",
      "Epoch 180: | Train Loss: 0.17635 | Test Loss: 0.40263\n",
      "Epoch 181: | Train Loss: 0.21686 | Test Loss: 0.14544\n",
      "Epoch 182: | Train Loss: 0.17661 | Test Loss: 0.17819\n",
      "Epoch 183: | Train Loss: 0.12394 | Test Loss: 0.14533\n",
      "Epoch 184: | Train Loss: 0.10211 | Test Loss: 0.16080\n",
      "Epoch 185: | Train Loss: 0.10969 | Test Loss: 0.14054\n",
      "Epoch 186: | Train Loss: 0.10433 | Test Loss: 0.15281\n",
      "Epoch 187: | Train Loss: 0.10232 | Test Loss: 0.16651\n",
      "Epoch 188: | Train Loss: 0.10107 | Test Loss: 0.17757\n",
      "Epoch 189: | Train Loss: 0.09811 | Test Loss: 0.21607\n",
      "Epoch 190: | Train Loss: 0.10382 | Test Loss: 0.13941\n",
      "Epoch 191: | Train Loss: 0.09973 | Test Loss: 0.18926\n",
      "Epoch 192: | Train Loss: 0.09982 | Test Loss: 0.17347\n",
      "Epoch 193: | Train Loss: 0.10132 | Test Loss: 0.17434\n",
      "Epoch 194: | Train Loss: 0.10364 | Test Loss: 0.18241\n",
      "Epoch 195: | Train Loss: 0.12284 | Test Loss: 0.17877\n",
      "Epoch 196: | Train Loss: 0.10450 | Test Loss: 0.16599\n",
      "Epoch 197: | Train Loss: 0.09992 | Test Loss: 0.17225\n",
      "Epoch 198: | Train Loss: 0.10551 | Test Loss: 0.14646\n",
      "Epoch 199: | Train Loss: 0.10806 | Test Loss: 0.19126\n",
      "Epoch 200: | Train Loss: 0.10373 | Test Loss: 0.14943\n",
      "Epoch 201: | Train Loss: 0.10579 | Test Loss: 0.15674\n",
      "Epoch 202: | Train Loss: 0.10557 | Test Loss: 0.15658\n",
      "Epoch 203: | Train Loss: 0.10444 | Test Loss: 0.16076\n",
      "Epoch 204: | Train Loss: 0.10012 | Test Loss: 0.15818\n",
      "Epoch 205: | Train Loss: 0.10979 | Test Loss: 0.16088\n",
      "Epoch 206: | Train Loss: 0.10892 | Test Loss: 0.14192\n",
      "Epoch 207: | Train Loss: 0.10569 | Test Loss: 0.14762\n",
      "Epoch 208: | Train Loss: 0.10395 | Test Loss: 0.20685\n",
      "Epoch 209: | Train Loss: 0.11406 | Test Loss: 0.15381\n",
      "Epoch 210: | Train Loss: 0.09883 | Test Loss: 0.14637\n",
      "Epoch 211: | Train Loss: 0.09728 | Test Loss: 0.18105\n",
      "Epoch 212: | Train Loss: 0.10518 | Test Loss: 0.17192\n",
      "Epoch 213: | Train Loss: 0.14536 | Test Loss: 0.14571\n",
      "Epoch 214: | Train Loss: 0.13496 | Test Loss: 0.15415\n",
      "Epoch 215: | Train Loss: 0.09681 | Test Loss: 0.14934\n",
      "Epoch 216: | Train Loss: 0.09488 | Test Loss: 0.17277\n",
      "Epoch 217: | Train Loss: 0.08798 | Test Loss: 0.14271\n",
      "Epoch 218: | Train Loss: 0.08570 | Test Loss: 0.14488\n",
      "Epoch 219: | Train Loss: 0.07882 | Test Loss: 0.14933\n",
      "Epoch 220: | Train Loss: 0.08325 | Test Loss: 0.14018\n",
      "Epoch 221: | Train Loss: 0.07297 | Test Loss: 0.13767\n",
      "Epoch 222: | Train Loss: 0.07210 | Test Loss: 0.14423\n",
      "Epoch 223: | Train Loss: 0.08170 | Test Loss: 0.15315\n",
      "Epoch 224: | Train Loss: 0.08209 | Test Loss: 0.18010\n",
      "Epoch 225: | Train Loss: 0.14879 | Test Loss: 0.16077\n",
      "Epoch 226: | Train Loss: 0.09383 | Test Loss: 0.14988\n",
      "Epoch 227: | Train Loss: 0.08848 | Test Loss: 0.23715\n",
      "Epoch 228: | Train Loss: 0.09520 | Test Loss: 0.13452\n",
      "Epoch 229: | Train Loss: 0.08946 | Test Loss: 0.13812\n",
      "Epoch 230: | Train Loss: 0.07325 | Test Loss: 0.13370\n",
      "Epoch 231: | Train Loss: 0.07506 | Test Loss: 0.13694\n",
      "Epoch 232: | Train Loss: 0.07401 | Test Loss: 0.15914\n",
      "Epoch 233: | Train Loss: 0.07162 | Test Loss: 0.14811\n",
      "Epoch 234: | Train Loss: 0.07122 | Test Loss: 0.17250\n",
      "Epoch 235: | Train Loss: 0.07337 | Test Loss: 0.16739\n",
      "Epoch 236: | Train Loss: 0.07868 | Test Loss: 0.16221\n",
      "Epoch 237: | Train Loss: 0.08750 | Test Loss: 0.14171\n",
      "Epoch 238: | Train Loss: 0.07784 | Test Loss: 0.16149\n",
      "Epoch 239: | Train Loss: 0.08412 | Test Loss: 0.14789\n",
      "Epoch 240: | Train Loss: 0.07093 | Test Loss: 0.17035\n",
      "stats of l2reg of  0.003 are [0.984   0.96826 0.06485 0.14957]\n",
      "running reg of 0.01\n",
      "initial run of high regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16878/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6b5be7df6341dcb3185f4da402fdc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 52.88378 | Test Loss: 27.61905\n",
      "Epoch 002: | Train Loss: 18.14614 | Test Loss: 0.56962\n",
      "Epoch 003: | Train Loss: 0.57596 | Test Loss: 0.48558\n",
      "Epoch 004: | Train Loss: 0.53992 | Test Loss: 0.94030\n",
      "Epoch 005: | Train Loss: 0.50145 | Test Loss: 0.59624\n",
      "Epoch 006: | Train Loss: 0.52615 | Test Loss: 0.45135\n",
      "Epoch 007: | Train Loss: 0.49159 | Test Loss: 0.45145\n",
      "Epoch 008: | Train Loss: 0.51698 | Test Loss: 0.49349\n",
      "Epoch 009: | Train Loss: 0.49410 | Test Loss: 0.42087\n",
      "Epoch 010: | Train Loss: 0.48263 | Test Loss: 0.45817\n",
      "Epoch 011: | Train Loss: 0.45974 | Test Loss: 0.45591\n",
      "Epoch 012: | Train Loss: 0.46568 | Test Loss: 0.40788\n",
      "Epoch 013: | Train Loss: 0.43838 | Test Loss: 0.43611\n",
      "Epoch 014: | Train Loss: 0.46424 | Test Loss: 0.45011\n",
      "Epoch 015: | Train Loss: 0.44797 | Test Loss: 0.44445\n",
      "Epoch 016: | Train Loss: 0.46487 | Test Loss: 0.44557\n",
      "Epoch 017: | Train Loss: 0.46168 | Test Loss: 0.46306\n",
      "Epoch 018: | Train Loss: 0.42835 | Test Loss: 0.58347\n",
      "Epoch 019: | Train Loss: 0.42780 | Test Loss: 0.41623\n",
      "Epoch 020: | Train Loss: 0.44702 | Test Loss: 0.43611\n",
      "run with given regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5533c219f6c5473c98bcc3f491184119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.42802 | Test Loss: 0.37945\n",
      "Epoch 002: | Train Loss: 0.45014 | Test Loss: 0.38065\n",
      "Epoch 003: | Train Loss: 0.43079 | Test Loss: 0.37023\n",
      "Epoch 004: | Train Loss: 0.38804 | Test Loss: 0.35625\n",
      "Epoch 005: | Train Loss: 0.38615 | Test Loss: 0.34387\n",
      "Epoch 006: | Train Loss: 0.38546 | Test Loss: 0.33994\n",
      "Epoch 007: | Train Loss: 0.38745 | Test Loss: 0.36675\n",
      "Epoch 008: | Train Loss: 0.36194 | Test Loss: 0.33794\n",
      "Epoch 009: | Train Loss: 0.35487 | Test Loss: 0.31936\n",
      "Epoch 010: | Train Loss: 0.34797 | Test Loss: 0.33959\n",
      "Epoch 011: | Train Loss: 0.35109 | Test Loss: 0.31702\n",
      "Epoch 012: | Train Loss: 0.30425 | Test Loss: 0.40318\n",
      "Epoch 013: | Train Loss: 0.32666 | Test Loss: 0.30914\n",
      "Epoch 014: | Train Loss: 0.33173 | Test Loss: 0.29240\n",
      "Epoch 015: | Train Loss: 0.32921 | Test Loss: 0.28295\n",
      "Epoch 016: | Train Loss: 0.33430 | Test Loss: 0.29158\n",
      "Epoch 017: | Train Loss: 0.29523 | Test Loss: 0.29243\n",
      "Epoch 018: | Train Loss: 0.30031 | Test Loss: 0.29515\n",
      "Epoch 019: | Train Loss: 0.28744 | Test Loss: 0.29597\n",
      "Epoch 020: | Train Loss: 0.28532 | Test Loss: 0.28084\n",
      "Epoch 021: | Train Loss: 0.28370 | Test Loss: 0.30487\n",
      "Epoch 022: | Train Loss: 0.27658 | Test Loss: 0.27938\n",
      "Epoch 023: | Train Loss: 0.26873 | Test Loss: 0.28356\n",
      "Epoch 024: | Train Loss: 0.27886 | Test Loss: 0.28610\n",
      "Epoch 025: | Train Loss: 0.30316 | Test Loss: 0.28687\n",
      "Epoch 026: | Train Loss: 0.28165 | Test Loss: 0.24855\n",
      "Epoch 027: | Train Loss: 0.27317 | Test Loss: 0.31976\n",
      "Epoch 028: | Train Loss: 0.27865 | Test Loss: 0.22511\n",
      "Epoch 029: | Train Loss: 0.27308 | Test Loss: 0.23051\n",
      "Epoch 030: | Train Loss: 0.23983 | Test Loss: 0.23817\n",
      "Epoch 031: | Train Loss: 0.25299 | Test Loss: 0.23025\n",
      "Epoch 032: | Train Loss: 0.24710 | Test Loss: 0.28941\n",
      "Epoch 033: | Train Loss: 0.25628 | Test Loss: 0.21230\n",
      "Epoch 034: | Train Loss: 0.23707 | Test Loss: 0.29971\n",
      "Epoch 035: | Train Loss: 0.24363 | Test Loss: 0.21363\n",
      "Epoch 036: | Train Loss: 0.25272 | Test Loss: 0.21759\n",
      "Epoch 037: | Train Loss: 0.25372 | Test Loss: 0.24592\n",
      "Epoch 038: | Train Loss: 0.23925 | Test Loss: 0.18896\n",
      "Epoch 039: | Train Loss: 0.21911 | Test Loss: 0.23752\n",
      "Epoch 040: | Train Loss: 0.19007 | Test Loss: 0.23431\n",
      "Epoch 041: | Train Loss: 0.21668 | Test Loss: 0.19278\n",
      "Epoch 042: | Train Loss: 0.17573 | Test Loss: 0.17546\n",
      "Epoch 043: | Train Loss: 0.17603 | Test Loss: 0.20608\n",
      "Epoch 044: | Train Loss: 0.15678 | Test Loss: 0.22149\n",
      "Epoch 045: | Train Loss: 0.19740 | Test Loss: 0.59166\n",
      "Epoch 046: | Train Loss: 0.18672 | Test Loss: 0.20185\n",
      "Epoch 047: | Train Loss: 0.19442 | Test Loss: 0.31782\n",
      "Epoch 048: | Train Loss: 0.19657 | Test Loss: 0.18350\n",
      "Epoch 049: | Train Loss: 0.21089 | Test Loss: 0.23766\n",
      "Epoch 050: | Train Loss: 0.19369 | Test Loss: 0.17513\n",
      "Epoch 051: | Train Loss: 0.18371 | Test Loss: 0.21056\n",
      "Epoch 052: | Train Loss: 0.18432 | Test Loss: 0.22509\n",
      "Epoch 053: | Train Loss: 0.19313 | Test Loss: 0.20582\n",
      "Epoch 054: | Train Loss: 0.19495 | Test Loss: 0.22873\n",
      "Epoch 055: | Train Loss: 0.19893 | Test Loss: 0.26684\n",
      "Epoch 056: | Train Loss: 0.16463 | Test Loss: 0.20838\n",
      "Epoch 057: | Train Loss: 0.18448 | Test Loss: 0.19908\n",
      "Epoch 058: | Train Loss: 0.18208 | Test Loss: 0.24811\n",
      "Epoch 059: | Train Loss: 0.18576 | Test Loss: 0.27577\n",
      "Epoch 060: | Train Loss: 0.20182 | Test Loss: 0.21224\n",
      "Epoch 061: | Train Loss: 0.15653 | Test Loss: 0.23236\n",
      "Epoch 062: | Train Loss: 0.15264 | Test Loss: 0.23680\n",
      "Epoch 063: | Train Loss: 0.17850 | Test Loss: 0.24909\n",
      "Epoch 064: | Train Loss: 0.18305 | Test Loss: 0.17867\n",
      "Epoch 065: | Train Loss: 0.19896 | Test Loss: 0.20252\n",
      "Epoch 066: | Train Loss: 0.17551 | Test Loss: 0.21406\n",
      "Epoch 067: | Train Loss: 0.18706 | Test Loss: 0.21407\n",
      "Epoch 068: | Train Loss: 0.17336 | Test Loss: 0.22632\n",
      "Epoch 069: | Train Loss: 0.17578 | Test Loss: 0.21095\n",
      "Epoch 070: | Train Loss: 0.17970 | Test Loss: 0.20378\n",
      "Epoch 071: | Train Loss: 0.17614 | Test Loss: 0.18663\n",
      "Epoch 072: | Train Loss: 0.16810 | Test Loss: 0.19916\n",
      "Epoch 073: | Train Loss: 0.17206 | Test Loss: 0.17028\n",
      "Epoch 074: | Train Loss: 0.17213 | Test Loss: 0.18823\n",
      "Epoch 075: | Train Loss: 0.16297 | Test Loss: 0.19373\n",
      "Epoch 076: | Train Loss: 0.15138 | Test Loss: 0.17597\n",
      "Epoch 077: | Train Loss: 0.16480 | Test Loss: 0.39720\n",
      "Epoch 078: | Train Loss: 0.15541 | Test Loss: 0.29193\n",
      "Epoch 079: | Train Loss: 0.18918 | Test Loss: 0.22124\n",
      "Epoch 080: | Train Loss: 0.15266 | Test Loss: 0.19641\n",
      "Epoch 081: | Train Loss: 0.15144 | Test Loss: 0.20751\n",
      "Epoch 082: | Train Loss: 0.16484 | Test Loss: 0.18829\n",
      "Epoch 083: | Train Loss: 0.16654 | Test Loss: 0.22810\n",
      "Epoch 084: | Train Loss: 0.14859 | Test Loss: 0.25137\n",
      "Epoch 085: | Train Loss: 0.17398 | Test Loss: 0.18913\n",
      "Epoch 086: | Train Loss: 0.14703 | Test Loss: 0.22641\n",
      "Epoch 087: | Train Loss: 0.15743 | Test Loss: 0.20518\n",
      "Epoch 088: | Train Loss: 0.17545 | Test Loss: 0.18745\n",
      "Epoch 089: | Train Loss: 0.17447 | Test Loss: 0.34239\n",
      "Epoch 090: | Train Loss: 0.16376 | Test Loss: 0.22255\n",
      "Epoch 091: | Train Loss: 0.19164 | Test Loss: 0.17827\n",
      "Epoch 092: | Train Loss: 0.15315 | Test Loss: 0.16482\n",
      "Epoch 093: | Train Loss: 0.15755 | Test Loss: 0.24725\n",
      "Epoch 094: | Train Loss: 0.15891 | Test Loss: 0.32345\n",
      "Epoch 095: | Train Loss: 0.15494 | Test Loss: 0.25778\n",
      "Epoch 096: | Train Loss: 0.16145 | Test Loss: 0.20046\n",
      "Epoch 097: | Train Loss: 0.13884 | Test Loss: 0.23185\n",
      "Epoch 098: | Train Loss: 0.17072 | Test Loss: 0.23076\n",
      "Epoch 099: | Train Loss: 0.15288 | Test Loss: 0.26243\n",
      "Epoch 100: | Train Loss: 0.15534 | Test Loss: 0.23192\n",
      "Epoch 101: | Train Loss: 0.17817 | Test Loss: 0.25745\n",
      "Epoch 102: | Train Loss: 0.14420 | Test Loss: 0.22315\n",
      "Epoch 103: | Train Loss: 0.14295 | Test Loss: 0.21499\n",
      "Epoch 104: | Train Loss: 0.17114 | Test Loss: 0.24975\n",
      "Epoch 105: | Train Loss: 0.14179 | Test Loss: 0.19727\n",
      "Epoch 106: | Train Loss: 0.15171 | Test Loss: 0.23933\n",
      "Epoch 107: | Train Loss: 0.13995 | Test Loss: 0.22862\n",
      "Epoch 108: | Train Loss: 0.22221 | Test Loss: 0.21012\n",
      "Epoch 109: | Train Loss: 0.15899 | Test Loss: 0.21059\n",
      "Epoch 110: | Train Loss: 0.16490 | Test Loss: 0.21945\n",
      "Epoch 111: | Train Loss: 0.16279 | Test Loss: 0.20829\n",
      "Epoch 112: | Train Loss: 0.13714 | Test Loss: 0.24549\n",
      "Epoch 113: | Train Loss: 0.14063 | Test Loss: 0.23424\n",
      "Epoch 114: | Train Loss: 0.14462 | Test Loss: 0.19728\n",
      "Epoch 115: | Train Loss: 0.14771 | Test Loss: 0.21379\n",
      "Epoch 116: | Train Loss: 0.14650 | Test Loss: 0.22556\n",
      "Epoch 117: | Train Loss: 0.14352 | Test Loss: 0.24211\n",
      "Epoch 118: | Train Loss: 0.16754 | Test Loss: 0.18528\n",
      "Epoch 119: | Train Loss: 0.15319 | Test Loss: 0.19080\n",
      "Epoch 120: | Train Loss: 0.14005 | Test Loss: 0.21185\n",
      "Epoch 121: | Train Loss: 0.14188 | Test Loss: 0.25024\n",
      "Epoch 122: | Train Loss: 0.14217 | Test Loss: 0.24539\n",
      "Epoch 123: | Train Loss: 0.15640 | Test Loss: 0.22396\n",
      "Epoch 124: | Train Loss: 0.14850 | Test Loss: 0.20652\n",
      "Epoch 125: | Train Loss: 0.14044 | Test Loss: 0.22187\n",
      "Epoch 126: | Train Loss: 0.15080 | Test Loss: 0.23080\n",
      "Epoch 127: | Train Loss: 0.13250 | Test Loss: 0.22590\n",
      "Epoch 128: | Train Loss: 0.13575 | Test Loss: 0.23354\n",
      "Epoch 129: | Train Loss: 0.13889 | Test Loss: 0.21942\n",
      "Epoch 130: | Train Loss: 0.16370 | Test Loss: 0.25418\n",
      "Epoch 131: | Train Loss: 0.15247 | Test Loss: 0.29592\n",
      "Epoch 132: | Train Loss: 0.15488 | Test Loss: 0.21654\n",
      "Epoch 133: | Train Loss: 0.14476 | Test Loss: 0.27597\n",
      "Epoch 134: | Train Loss: 0.16940 | Test Loss: 0.22005\n",
      "Epoch 135: | Train Loss: 0.15736 | Test Loss: 0.23689\n",
      "Epoch 136: | Train Loss: 0.14276 | Test Loss: 0.21881\n",
      "Epoch 137: | Train Loss: 0.13285 | Test Loss: 0.22229\n",
      "Epoch 138: | Train Loss: 0.14977 | Test Loss: 0.24379\n",
      "Epoch 139: | Train Loss: 0.16956 | Test Loss: 0.22254\n",
      "Epoch 140: | Train Loss: 0.17564 | Test Loss: 0.25843\n",
      "Epoch 141: | Train Loss: 0.16194 | Test Loss: 0.21960\n",
      "Epoch 142: | Train Loss: 0.14205 | Test Loss: 0.23626\n",
      "Epoch 143: | Train Loss: 0.15754 | Test Loss: 0.22799\n",
      "Epoch 144: | Train Loss: 0.14813 | Test Loss: 0.16670\n",
      "Epoch 145: | Train Loss: 0.13016 | Test Loss: 0.25189\n",
      "Epoch 146: | Train Loss: 0.16246 | Test Loss: 0.24340\n",
      "Epoch 147: | Train Loss: 0.15796 | Test Loss: 0.22694\n",
      "Epoch 148: | Train Loss: 0.19170 | Test Loss: 0.20948\n",
      "Epoch 149: | Train Loss: 0.15871 | Test Loss: 0.23155\n",
      "Epoch 150: | Train Loss: 0.13490 | Test Loss: 0.23672\n",
      "Epoch 151: | Train Loss: 0.13495 | Test Loss: 0.19821\n",
      "Epoch 152: | Train Loss: 0.13933 | Test Loss: 0.22149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: | Train Loss: 0.15523 | Test Loss: 0.22848\n",
      "Epoch 154: | Train Loss: 0.14840 | Test Loss: 0.24177\n",
      "Epoch 155: | Train Loss: 0.13795 | Test Loss: 0.22800\n",
      "Epoch 156: | Train Loss: 0.14048 | Test Loss: 0.22160\n",
      "Epoch 157: | Train Loss: 0.13311 | Test Loss: 0.22598\n",
      "Epoch 158: | Train Loss: 0.14410 | Test Loss: 0.22688\n",
      "Epoch 159: | Train Loss: 0.16246 | Test Loss: 0.23311\n",
      "Epoch 160: | Train Loss: 0.13701 | Test Loss: 0.24438\n",
      "Epoch 161: | Train Loss: 0.13503 | Test Loss: 0.23272\n",
      "Epoch 162: | Train Loss: 0.14736 | Test Loss: 0.22878\n",
      "Epoch 163: | Train Loss: 0.13200 | Test Loss: 0.29288\n",
      "Epoch 164: | Train Loss: 0.13398 | Test Loss: 0.22761\n",
      "Epoch 165: | Train Loss: 0.15454 | Test Loss: 0.22758\n",
      "Epoch 166: | Train Loss: 0.14225 | Test Loss: 0.28060\n",
      "Epoch 167: | Train Loss: 0.15016 | Test Loss: 0.21677\n",
      "Epoch 168: | Train Loss: 0.13481 | Test Loss: 0.36425\n",
      "Epoch 169: | Train Loss: 0.14119 | Test Loss: 0.20872\n",
      "Epoch 170: | Train Loss: 0.15613 | Test Loss: 0.23427\n",
      "Epoch 171: | Train Loss: 0.14568 | Test Loss: 0.22592\n",
      "Epoch 172: | Train Loss: 0.13656 | Test Loss: 0.21651\n",
      "Epoch 173: | Train Loss: 0.13871 | Test Loss: 0.23196\n",
      "Epoch 174: | Train Loss: 0.13423 | Test Loss: 0.22251\n",
      "Epoch 175: | Train Loss: 0.13519 | Test Loss: 0.22453\n",
      "Epoch 176: | Train Loss: 0.16527 | Test Loss: 0.26764\n",
      "Epoch 177: | Train Loss: 0.14227 | Test Loss: 0.22436\n",
      "Epoch 178: | Train Loss: 0.15791 | Test Loss: 0.21890\n",
      "Epoch 179: | Train Loss: 0.12995 | Test Loss: 0.22138\n",
      "Epoch 180: | Train Loss: 0.13147 | Test Loss: 0.21113\n",
      "Epoch 181: | Train Loss: 0.16655 | Test Loss: 0.27701\n",
      "Epoch 182: | Train Loss: 0.14029 | Test Loss: 0.21763\n",
      "Epoch 183: | Train Loss: 0.13151 | Test Loss: 0.21675\n",
      "Epoch 184: | Train Loss: 0.15946 | Test Loss: 0.24902\n",
      "Epoch 185: | Train Loss: 0.13504 | Test Loss: 0.21471\n",
      "Epoch 186: | Train Loss: 0.13942 | Test Loss: 0.28684\n",
      "Epoch 187: | Train Loss: 0.14341 | Test Loss: 0.24283\n",
      "Epoch 188: | Train Loss: 0.15863 | Test Loss: 0.22728\n",
      "Epoch 189: | Train Loss: 0.13700 | Test Loss: 0.23651\n",
      "Epoch 190: | Train Loss: 0.13382 | Test Loss: 0.23898\n",
      "Epoch 191: | Train Loss: 0.15792 | Test Loss: 0.23412\n",
      "Epoch 192: | Train Loss: 0.14111 | Test Loss: 0.24264\n",
      "Epoch 193: | Train Loss: 0.13735 | Test Loss: 0.22036\n",
      "Epoch 194: | Train Loss: 0.13944 | Test Loss: 0.21862\n",
      "Epoch 195: | Train Loss: 0.14285 | Test Loss: 0.22012\n",
      "Epoch 196: | Train Loss: 0.15213 | Test Loss: 0.24552\n",
      "Epoch 197: | Train Loss: 0.14164 | Test Loss: 0.22207\n",
      "Epoch 198: | Train Loss: 0.13829 | Test Loss: 0.24554\n",
      "Epoch 199: | Train Loss: 0.17134 | Test Loss: 0.21611\n",
      "Epoch 200: | Train Loss: 0.16016 | Test Loss: 0.21209\n",
      "Epoch 201: | Train Loss: 0.14945 | Test Loss: 0.22749\n",
      "Epoch 202: | Train Loss: 0.15983 | Test Loss: 0.23381\n",
      "Epoch 203: | Train Loss: 0.14159 | Test Loss: 0.22862\n",
      "Epoch 204: | Train Loss: 0.13865 | Test Loss: 0.22613\n",
      "Epoch 205: | Train Loss: 0.13725 | Test Loss: 0.21785\n",
      "Epoch 206: | Train Loss: 0.15782 | Test Loss: 0.27897\n",
      "Epoch 207: | Train Loss: 0.12901 | Test Loss: 0.21053\n",
      "Epoch 208: | Train Loss: 0.13823 | Test Loss: 0.22103\n",
      "Epoch 209: | Train Loss: 0.12698 | Test Loss: 0.23473\n",
      "Epoch 210: | Train Loss: 0.12450 | Test Loss: 0.27459\n",
      "Epoch 211: | Train Loss: 0.13126 | Test Loss: 0.21089\n",
      "Epoch 212: | Train Loss: 0.13764 | Test Loss: 0.22387\n",
      "Epoch 213: | Train Loss: 0.16467 | Test Loss: 0.22301\n",
      "Epoch 214: | Train Loss: 0.15607 | Test Loss: 0.25552\n",
      "Epoch 215: | Train Loss: 0.13112 | Test Loss: 0.23543\n",
      "Epoch 216: | Train Loss: 0.13730 | Test Loss: 0.22114\n",
      "Epoch 217: | Train Loss: 0.13446 | Test Loss: 0.22135\n",
      "Epoch 218: | Train Loss: 0.13082 | Test Loss: 0.22167\n",
      "Epoch 219: | Train Loss: 0.14390 | Test Loss: 0.21928\n",
      "Epoch 220: | Train Loss: 0.13591 | Test Loss: 0.23279\n",
      "Epoch 221: | Train Loss: 0.13078 | Test Loss: 0.22701\n",
      "Epoch 222: | Train Loss: 0.13133 | Test Loss: 0.27914\n",
      "Epoch 223: | Train Loss: 0.13323 | Test Loss: 0.22719\n",
      "Epoch 224: | Train Loss: 0.15075 | Test Loss: 0.21705\n",
      "Epoch 225: | Train Loss: 0.15007 | Test Loss: 0.22222\n",
      "Epoch 226: | Train Loss: 0.14265 | Test Loss: 0.22532\n",
      "Epoch 227: | Train Loss: 0.13457 | Test Loss: 0.22322\n",
      "Epoch 228: | Train Loss: 0.15779 | Test Loss: 0.23097\n",
      "Epoch 229: | Train Loss: 0.14152 | Test Loss: 0.22734\n",
      "Epoch 230: | Train Loss: 0.15450 | Test Loss: 0.22271\n",
      "Epoch 231: | Train Loss: 0.17490 | Test Loss: 0.22560\n",
      "Epoch 232: | Train Loss: 0.16641 | Test Loss: 0.22498\n",
      "Epoch 233: | Train Loss: 0.12942 | Test Loss: 0.23529\n",
      "Epoch 234: | Train Loss: 0.13315 | Test Loss: 0.20560\n",
      "Epoch 235: | Train Loss: 0.13603 | Test Loss: 0.23582\n",
      "Epoch 236: | Train Loss: 0.12688 | Test Loss: 0.21899\n",
      "Epoch 237: | Train Loss: 0.13323 | Test Loss: 0.23168\n",
      "Epoch 238: | Train Loss: 0.13802 | Test Loss: 0.21861\n",
      "Epoch 239: | Train Loss: 0.13393 | Test Loss: 0.22878\n",
      "Epoch 240: | Train Loss: 0.14586 | Test Loss: 0.22046\n",
      "stats of l2reg of  0.01 are [0.97817 0.96538 0.10727 0.1789 ]\n",
      "running reg of 0.03\n",
      "initial run of high regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16878/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23caace92cb04b98a26b9c98ff0eeb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 26.16111 | Test Loss: 27.61905\n",
      "Epoch 002: | Train Loss: 25.91140 | Test Loss: 27.37370\n",
      "Epoch 003: | Train Loss: 4.27238 | Test Loss: 0.53893\n",
      "Epoch 004: | Train Loss: 0.54456 | Test Loss: 0.74218\n",
      "Epoch 005: | Train Loss: 0.49715 | Test Loss: 0.59413\n",
      "Epoch 006: | Train Loss: 0.48035 | Test Loss: 0.55873\n",
      "Epoch 007: | Train Loss: 0.48569 | Test Loss: 0.47163\n",
      "Epoch 008: | Train Loss: 0.50970 | Test Loss: 0.47321\n",
      "Epoch 009: | Train Loss: 0.50985 | Test Loss: 0.47123\n",
      "Epoch 010: | Train Loss: 0.50849 | Test Loss: 0.46974\n",
      "Epoch 011: | Train Loss: 0.46972 | Test Loss: 0.69036\n",
      "Epoch 012: | Train Loss: 0.47107 | Test Loss: 0.45714\n",
      "Epoch 013: | Train Loss: 0.50466 | Test Loss: 0.48399\n",
      "Epoch 014: | Train Loss: 0.49071 | Test Loss: 0.53203\n",
      "Epoch 015: | Train Loss: 0.47716 | Test Loss: 0.49394\n",
      "Epoch 016: | Train Loss: 0.47663 | Test Loss: 0.49887\n",
      "Epoch 017: | Train Loss: 0.45578 | Test Loss: 0.66542\n",
      "Epoch 018: | Train Loss: 0.45386 | Test Loss: 0.55368\n",
      "Epoch 019: | Train Loss: 0.45863 | Test Loss: 0.46185\n",
      "Epoch 020: | Train Loss: 0.45536 | Test Loss: 0.54033\n",
      "run with given regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e285a3fbf0dd4cde89bf67e02d75a736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.43348 | Test Loss: 0.62300\n",
      "Epoch 002: | Train Loss: 0.40549 | Test Loss: 0.41325\n",
      "Epoch 003: | Train Loss: 0.44475 | Test Loss: 0.38896\n",
      "Epoch 004: | Train Loss: 0.41073 | Test Loss: 0.39572\n",
      "Epoch 005: | Train Loss: 0.37917 | Test Loss: 0.43568\n",
      "Epoch 006: | Train Loss: 0.39131 | Test Loss: 0.40658\n",
      "Epoch 007: | Train Loss: 0.37308 | Test Loss: 0.43968\n",
      "Epoch 008: | Train Loss: 0.36693 | Test Loss: 0.42301\n",
      "Epoch 009: | Train Loss: 0.37176 | Test Loss: 0.36176\n",
      "Epoch 010: | Train Loss: 0.36947 | Test Loss: 0.40284\n",
      "Epoch 011: | Train Loss: 0.37014 | Test Loss: 0.36896\n",
      "Epoch 012: | Train Loss: 0.39850 | Test Loss: 0.38036\n",
      "Epoch 013: | Train Loss: 0.35640 | Test Loss: 0.44434\n",
      "Epoch 014: | Train Loss: 0.34459 | Test Loss: 0.36641\n",
      "Epoch 015: | Train Loss: 0.35420 | Test Loss: 0.35654\n",
      "Epoch 016: | Train Loss: 0.35001 | Test Loss: 0.35881\n",
      "Epoch 017: | Train Loss: 0.34141 | Test Loss: 0.35982\n",
      "Epoch 018: | Train Loss: 0.34635 | Test Loss: 0.37531\n",
      "Epoch 019: | Train Loss: 0.33043 | Test Loss: 0.39970\n",
      "Epoch 020: | Train Loss: 0.33808 | Test Loss: 0.36149\n",
      "Epoch 021: | Train Loss: 0.36226 | Test Loss: 0.37243\n",
      "Epoch 022: | Train Loss: 0.33591 | Test Loss: 0.36076\n",
      "Epoch 023: | Train Loss: 0.35857 | Test Loss: 0.39237\n",
      "Epoch 024: | Train Loss: 0.31423 | Test Loss: 0.40820\n",
      "Epoch 025: | Train Loss: 0.31749 | Test Loss: 0.42029\n",
      "Epoch 026: | Train Loss: 0.33631 | Test Loss: 0.37512\n",
      "Epoch 027: | Train Loss: 0.36201 | Test Loss: 0.35847\n",
      "Epoch 028: | Train Loss: 0.33327 | Test Loss: 0.37399\n",
      "Epoch 029: | Train Loss: 0.35403 | Test Loss: 0.40417\n",
      "Epoch 030: | Train Loss: 0.32891 | Test Loss: 0.35694\n",
      "Epoch 031: | Train Loss: 0.31789 | Test Loss: 0.36120\n",
      "Epoch 032: | Train Loss: 0.31661 | Test Loss: 0.41740\n",
      "Epoch 033: | Train Loss: 0.33773 | Test Loss: 0.34755\n",
      "Epoch 034: | Train Loss: 0.31161 | Test Loss: 0.34731\n",
      "Epoch 035: | Train Loss: 0.36501 | Test Loss: 0.36581\n",
      "Epoch 036: | Train Loss: 0.30536 | Test Loss: 0.35503\n",
      "Epoch 037: | Train Loss: 0.29730 | Test Loss: 0.40371\n",
      "Epoch 038: | Train Loss: 0.32792 | Test Loss: 0.34796\n",
      "Epoch 039: | Train Loss: 0.32277 | Test Loss: 0.34202\n",
      "Epoch 040: | Train Loss: 0.29330 | Test Loss: 0.38464\n",
      "Epoch 041: | Train Loss: 0.32728 | Test Loss: 0.35674\n",
      "Epoch 042: | Train Loss: 0.29014 | Test Loss: 0.35409\n",
      "Epoch 043: | Train Loss: 0.36168 | Test Loss: 0.36444\n",
      "Epoch 044: | Train Loss: 0.29457 | Test Loss: 0.34278\n",
      "Epoch 045: | Train Loss: 0.30142 | Test Loss: 0.33563\n",
      "Epoch 046: | Train Loss: 0.29405 | Test Loss: 0.33064\n",
      "Epoch 047: | Train Loss: 0.29341 | Test Loss: 0.38736\n",
      "Epoch 048: | Train Loss: 0.28748 | Test Loss: 0.50485\n",
      "Epoch 049: | Train Loss: 0.29370 | Test Loss: 0.34152\n",
      "Epoch 050: | Train Loss: 0.28808 | Test Loss: 0.35801\n",
      "Epoch 051: | Train Loss: 0.28987 | Test Loss: 0.33910\n",
      "Epoch 052: | Train Loss: 0.32290 | Test Loss: 0.33937\n",
      "Epoch 053: | Train Loss: 0.30368 | Test Loss: 0.33659\n",
      "Epoch 054: | Train Loss: 0.27765 | Test Loss: 0.33983\n",
      "Epoch 055: | Train Loss: 0.28470 | Test Loss: 0.34476\n",
      "Epoch 056: | Train Loss: 0.31981 | Test Loss: 0.33333\n",
      "Epoch 057: | Train Loss: 0.28952 | Test Loss: 0.33454\n",
      "Epoch 058: | Train Loss: 0.28718 | Test Loss: 0.32791\n",
      "Epoch 059: | Train Loss: 0.26943 | Test Loss: 0.33115\n",
      "Epoch 060: | Train Loss: 0.29967 | Test Loss: 0.32280\n",
      "Epoch 061: | Train Loss: 0.30534 | Test Loss: 0.35131\n",
      "Epoch 062: | Train Loss: 0.28149 | Test Loss: 0.33077\n",
      "Epoch 063: | Train Loss: 0.26812 | Test Loss: 0.31790\n",
      "Epoch 064: | Train Loss: 0.28741 | Test Loss: 0.31615\n",
      "Epoch 065: | Train Loss: 0.29748 | Test Loss: 0.31204\n",
      "Epoch 066: | Train Loss: 0.26769 | Test Loss: 0.33526\n",
      "Epoch 067: | Train Loss: 0.26202 | Test Loss: 0.38525\n",
      "Epoch 068: | Train Loss: 0.28273 | Test Loss: 0.32092\n",
      "Epoch 069: | Train Loss: 0.28670 | Test Loss: 0.37755\n",
      "Epoch 070: | Train Loss: 0.26771 | Test Loss: 0.34949\n",
      "Epoch 071: | Train Loss: 0.25912 | Test Loss: 0.33049\n",
      "Epoch 072: | Train Loss: 0.25572 | Test Loss: 0.32526\n",
      "Epoch 073: | Train Loss: 0.26760 | Test Loss: 0.33311\n",
      "Epoch 074: | Train Loss: 0.27079 | Test Loss: 0.32547\n",
      "Epoch 075: | Train Loss: 0.26319 | Test Loss: 0.32205\n",
      "Epoch 076: | Train Loss: 0.26754 | Test Loss: 0.33585\n",
      "Epoch 077: | Train Loss: 0.27216 | Test Loss: 0.33127\n",
      "Epoch 078: | Train Loss: 0.25725 | Test Loss: 0.39074\n",
      "Epoch 079: | Train Loss: 0.27105 | Test Loss: 0.29216\n",
      "Epoch 080: | Train Loss: 0.27347 | Test Loss: 0.28614\n",
      "Epoch 081: | Train Loss: 0.28224 | Test Loss: 0.30903\n",
      "Epoch 082: | Train Loss: 0.25445 | Test Loss: 0.28637\n",
      "Epoch 083: | Train Loss: 0.25952 | Test Loss: 0.30174\n",
      "Epoch 084: | Train Loss: 0.26572 | Test Loss: 0.32471\n",
      "Epoch 085: | Train Loss: 0.26541 | Test Loss: 0.31541\n",
      "Epoch 086: | Train Loss: 0.25238 | Test Loss: 0.30554\n",
      "Epoch 087: | Train Loss: 0.24886 | Test Loss: 0.31506\n",
      "Epoch 088: | Train Loss: 0.25240 | Test Loss: 0.29545\n",
      "Epoch 089: | Train Loss: 0.26654 | Test Loss: 0.27485\n",
      "Epoch 090: | Train Loss: 0.28412 | Test Loss: 0.27000\n",
      "Epoch 091: | Train Loss: 0.27006 | Test Loss: 0.29699\n",
      "Epoch 092: | Train Loss: 0.24690 | Test Loss: 0.27691\n",
      "Epoch 093: | Train Loss: 0.26732 | Test Loss: 0.26732\n",
      "Epoch 094: | Train Loss: 0.24146 | Test Loss: 0.32969\n",
      "Epoch 095: | Train Loss: 0.27787 | Test Loss: 0.29197\n",
      "Epoch 096: | Train Loss: 0.28960 | Test Loss: 0.28979\n",
      "Epoch 097: | Train Loss: 0.27256 | Test Loss: 0.29855\n",
      "Epoch 098: | Train Loss: 0.26661 | Test Loss: 0.27003\n",
      "Epoch 099: | Train Loss: 0.24744 | Test Loss: 0.26831\n",
      "Epoch 100: | Train Loss: 0.26590 | Test Loss: 0.24962\n",
      "Epoch 101: | Train Loss: 0.26678 | Test Loss: 0.26170\n",
      "Epoch 102: | Train Loss: 0.26673 | Test Loss: 0.25302\n",
      "Epoch 103: | Train Loss: 0.25815 | Test Loss: 0.24529\n",
      "Epoch 104: | Train Loss: 0.28590 | Test Loss: 0.27442\n",
      "Epoch 105: | Train Loss: 0.24083 | Test Loss: 0.27194\n",
      "Epoch 106: | Train Loss: 0.25923 | Test Loss: 0.24728\n",
      "Epoch 107: | Train Loss: 0.22990 | Test Loss: 0.25284\n",
      "Epoch 108: | Train Loss: 0.27395 | Test Loss: 0.24824\n",
      "Epoch 109: | Train Loss: 0.26025 | Test Loss: 0.24369\n",
      "Epoch 110: | Train Loss: 0.25665 | Test Loss: 0.24740\n",
      "Epoch 111: | Train Loss: 0.24032 | Test Loss: 0.25784\n",
      "Epoch 112: | Train Loss: 0.26040 | Test Loss: 0.26529\n",
      "Epoch 113: | Train Loss: 0.27425 | Test Loss: 0.26917\n",
      "Epoch 114: | Train Loss: 0.26300 | Test Loss: 0.26781\n",
      "Epoch 115: | Train Loss: 0.25883 | Test Loss: 0.23448\n",
      "Epoch 116: | Train Loss: 0.26597 | Test Loss: 0.23987\n",
      "Epoch 117: | Train Loss: 0.23792 | Test Loss: 0.21682\n",
      "Epoch 118: | Train Loss: 0.23612 | Test Loss: 0.21577\n",
      "Epoch 119: | Train Loss: 0.25622 | Test Loss: 0.20640\n",
      "Epoch 120: | Train Loss: 0.24053 | Test Loss: 0.24236\n",
      "Epoch 121: | Train Loss: 0.21924 | Test Loss: 0.24891\n",
      "Epoch 122: | Train Loss: 0.22660 | Test Loss: 0.25087\n",
      "Epoch 123: | Train Loss: 0.25626 | Test Loss: 0.25884\n",
      "Epoch 124: | Train Loss: 0.23021 | Test Loss: 0.25436\n",
      "Epoch 125: | Train Loss: 0.23782 | Test Loss: 0.24800\n",
      "Epoch 126: | Train Loss: 0.23575 | Test Loss: 0.23134\n",
      "Epoch 127: | Train Loss: 0.24515 | Test Loss: 0.22516\n",
      "Epoch 128: | Train Loss: 0.23316 | Test Loss: 0.24363\n",
      "Epoch 129: | Train Loss: 0.22994 | Test Loss: 0.27237\n",
      "Epoch 130: | Train Loss: 0.22929 | Test Loss: 0.58657\n",
      "Epoch 131: | Train Loss: 0.22590 | Test Loss: 0.23962\n",
      "Epoch 132: | Train Loss: 0.21364 | Test Loss: 0.26328\n",
      "Epoch 133: | Train Loss: 0.23423 | Test Loss: 0.23576\n",
      "Epoch 134: | Train Loss: 0.23306 | Test Loss: 0.24035\n",
      "Epoch 135: | Train Loss: 0.23429 | Test Loss: 0.28170\n",
      "Epoch 136: | Train Loss: 0.22709 | Test Loss: 0.25758\n",
      "Epoch 137: | Train Loss: 0.24565 | Test Loss: 0.25223\n",
      "Epoch 138: | Train Loss: 0.23004 | Test Loss: 0.21394\n",
      "Epoch 139: | Train Loss: 0.24561 | Test Loss: 0.24555\n",
      "Epoch 140: | Train Loss: 0.23128 | Test Loss: 0.24527\n",
      "Epoch 141: | Train Loss: 0.23540 | Test Loss: 0.24723\n",
      "Epoch 142: | Train Loss: 0.22467 | Test Loss: 0.23909\n",
      "Epoch 143: | Train Loss: 0.24871 | Test Loss: 0.23807\n",
      "Epoch 144: | Train Loss: 0.24189 | Test Loss: 0.28071\n",
      "Epoch 145: | Train Loss: 0.21854 | Test Loss: 0.24244\n",
      "Epoch 146: | Train Loss: 0.23034 | Test Loss: 0.25821\n",
      "Epoch 147: | Train Loss: 0.24012 | Test Loss: 0.24625\n",
      "Epoch 148: | Train Loss: 0.22088 | Test Loss: 0.21651\n",
      "Epoch 149: | Train Loss: 0.23028 | Test Loss: 0.21569\n",
      "Epoch 150: | Train Loss: 0.22632 | Test Loss: 0.24106\n",
      "Epoch 151: | Train Loss: 0.22444 | Test Loss: 0.22959\n",
      "Epoch 152: | Train Loss: 0.22269 | Test Loss: 0.23236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: | Train Loss: 0.22788 | Test Loss: 0.22660\n",
      "Epoch 154: | Train Loss: 0.22776 | Test Loss: 0.23387\n",
      "Epoch 155: | Train Loss: 0.23160 | Test Loss: 0.25718\n",
      "Epoch 156: | Train Loss: 0.23124 | Test Loss: 0.22445\n",
      "Epoch 157: | Train Loss: 0.25090 | Test Loss: 0.25173\n",
      "Epoch 158: | Train Loss: 0.24203 | Test Loss: 0.23441\n",
      "Epoch 159: | Train Loss: 0.23980 | Test Loss: 0.26757\n",
      "Epoch 160: | Train Loss: 0.22416 | Test Loss: 0.24451\n",
      "Epoch 161: | Train Loss: 0.23155 | Test Loss: 0.25724\n",
      "Epoch 162: | Train Loss: 0.22620 | Test Loss: 0.20948\n",
      "Epoch 163: | Train Loss: 0.22580 | Test Loss: 0.23547\n",
      "Epoch 164: | Train Loss: 0.23832 | Test Loss: 0.24027\n",
      "Epoch 165: | Train Loss: 0.22243 | Test Loss: 0.21870\n",
      "Epoch 166: | Train Loss: 0.22581 | Test Loss: 0.23043\n",
      "Epoch 167: | Train Loss: 0.24462 | Test Loss: 0.23637\n",
      "Epoch 168: | Train Loss: 0.23240 | Test Loss: 0.22830\n",
      "Epoch 169: | Train Loss: 0.23002 | Test Loss: 0.26459\n",
      "Epoch 170: | Train Loss: 0.23103 | Test Loss: 0.25168\n",
      "Epoch 171: | Train Loss: 0.22220 | Test Loss: 0.20696\n",
      "Epoch 172: | Train Loss: 0.23305 | Test Loss: 0.23586\n",
      "Epoch 173: | Train Loss: 0.22309 | Test Loss: 0.21540\n",
      "Epoch 174: | Train Loss: 0.23102 | Test Loss: 0.24601\n",
      "Epoch 175: | Train Loss: 0.22748 | Test Loss: 0.28197\n",
      "Epoch 176: | Train Loss: 0.23273 | Test Loss: 0.28839\n",
      "Epoch 177: | Train Loss: 0.22684 | Test Loss: 0.24535\n",
      "Epoch 178: | Train Loss: 0.21348 | Test Loss: 0.23161\n",
      "Epoch 179: | Train Loss: 0.22289 | Test Loss: 0.20775\n",
      "Epoch 180: | Train Loss: 0.24273 | Test Loss: 0.22906\n",
      "Epoch 181: | Train Loss: 0.25489 | Test Loss: 0.23721\n",
      "Epoch 182: | Train Loss: 0.23179 | Test Loss: 0.20700\n",
      "Epoch 183: | Train Loss: 0.23427 | Test Loss: 0.25122\n",
      "Epoch 184: | Train Loss: 0.22421 | Test Loss: 0.24253\n",
      "Epoch 185: | Train Loss: 0.22409 | Test Loss: 0.28062\n",
      "Epoch 186: | Train Loss: 0.21901 | Test Loss: 0.23830\n",
      "Epoch 187: | Train Loss: 0.21610 | Test Loss: 0.28623\n",
      "Epoch 188: | Train Loss: 0.22588 | Test Loss: 0.25949\n",
      "Epoch 189: | Train Loss: 0.22900 | Test Loss: 0.23787\n",
      "Epoch 190: | Train Loss: 0.23257 | Test Loss: 0.26363\n",
      "Epoch 191: | Train Loss: 0.22332 | Test Loss: 0.27870\n",
      "Epoch 192: | Train Loss: 0.23414 | Test Loss: 0.24154\n",
      "Epoch 193: | Train Loss: 0.22776 | Test Loss: 0.25116\n",
      "Epoch 194: | Train Loss: 0.22820 | Test Loss: 0.23435\n",
      "Epoch 195: | Train Loss: 0.23533 | Test Loss: 0.24348\n",
      "Epoch 196: | Train Loss: 0.22557 | Test Loss: 0.26314\n",
      "Epoch 197: | Train Loss: 0.21713 | Test Loss: 0.23814\n",
      "Epoch 198: | Train Loss: 0.24842 | Test Loss: 0.22645\n",
      "Epoch 199: | Train Loss: 0.22834 | Test Loss: 0.20727\n",
      "Epoch 200: | Train Loss: 0.24672 | Test Loss: 0.27381\n",
      "Epoch 201: | Train Loss: 0.22154 | Test Loss: 0.20179\n",
      "Epoch 202: | Train Loss: 0.22042 | Test Loss: 0.26496\n",
      "Epoch 203: | Train Loss: 0.24442 | Test Loss: 0.22403\n",
      "Epoch 204: | Train Loss: 0.21863 | Test Loss: 0.19722\n",
      "Epoch 205: | Train Loss: 0.21653 | Test Loss: 0.21099\n",
      "Epoch 206: | Train Loss: 0.23965 | Test Loss: 0.26955\n",
      "Epoch 207: | Train Loss: 0.23450 | Test Loss: 0.25684\n",
      "Epoch 208: | Train Loss: 0.23589 | Test Loss: 0.23886\n",
      "Epoch 209: | Train Loss: 0.24024 | Test Loss: 0.27893\n",
      "Epoch 210: | Train Loss: 0.24882 | Test Loss: 0.23173\n",
      "Epoch 211: | Train Loss: 0.21870 | Test Loss: 0.22787\n",
      "Epoch 212: | Train Loss: 0.23683 | Test Loss: 0.27200\n",
      "Epoch 213: | Train Loss: 0.23037 | Test Loss: 0.26578\n",
      "Epoch 214: | Train Loss: 0.21446 | Test Loss: 0.27853\n",
      "Epoch 215: | Train Loss: 0.27656 | Test Loss: 0.27470\n",
      "Epoch 216: | Train Loss: 0.25583 | Test Loss: 0.23265\n",
      "Epoch 217: | Train Loss: 0.21974 | Test Loss: 0.26065\n",
      "Epoch 218: | Train Loss: 0.22033 | Test Loss: 0.22405\n",
      "Epoch 219: | Train Loss: 0.22037 | Test Loss: 0.25933\n",
      "Epoch 220: | Train Loss: 0.24090 | Test Loss: 0.27296\n",
      "Epoch 221: | Train Loss: 0.21658 | Test Loss: 0.24656\n",
      "Epoch 222: | Train Loss: 0.21530 | Test Loss: 0.23489\n",
      "Epoch 223: | Train Loss: 0.23819 | Test Loss: 0.24198\n",
      "Epoch 224: | Train Loss: 0.20346 | Test Loss: 0.22811\n",
      "Epoch 225: | Train Loss: 0.22681 | Test Loss: 0.23352\n",
      "Epoch 226: | Train Loss: 0.21650 | Test Loss: 0.22847\n",
      "Epoch 227: | Train Loss: 0.21991 | Test Loss: 0.23988\n",
      "Epoch 228: | Train Loss: 0.24077 | Test Loss: 0.25486\n",
      "Epoch 229: | Train Loss: 0.23333 | Test Loss: 0.26056\n",
      "Epoch 230: | Train Loss: 0.22408 | Test Loss: 0.22979\n",
      "Epoch 231: | Train Loss: 0.24087 | Test Loss: 0.24257\n",
      "Epoch 232: | Train Loss: 0.21673 | Test Loss: 0.25968\n",
      "Epoch 233: | Train Loss: 0.23306 | Test Loss: 0.25930\n",
      "Epoch 234: | Train Loss: 0.23635 | Test Loss: 0.23687\n",
      "Epoch 235: | Train Loss: 0.21769 | Test Loss: 0.24964\n",
      "Epoch 236: | Train Loss: 0.22866 | Test Loss: 0.22607\n",
      "Epoch 237: | Train Loss: 0.22694 | Test Loss: 0.27007\n",
      "Epoch 238: | Train Loss: 0.21858 | Test Loss: 0.26240\n",
      "Epoch 239: | Train Loss: 0.21444 | Test Loss: 0.26862\n",
      "Epoch 240: | Train Loss: 0.22027 | Test Loss: 0.28338\n",
      "stats of l2reg of  0.03 are [0.96289 0.95639 0.18411 0.24181]\n",
      "running reg of 0.1\n",
      "initial run of high regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16878/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2116c81e4f742aea6eb3aa5f76bda6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 18.44536 | Test Loss: 0.60316\n",
      "Epoch 002: | Train Loss: 0.52855 | Test Loss: 0.50289\n",
      "Epoch 003: | Train Loss: 0.48506 | Test Loss: 0.47577\n",
      "Epoch 004: | Train Loss: 0.47376 | Test Loss: 0.48160\n",
      "Epoch 005: | Train Loss: 0.46569 | Test Loss: 0.58106\n",
      "Epoch 006: | Train Loss: 0.45690 | Test Loss: 0.45904\n",
      "Epoch 007: | Train Loss: 0.48816 | Test Loss: 0.44540\n",
      "Epoch 008: | Train Loss: 0.46643 | Test Loss: 0.46648\n",
      "Epoch 009: | Train Loss: 0.46065 | Test Loss: 0.47069\n",
      "Epoch 010: | Train Loss: 0.47728 | Test Loss: 0.41546\n",
      "Epoch 011: | Train Loss: 0.49425 | Test Loss: 0.38867\n",
      "Epoch 012: | Train Loss: 0.46785 | Test Loss: 0.39503\n",
      "Epoch 013: | Train Loss: 0.43727 | Test Loss: 0.38605\n",
      "Epoch 014: | Train Loss: 0.45121 | Test Loss: 0.37374\n",
      "Epoch 015: | Train Loss: 0.45081 | Test Loss: 0.35988\n",
      "Epoch 016: | Train Loss: 0.42043 | Test Loss: 0.34241\n",
      "Epoch 017: | Train Loss: 0.40669 | Test Loss: 0.34451\n",
      "Epoch 018: | Train Loss: 0.38979 | Test Loss: 0.39005\n",
      "Epoch 019: | Train Loss: 0.40660 | Test Loss: 0.33706\n",
      "Epoch 020: | Train Loss: 0.39991 | Test Loss: 0.36522\n",
      "run with given regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1719046c81456e83aa963814eaeac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.37734 | Test Loss: 0.41357\n",
      "Epoch 002: | Train Loss: 0.37353 | Test Loss: 0.44633\n",
      "Epoch 003: | Train Loss: 0.36514 | Test Loss: 0.30768\n",
      "Epoch 004: | Train Loss: 0.36610 | Test Loss: 0.28570\n",
      "Epoch 005: | Train Loss: 0.37104 | Test Loss: 0.29398\n",
      "Epoch 006: | Train Loss: 0.33525 | Test Loss: 0.29119\n",
      "Epoch 007: | Train Loss: 0.38241 | Test Loss: 0.28844\n",
      "Epoch 008: | Train Loss: 0.33792 | Test Loss: 0.34837\n",
      "Epoch 009: | Train Loss: 0.36696 | Test Loss: 0.33805\n",
      "Epoch 010: | Train Loss: 0.35414 | Test Loss: 0.29955\n",
      "Epoch 011: | Train Loss: 0.35894 | Test Loss: 0.30019\n",
      "Epoch 012: | Train Loss: 0.35959 | Test Loss: 0.34154\n",
      "Epoch 013: | Train Loss: 0.35048 | Test Loss: 0.31803\n",
      "Epoch 014: | Train Loss: 0.34049 | Test Loss: 0.32284\n",
      "Epoch 015: | Train Loss: 0.32831 | Test Loss: 0.60782\n",
      "Epoch 016: | Train Loss: 0.34559 | Test Loss: 0.28434\n",
      "Epoch 017: | Train Loss: 0.33292 | Test Loss: 0.29742\n",
      "Epoch 018: | Train Loss: 0.36071 | Test Loss: 0.31355\n",
      "Epoch 019: | Train Loss: 0.36265 | Test Loss: 0.30954\n",
      "Epoch 020: | Train Loss: 0.33324 | Test Loss: 0.34085\n",
      "Epoch 021: | Train Loss: 0.32643 | Test Loss: 0.28614\n",
      "Epoch 022: | Train Loss: 0.33423 | Test Loss: 0.29059\n",
      "Epoch 023: | Train Loss: 0.33187 | Test Loss: 0.33263\n",
      "Epoch 024: | Train Loss: 0.37618 | Test Loss: 0.28346\n",
      "Epoch 025: | Train Loss: 0.36236 | Test Loss: 0.33453\n",
      "Epoch 026: | Train Loss: 0.35929 | Test Loss: 0.30149\n",
      "Epoch 027: | Train Loss: 0.31562 | Test Loss: 0.48896\n",
      "Epoch 028: | Train Loss: 0.32721 | Test Loss: 0.29479\n",
      "Epoch 029: | Train Loss: 0.32864 | Test Loss: 0.27096\n",
      "Epoch 030: | Train Loss: 0.34212 | Test Loss: 0.29124\n",
      "Epoch 031: | Train Loss: 0.32532 | Test Loss: 0.32413\n",
      "Epoch 032: | Train Loss: 0.33912 | Test Loss: 0.27463\n",
      "Epoch 033: | Train Loss: 0.31671 | Test Loss: 0.26034\n",
      "Epoch 034: | Train Loss: 0.32939 | Test Loss: 0.31075\n",
      "Epoch 035: | Train Loss: 0.31978 | Test Loss: 0.33368\n",
      "Epoch 036: | Train Loss: 0.33053 | Test Loss: 0.32593\n",
      "Epoch 037: | Train Loss: 0.32742 | Test Loss: 0.28703\n",
      "Epoch 038: | Train Loss: 0.33116 | Test Loss: 0.32509\n",
      "Epoch 039: | Train Loss: 0.34209 | Test Loss: 0.30407\n",
      "Epoch 040: | Train Loss: 0.34157 | Test Loss: 0.26711\n",
      "Epoch 041: | Train Loss: 0.34730 | Test Loss: 0.28403\n",
      "Epoch 042: | Train Loss: 0.34036 | Test Loss: 0.27995\n",
      "Epoch 043: | Train Loss: 0.33407 | Test Loss: 0.34573\n",
      "Epoch 044: | Train Loss: 0.34836 | Test Loss: 0.29137\n",
      "Epoch 045: | Train Loss: 0.34645 | Test Loss: 0.31175\n",
      "Epoch 046: | Train Loss: 0.33184 | Test Loss: 0.25851\n",
      "Epoch 047: | Train Loss: 0.33302 | Test Loss: 0.29273\n",
      "Epoch 048: | Train Loss: 0.35323 | Test Loss: 0.26865\n",
      "Epoch 049: | Train Loss: 0.31699 | Test Loss: 0.29542\n",
      "Epoch 050: | Train Loss: 0.31270 | Test Loss: 0.27319\n",
      "Epoch 051: | Train Loss: 0.31015 | Test Loss: 0.29452\n",
      "Epoch 052: | Train Loss: 0.33493 | Test Loss: 0.27017\n",
      "Epoch 053: | Train Loss: 0.33509 | Test Loss: 0.27764\n",
      "Epoch 054: | Train Loss: 0.31632 | Test Loss: 0.28507\n",
      "Epoch 055: | Train Loss: 0.34372 | Test Loss: 1.41496\n",
      "Epoch 056: | Train Loss: 0.32521 | Test Loss: 0.27229\n",
      "Epoch 057: | Train Loss: 0.34220 | Test Loss: 0.27041\n",
      "Epoch 058: | Train Loss: 0.35836 | Test Loss: 0.26574\n",
      "Epoch 059: | Train Loss: 0.32033 | Test Loss: 0.45112\n",
      "Epoch 060: | Train Loss: 0.33074 | Test Loss: 0.27159\n",
      "Epoch 061: | Train Loss: 0.31750 | Test Loss: 0.26481\n",
      "Epoch 062: | Train Loss: 0.31412 | Test Loss: 0.34133\n",
      "Epoch 063: | Train Loss: 0.33458 | Test Loss: 0.32129\n",
      "Epoch 064: | Train Loss: 0.34559 | Test Loss: 0.39928\n",
      "Epoch 065: | Train Loss: 0.33563 | Test Loss: 0.32792\n",
      "Epoch 066: | Train Loss: 0.32509 | Test Loss: 0.35119\n",
      "Epoch 067: | Train Loss: 0.32458 | Test Loss: 0.29517\n",
      "Epoch 068: | Train Loss: 0.31948 | Test Loss: 0.28492\n",
      "Epoch 069: | Train Loss: 0.31583 | Test Loss: 0.28487\n",
      "Epoch 070: | Train Loss: 0.31969 | Test Loss: 0.30995\n",
      "Epoch 071: | Train Loss: 0.31235 | Test Loss: 0.27505\n",
      "Epoch 072: | Train Loss: 0.32157 | Test Loss: 0.41681\n",
      "Epoch 073: | Train Loss: 0.36248 | Test Loss: 0.28640\n",
      "Epoch 074: | Train Loss: 0.30536 | Test Loss: 0.27439\n",
      "Epoch 075: | Train Loss: 0.32600 | Test Loss: 0.26740\n",
      "Epoch 076: | Train Loss: 0.29582 | Test Loss: 0.30466\n",
      "Epoch 077: | Train Loss: 0.31393 | Test Loss: 0.27611\n",
      "Epoch 078: | Train Loss: 0.31495 | Test Loss: 0.29180\n",
      "Epoch 079: | Train Loss: 0.30892 | Test Loss: 0.27667\n",
      "Epoch 080: | Train Loss: 0.32962 | Test Loss: 0.29051\n",
      "Epoch 081: | Train Loss: 0.32274 | Test Loss: 0.26766\n",
      "Epoch 082: | Train Loss: 0.32336 | Test Loss: 0.30013\n",
      "Epoch 083: | Train Loss: 0.32833 | Test Loss: 0.26106\n",
      "Epoch 084: | Train Loss: 0.32230 | Test Loss: 0.29825\n",
      "Epoch 085: | Train Loss: 0.33662 | Test Loss: 0.29516\n",
      "Epoch 086: | Train Loss: 0.32383 | Test Loss: 0.26756\n",
      "Epoch 087: | Train Loss: 0.32913 | Test Loss: 0.27411\n",
      "Epoch 088: | Train Loss: 0.33365 | Test Loss: 0.29042\n",
      "Epoch 089: | Train Loss: 0.34075 | Test Loss: 0.27089\n",
      "Epoch 090: | Train Loss: 0.33133 | Test Loss: 0.26843\n",
      "Epoch 091: | Train Loss: 0.33189 | Test Loss: 0.30207\n",
      "Epoch 092: | Train Loss: 0.32075 | Test Loss: 0.30370\n",
      "Epoch 093: | Train Loss: 0.30937 | Test Loss: 0.27568\n",
      "Epoch 094: | Train Loss: 0.32480 | Test Loss: 0.30891\n",
      "Epoch 095: | Train Loss: 0.32589 | Test Loss: 0.28964\n",
      "Epoch 096: | Train Loss: 0.31710 | Test Loss: 0.26996\n",
      "Epoch 097: | Train Loss: 0.33812 | Test Loss: 0.32195\n",
      "Epoch 098: | Train Loss: 0.32250 | Test Loss: 0.26901\n",
      "Epoch 099: | Train Loss: 0.32585 | Test Loss: 0.29460\n",
      "Epoch 100: | Train Loss: 0.30475 | Test Loss: 0.27736\n",
      "Epoch 101: | Train Loss: 0.30561 | Test Loss: 0.29618\n",
      "Epoch 102: | Train Loss: 0.33646 | Test Loss: 0.27234\n",
      "Epoch 103: | Train Loss: 0.31952 | Test Loss: 0.26102\n",
      "Epoch 104: | Train Loss: 0.33315 | Test Loss: 0.27483\n",
      "Epoch 105: | Train Loss: 0.33486 | Test Loss: 0.27014\n",
      "Epoch 106: | Train Loss: 0.31524 | Test Loss: 0.30271\n",
      "Epoch 107: | Train Loss: 0.30964 | Test Loss: 0.30505\n",
      "Epoch 108: | Train Loss: 0.31856 | Test Loss: 0.30925\n",
      "Epoch 109: | Train Loss: 0.34571 | Test Loss: 0.31318\n",
      "Epoch 110: | Train Loss: 0.30626 | Test Loss: 0.27218\n",
      "Epoch 111: | Train Loss: 0.34436 | Test Loss: 0.29902\n",
      "Epoch 112: | Train Loss: 0.30276 | Test Loss: 0.28222\n",
      "Epoch 113: | Train Loss: 0.30716 | Test Loss: 0.31525\n",
      "Epoch 114: | Train Loss: 0.32141 | Test Loss: 0.27963\n",
      "Epoch 115: | Train Loss: 0.32441 | Test Loss: 0.26636\n",
      "Epoch 116: | Train Loss: 0.32099 | Test Loss: 0.25922\n",
      "Epoch 117: | Train Loss: 0.30336 | Test Loss: 0.27449\n",
      "Epoch 118: | Train Loss: 0.31392 | Test Loss: 0.25941\n",
      "Epoch 119: | Train Loss: 0.30329 | Test Loss: 0.30241\n",
      "Epoch 120: | Train Loss: 0.32568 | Test Loss: 0.26876\n",
      "Epoch 121: | Train Loss: 0.30156 | Test Loss: 0.29084\n",
      "Epoch 122: | Train Loss: 0.31651 | Test Loss: 0.26451\n",
      "Epoch 123: | Train Loss: 0.30638 | Test Loss: 0.28097\n",
      "Epoch 124: | Train Loss: 0.30186 | Test Loss: 0.26655\n",
      "Epoch 125: | Train Loss: 0.31823 | Test Loss: 0.28888\n",
      "Epoch 126: | Train Loss: 0.30811 | Test Loss: 0.26830\n",
      "Epoch 127: | Train Loss: 0.30644 | Test Loss: 0.29467\n",
      "Epoch 128: | Train Loss: 0.30576 | Test Loss: 0.31693\n",
      "Epoch 129: | Train Loss: 0.30393 | Test Loss: 0.29761\n",
      "Epoch 130: | Train Loss: 0.34706 | Test Loss: 0.29364\n",
      "Epoch 131: | Train Loss: 0.31391 | Test Loss: 0.26613\n",
      "Epoch 132: | Train Loss: 0.29961 | Test Loss: 0.28289\n",
      "Epoch 133: | Train Loss: 0.35929 | Test Loss: 0.29367\n",
      "Epoch 134: | Train Loss: 0.30480 | Test Loss: 0.26968\n",
      "Epoch 135: | Train Loss: 0.36025 | Test Loss: 0.28527\n",
      "Epoch 136: | Train Loss: 0.32134 | Test Loss: 0.28745\n",
      "Epoch 137: | Train Loss: 0.33477 | Test Loss: 0.31208\n",
      "Epoch 138: | Train Loss: 0.31037 | Test Loss: 0.27140\n",
      "Epoch 139: | Train Loss: 0.30431 | Test Loss: 0.26160\n",
      "Epoch 140: | Train Loss: 0.31587 | Test Loss: 0.25891\n",
      "Epoch 141: | Train Loss: 0.29548 | Test Loss: 0.27395\n",
      "Epoch 142: | Train Loss: 0.32310 | Test Loss: 0.26304\n",
      "Epoch 143: | Train Loss: 0.29829 | Test Loss: 0.28426\n",
      "Epoch 144: | Train Loss: 0.32371 | Test Loss: 0.27789\n",
      "Epoch 145: | Train Loss: 0.30514 | Test Loss: 0.27599\n",
      "Epoch 146: | Train Loss: 0.32412 | Test Loss: 0.26210\n",
      "Epoch 147: | Train Loss: 0.31689 | Test Loss: 0.26186\n",
      "Epoch 148: | Train Loss: 0.33580 | Test Loss: 0.28970\n",
      "Epoch 149: | Train Loss: 0.31470 | Test Loss: 0.26772\n",
      "Epoch 150: | Train Loss: 0.34226 | Test Loss: 0.26829\n",
      "Epoch 151: | Train Loss: 0.31346 | Test Loss: 0.26658\n",
      "Epoch 152: | Train Loss: 0.32021 | Test Loss: 0.31898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: | Train Loss: 0.30126 | Test Loss: 0.33669\n",
      "Epoch 154: | Train Loss: 0.31017 | Test Loss: 0.29186\n",
      "Epoch 155: | Train Loss: 0.34823 | Test Loss: 0.27058\n",
      "Epoch 156: | Train Loss: 0.29358 | Test Loss: 0.26816\n",
      "Epoch 157: | Train Loss: 0.31620 | Test Loss: 0.29119\n",
      "Epoch 158: | Train Loss: 0.31249 | Test Loss: 0.37803\n",
      "Epoch 159: | Train Loss: 0.32317 | Test Loss: 0.26189\n",
      "Epoch 160: | Train Loss: 0.28412 | Test Loss: 0.29994\n",
      "Epoch 161: | Train Loss: 0.32264 | Test Loss: 0.27306\n",
      "Epoch 162: | Train Loss: 0.30417 | Test Loss: 0.26843\n",
      "Epoch 163: | Train Loss: 0.30134 | Test Loss: 0.32836\n",
      "Epoch 164: | Train Loss: 0.30635 | Test Loss: 0.30356\n",
      "Epoch 165: | Train Loss: 0.31256 | Test Loss: 0.31821\n",
      "Epoch 166: | Train Loss: 0.30926 | Test Loss: 0.27718\n",
      "Epoch 167: | Train Loss: 0.31978 | Test Loss: 0.27652\n",
      "Epoch 168: | Train Loss: 0.31075 | Test Loss: 0.28335\n",
      "Epoch 169: | Train Loss: 0.28300 | Test Loss: 0.27105\n",
      "Epoch 170: | Train Loss: 0.29253 | Test Loss: 0.29226\n",
      "Epoch 171: | Train Loss: 0.29555 | Test Loss: 0.26684\n",
      "Epoch 172: | Train Loss: 0.30969 | Test Loss: 0.26018\n",
      "Epoch 173: | Train Loss: 0.31685 | Test Loss: 0.27452\n",
      "Epoch 174: | Train Loss: 0.28815 | Test Loss: 0.27620\n",
      "Epoch 175: | Train Loss: 0.29839 | Test Loss: 0.26347\n",
      "Epoch 176: | Train Loss: 0.29517 | Test Loss: 0.25850\n",
      "Epoch 177: | Train Loss: 0.30948 | Test Loss: 0.26012\n",
      "Epoch 178: | Train Loss: 0.30603 | Test Loss: 0.26403\n",
      "Epoch 179: | Train Loss: 0.30549 | Test Loss: 0.25656\n",
      "Epoch 180: | Train Loss: 0.30741 | Test Loss: 0.26518\n",
      "Epoch 181: | Train Loss: 0.30151 | Test Loss: 0.25970\n",
      "Epoch 182: | Train Loss: 0.31717 | Test Loss: 0.37888\n",
      "Epoch 183: | Train Loss: 0.31866 | Test Loss: 0.26021\n",
      "Epoch 184: | Train Loss: 0.29787 | Test Loss: 0.27997\n",
      "Epoch 185: | Train Loss: 0.31732 | Test Loss: 0.29838\n",
      "Epoch 186: | Train Loss: 0.30917 | Test Loss: 0.26763\n",
      "Epoch 187: | Train Loss: 0.31079 | Test Loss: 0.26324\n",
      "Epoch 188: | Train Loss: 0.30074 | Test Loss: 0.27230\n",
      "Epoch 189: | Train Loss: 0.32231 | Test Loss: 0.26671\n",
      "Epoch 190: | Train Loss: 0.30641 | Test Loss: 0.27425\n",
      "Epoch 191: | Train Loss: 0.31129 | Test Loss: 0.28687\n",
      "Epoch 192: | Train Loss: 0.29648 | Test Loss: 0.30978\n",
      "Epoch 193: | Train Loss: 0.31303 | Test Loss: 0.26573\n",
      "Epoch 194: | Train Loss: 0.30780 | Test Loss: 0.32582\n",
      "Epoch 195: | Train Loss: 0.29717 | Test Loss: 0.25561\n",
      "Epoch 196: | Train Loss: 0.29308 | Test Loss: 0.28853\n",
      "Epoch 197: | Train Loss: 0.32843 | Test Loss: 0.26719\n",
      "Epoch 198: | Train Loss: 0.32116 | Test Loss: 0.26662\n",
      "Epoch 199: | Train Loss: 0.30479 | Test Loss: 0.30935\n",
      "Epoch 200: | Train Loss: 0.27909 | Test Loss: 0.39444\n",
      "Epoch 201: | Train Loss: 0.31429 | Test Loss: 0.30395\n",
      "Epoch 202: | Train Loss: 0.30742 | Test Loss: 0.28202\n",
      "Epoch 203: | Train Loss: 0.31589 | Test Loss: 0.26166\n",
      "Epoch 204: | Train Loss: 0.30231 | Test Loss: 0.30155\n",
      "Epoch 205: | Train Loss: 0.28024 | Test Loss: 0.28601\n",
      "Epoch 206: | Train Loss: 0.31910 | Test Loss: 0.26243\n",
      "Epoch 207: | Train Loss: 0.30874 | Test Loss: 0.27793\n",
      "Epoch 208: | Train Loss: 0.30617 | Test Loss: 0.25695\n",
      "Epoch 209: | Train Loss: 0.29812 | Test Loss: 0.29232\n",
      "Epoch 210: | Train Loss: 0.30640 | Test Loss: 0.31030\n",
      "Epoch 211: | Train Loss: 0.30659 | Test Loss: 0.30371\n",
      "Epoch 212: | Train Loss: 0.28002 | Test Loss: 0.30887\n",
      "Epoch 213: | Train Loss: 0.32142 | Test Loss: 0.26024\n",
      "Epoch 214: | Train Loss: 0.30502 | Test Loss: 0.26466\n",
      "Epoch 215: | Train Loss: 0.30711 | Test Loss: 0.25592\n",
      "Epoch 216: | Train Loss: 0.32007 | Test Loss: 0.25524\n",
      "Epoch 217: | Train Loss: 0.30152 | Test Loss: 0.30769\n",
      "Epoch 218: | Train Loss: 0.32497 | Test Loss: 0.26182\n",
      "Epoch 219: | Train Loss: 0.29141 | Test Loss: 0.28510\n",
      "Epoch 220: | Train Loss: 0.30762 | Test Loss: 0.29337\n",
      "Epoch 221: | Train Loss: 0.30954 | Test Loss: 0.28677\n",
      "Epoch 222: | Train Loss: 0.31498 | Test Loss: 0.26669\n",
      "Epoch 223: | Train Loss: 0.29291 | Test Loss: 0.26367\n",
      "Epoch 224: | Train Loss: 0.31031 | Test Loss: 0.26371\n",
      "Epoch 225: | Train Loss: 0.30305 | Test Loss: 0.27011\n",
      "Epoch 226: | Train Loss: 0.30868 | Test Loss: 0.30817\n",
      "Epoch 227: | Train Loss: 0.31524 | Test Loss: 0.28750\n",
      "Epoch 228: | Train Loss: 0.31190 | Test Loss: 0.28904\n",
      "Epoch 229: | Train Loss: 0.31155 | Test Loss: 0.26838\n",
      "Epoch 230: | Train Loss: 0.28190 | Test Loss: 0.27706\n",
      "Epoch 231: | Train Loss: 0.30376 | Test Loss: 0.26681\n",
      "Epoch 232: | Train Loss: 0.32496 | Test Loss: 0.27208\n",
      "Epoch 233: | Train Loss: 0.30724 | Test Loss: 0.26476\n",
      "Epoch 234: | Train Loss: 0.30522 | Test Loss: 0.27732\n",
      "Epoch 235: | Train Loss: 0.29830 | Test Loss: 0.25454\n",
      "Epoch 236: | Train Loss: 0.30751 | Test Loss: 0.29557\n",
      "Epoch 237: | Train Loss: 0.31449 | Test Loss: 0.32445\n",
      "Epoch 238: | Train Loss: 0.31262 | Test Loss: 0.27345\n",
      "Epoch 239: | Train Loss: 0.29949 | Test Loss: 0.25757\n",
      "Epoch 240: | Train Loss: 0.28919 | Test Loss: 0.28800\n",
      "stats of l2reg of  0.1 are [0.95041 0.94118 0.24904 0.26722]\n",
      "running reg of 0.3\n",
      "initial run of high regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16878/3106201501.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight) #old\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423c6c9b8fdf4056b5ec191959bd53da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 26.07730 | Test Loss: 27.61905\n",
      "Epoch 002: | Train Loss: 26.19450 | Test Loss: 27.51055\n",
      "Epoch 003: | Train Loss: 4.84322 | Test Loss: 0.55637\n",
      "Epoch 004: | Train Loss: 0.53728 | Test Loss: 0.82026\n",
      "Epoch 005: | Train Loss: 0.52818 | Test Loss: 0.49056\n",
      "Epoch 006: | Train Loss: 0.52542 | Test Loss: 0.54585\n",
      "Epoch 007: | Train Loss: 0.52112 | Test Loss: 0.45377\n",
      "Epoch 008: | Train Loss: 0.51617 | Test Loss: 0.66543\n",
      "Epoch 009: | Train Loss: 0.49409 | Test Loss: 0.43105\n",
      "Epoch 010: | Train Loss: 0.51747 | Test Loss: 0.45781\n",
      "Epoch 011: | Train Loss: 0.49596 | Test Loss: 0.43401\n",
      "Epoch 012: | Train Loss: 0.48241 | Test Loss: 0.45704\n",
      "Epoch 013: | Train Loss: 0.49178 | Test Loss: 0.42756\n",
      "Epoch 014: | Train Loss: 0.48339 | Test Loss: 0.43198\n",
      "Epoch 015: | Train Loss: 0.47494 | Test Loss: 0.44635\n",
      "Epoch 016: | Train Loss: 0.46961 | Test Loss: 0.42017\n",
      "Epoch 017: | Train Loss: 0.51237 | Test Loss: 0.49056\n",
      "Epoch 018: | Train Loss: 0.48192 | Test Loss: 0.43588\n",
      "Epoch 019: | Train Loss: 0.47729 | Test Loss: 0.47374\n",
      "Epoch 020: | Train Loss: 0.45708 | Test Loss: 0.45531\n",
      "run with given regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de5e09aeb7847cc9ad920a47abab3b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.47812 | Test Loss: 0.44239\n",
      "Epoch 002: | Train Loss: 0.46594 | Test Loss: 0.43814\n",
      "Epoch 003: | Train Loss: 0.46671 | Test Loss: 0.40640\n",
      "Epoch 004: | Train Loss: 0.45063 | Test Loss: 0.43572\n",
      "Epoch 005: | Train Loss: 0.46800 | Test Loss: 0.40917\n",
      "Epoch 006: | Train Loss: 0.44029 | Test Loss: 0.40978\n",
      "Epoch 007: | Train Loss: 0.45240 | Test Loss: 0.48652\n",
      "Epoch 008: | Train Loss: 0.43564 | Test Loss: 0.39350\n",
      "Epoch 009: | Train Loss: 0.45454 | Test Loss: 0.46161\n",
      "Epoch 010: | Train Loss: 0.47394 | Test Loss: 0.44378\n",
      "Epoch 011: | Train Loss: 0.45703 | Test Loss: 0.42662\n",
      "Epoch 012: | Train Loss: 0.45304 | Test Loss: 0.47861\n",
      "Epoch 013: | Train Loss: 0.44813 | Test Loss: 0.60284\n",
      "Epoch 014: | Train Loss: 0.43474 | Test Loss: 0.42126\n",
      "Epoch 015: | Train Loss: 0.45820 | Test Loss: 0.51491\n",
      "Epoch 016: | Train Loss: 0.45053 | Test Loss: 0.42287\n",
      "Epoch 017: | Train Loss: 0.44907 | Test Loss: 0.40445\n",
      "Epoch 018: | Train Loss: 0.43744 | Test Loss: 0.45657\n",
      "Epoch 019: | Train Loss: 0.44271 | Test Loss: 0.43801\n",
      "Epoch 020: | Train Loss: 0.45082 | Test Loss: 0.39547\n",
      "Epoch 021: | Train Loss: 0.45507 | Test Loss: 0.41507\n",
      "Epoch 022: | Train Loss: 0.46145 | Test Loss: 0.42394\n",
      "Epoch 023: | Train Loss: 0.47487 | Test Loss: 0.98362\n",
      "Epoch 024: | Train Loss: 0.45211 | Test Loss: 0.45468\n",
      "Epoch 025: | Train Loss: 0.46686 | Test Loss: 0.47005\n",
      "Epoch 026: | Train Loss: 0.46850 | Test Loss: 0.62124\n",
      "Epoch 027: | Train Loss: 0.44804 | Test Loss: 0.46298\n",
      "Epoch 028: | Train Loss: 0.44074 | Test Loss: 0.45995\n",
      "Epoch 029: | Train Loss: 0.44690 | Test Loss: 0.44475\n",
      "Epoch 030: | Train Loss: 0.42360 | Test Loss: 0.40941\n",
      "Epoch 031: | Train Loss: 0.45990 | Test Loss: 0.44993\n",
      "Epoch 032: | Train Loss: 0.43199 | Test Loss: 0.42039\n",
      "Epoch 033: | Train Loss: 0.43921 | Test Loss: 0.42120\n",
      "Epoch 034: | Train Loss: 0.42941 | Test Loss: 0.46612\n",
      "Epoch 035: | Train Loss: 0.45061 | Test Loss: 0.45954\n",
      "Epoch 036: | Train Loss: 0.47278 | Test Loss: 0.42631\n",
      "Epoch 037: | Train Loss: 0.44991 | Test Loss: 0.45194\n",
      "Epoch 038: | Train Loss: 0.43535 | Test Loss: 0.45412\n",
      "Epoch 039: | Train Loss: 0.44124 | Test Loss: 0.44673\n",
      "Epoch 040: | Train Loss: 0.43436 | Test Loss: 0.44808\n",
      "Epoch 041: | Train Loss: 0.44656 | Test Loss: 0.45694\n",
      "Epoch 042: | Train Loss: 0.43448 | Test Loss: 0.41209\n",
      "Epoch 043: | Train Loss: 0.43353 | Test Loss: 0.45956\n",
      "Epoch 044: | Train Loss: 0.45921 | Test Loss: 0.44815\n",
      "Epoch 045: | Train Loss: 0.44476 | Test Loss: 0.48746\n",
      "Epoch 046: | Train Loss: 0.46038 | Test Loss: 0.44724\n",
      "Epoch 047: | Train Loss: 0.43121 | Test Loss: 0.45580\n",
      "Epoch 048: | Train Loss: 0.42729 | Test Loss: 0.46818\n",
      "Epoch 049: | Train Loss: 0.42865 | Test Loss: 0.45574\n",
      "Epoch 050: | Train Loss: 0.42940 | Test Loss: 0.47496\n",
      "Epoch 051: | Train Loss: 0.44081 | Test Loss: 0.43131\n",
      "Epoch 052: | Train Loss: 0.41678 | Test Loss: 0.44741\n",
      "Epoch 053: | Train Loss: 0.45737 | Test Loss: 0.42314\n",
      "Epoch 054: | Train Loss: 0.41733 | Test Loss: 0.85993\n",
      "Epoch 055: | Train Loss: 0.43906 | Test Loss: 0.44465\n",
      "Epoch 056: | Train Loss: 0.44905 | Test Loss: 0.44672\n",
      "Epoch 057: | Train Loss: 0.44156 | Test Loss: 0.45780\n",
      "Epoch 058: | Train Loss: 0.46731 | Test Loss: 0.44906\n",
      "Epoch 059: | Train Loss: 0.43558 | Test Loss: 0.44304\n",
      "Epoch 060: | Train Loss: 0.45069 | Test Loss: 0.45471\n",
      "Epoch 061: | Train Loss: 0.43222 | Test Loss: 0.45464\n",
      "Epoch 062: | Train Loss: 0.42156 | Test Loss: 0.47359\n",
      "Epoch 063: | Train Loss: 0.45938 | Test Loss: 0.45560\n",
      "Epoch 064: | Train Loss: 0.44505 | Test Loss: 0.53803\n",
      "Epoch 065: | Train Loss: 0.43726 | Test Loss: 0.46606\n",
      "Epoch 066: | Train Loss: 0.43717 | Test Loss: 0.43082\n",
      "Epoch 067: | Train Loss: 0.42084 | Test Loss: 0.41996\n",
      "Epoch 068: | Train Loss: 0.44321 | Test Loss: 0.45640\n",
      "Epoch 069: | Train Loss: 0.45026 | Test Loss: 0.45907\n",
      "Epoch 070: | Train Loss: 0.44254 | Test Loss: 0.44299\n",
      "Epoch 071: | Train Loss: 0.43349 | Test Loss: 0.45328\n",
      "Epoch 072: | Train Loss: 0.44319 | Test Loss: 0.43247\n",
      "Epoch 073: | Train Loss: 0.43005 | Test Loss: 0.46730\n",
      "Epoch 074: | Train Loss: 0.44443 | Test Loss: 0.44318\n",
      "Epoch 075: | Train Loss: 0.42630 | Test Loss: 0.45454\n",
      "Epoch 076: | Train Loss: 0.43318 | Test Loss: 0.44429\n",
      "Epoch 077: | Train Loss: 0.43230 | Test Loss: 0.44995\n",
      "Epoch 078: | Train Loss: 0.43462 | Test Loss: 0.42317\n",
      "Epoch 079: | Train Loss: 0.44920 | Test Loss: 0.46406\n",
      "Epoch 080: | Train Loss: 0.42780 | Test Loss: 0.43444\n",
      "Epoch 081: | Train Loss: 0.42537 | Test Loss: 0.45867\n",
      "Epoch 082: | Train Loss: 0.43759 | Test Loss: 0.42499\n",
      "Epoch 083: | Train Loss: 0.42794 | Test Loss: 0.42713\n",
      "Epoch 084: | Train Loss: 0.45542 | Test Loss: 0.50850\n",
      "Epoch 085: | Train Loss: 0.45352 | Test Loss: 0.46060\n",
      "Epoch 086: | Train Loss: 0.44170 | Test Loss: 0.78587\n",
      "Epoch 087: | Train Loss: 0.44745 | Test Loss: 0.91761\n",
      "Epoch 088: | Train Loss: 0.45557 | Test Loss: 0.44936\n",
      "Epoch 089: | Train Loss: 0.44508 | Test Loss: 0.44936\n",
      "Epoch 090: | Train Loss: 0.42197 | Test Loss: 0.45137\n",
      "Epoch 091: | Train Loss: 0.44345 | Test Loss: 0.47074\n",
      "Epoch 092: | Train Loss: 0.43602 | Test Loss: 0.44900\n",
      "Epoch 093: | Train Loss: 0.44641 | Test Loss: 0.45883\n",
      "Epoch 094: | Train Loss: 0.43792 | Test Loss: 0.41933\n",
      "Epoch 095: | Train Loss: 0.44604 | Test Loss: 0.42290\n",
      "Epoch 096: | Train Loss: 0.46352 | Test Loss: 0.41932\n",
      "Epoch 097: | Train Loss: 0.43185 | Test Loss: 0.45708\n",
      "Epoch 098: | Train Loss: 0.45106 | Test Loss: 0.46210\n",
      "Epoch 099: | Train Loss: 0.43856 | Test Loss: 0.44838\n",
      "Epoch 100: | Train Loss: 0.43464 | Test Loss: 0.45034\n",
      "Epoch 101: | Train Loss: 0.44605 | Test Loss: 0.53282\n",
      "Epoch 102: | Train Loss: 0.41998 | Test Loss: 0.44720\n",
      "Epoch 103: | Train Loss: 0.43686 | Test Loss: 0.44337\n",
      "Epoch 104: | Train Loss: 0.44055 | Test Loss: 0.44316\n",
      "Epoch 105: | Train Loss: 0.44122 | Test Loss: 0.57751\n",
      "Epoch 106: | Train Loss: 0.43974 | Test Loss: 0.45143\n",
      "Epoch 107: | Train Loss: 0.44824 | Test Loss: 0.42903\n",
      "Epoch 108: | Train Loss: 0.42782 | Test Loss: 0.47399\n",
      "Epoch 109: | Train Loss: 0.44843 | Test Loss: 0.44785\n",
      "Epoch 110: | Train Loss: 0.42412 | Test Loss: 0.49234\n",
      "Epoch 111: | Train Loss: 0.43473 | Test Loss: 0.62656\n",
      "Epoch 112: | Train Loss: 0.45560 | Test Loss: 0.45458\n",
      "Epoch 113: | Train Loss: 0.44262 | Test Loss: 0.57833\n",
      "Epoch 114: | Train Loss: 0.43532 | Test Loss: 0.41953\n",
      "Epoch 115: | Train Loss: 0.44124 | Test Loss: 0.46842\n",
      "Epoch 116: | Train Loss: 0.45807 | Test Loss: 0.45609\n",
      "Epoch 117: | Train Loss: 0.44374 | Test Loss: 0.45958\n",
      "Epoch 118: | Train Loss: 0.43264 | Test Loss: 0.44573\n",
      "Epoch 119: | Train Loss: 0.43621 | Test Loss: 0.45730\n",
      "Epoch 120: | Train Loss: 0.45255 | Test Loss: 0.46460\n",
      "Epoch 121: | Train Loss: 0.42851 | Test Loss: 0.41930\n",
      "Epoch 122: | Train Loss: 0.44994 | Test Loss: 0.41794\n",
      "Epoch 123: | Train Loss: 0.43426 | Test Loss: 0.44191\n",
      "Epoch 124: | Train Loss: 0.42767 | Test Loss: 0.42257\n",
      "Epoch 125: | Train Loss: 0.43946 | Test Loss: 0.44912\n",
      "Epoch 126: | Train Loss: 0.42601 | Test Loss: 0.44963\n",
      "Epoch 127: | Train Loss: 0.45479 | Test Loss: 0.48339\n",
      "Epoch 128: | Train Loss: 0.43772 | Test Loss: 0.45581\n",
      "Epoch 129: | Train Loss: 0.46576 | Test Loss: 0.45286\n",
      "Epoch 130: | Train Loss: 0.43728 | Test Loss: 0.45108\n",
      "Epoch 131: | Train Loss: 0.44019 | Test Loss: 0.45347\n",
      "Epoch 132: | Train Loss: 0.45406 | Test Loss: 0.42900\n",
      "Epoch 133: | Train Loss: 0.45219 | Test Loss: 0.45884\n",
      "Epoch 134: | Train Loss: 0.43565 | Test Loss: 0.42224\n",
      "Epoch 135: | Train Loss: 0.42124 | Test Loss: 0.45283\n",
      "Epoch 136: | Train Loss: 0.45429 | Test Loss: 0.44730\n",
      "Epoch 137: | Train Loss: 0.43365 | Test Loss: 0.44849\n",
      "Epoch 138: | Train Loss: 0.44089 | Test Loss: 0.44304\n",
      "Epoch 139: | Train Loss: 0.43751 | Test Loss: 0.45072\n",
      "Epoch 140: | Train Loss: 0.43236 | Test Loss: 0.42941\n",
      "Epoch 141: | Train Loss: 0.43378 | Test Loss: 0.42900\n",
      "Epoch 142: | Train Loss: 0.43283 | Test Loss: 0.42302\n",
      "Epoch 143: | Train Loss: 0.45291 | Test Loss: 0.48593\n",
      "Epoch 144: | Train Loss: 0.44420 | Test Loss: 0.44946\n",
      "Epoch 145: | Train Loss: 0.44062 | Test Loss: 0.45431\n",
      "Epoch 146: | Train Loss: 0.43952 | Test Loss: 0.45036\n",
      "Epoch 147: | Train Loss: 0.42598 | Test Loss: 0.44980\n",
      "Epoch 148: | Train Loss: 0.42125 | Test Loss: 0.44920\n",
      "Epoch 149: | Train Loss: 0.43340 | Test Loss: 0.45209\n",
      "Epoch 150: | Train Loss: 0.41874 | Test Loss: 0.44599\n",
      "Epoch 151: | Train Loss: 0.43075 | Test Loss: 0.42430\n",
      "Epoch 152: | Train Loss: 0.43453 | Test Loss: 0.44553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: | Train Loss: 0.45113 | Test Loss: 0.43025\n",
      "Epoch 154: | Train Loss: 0.43996 | Test Loss: 0.45383\n",
      "Epoch 155: | Train Loss: 0.43502 | Test Loss: 0.44767\n",
      "Epoch 156: | Train Loss: 0.43366 | Test Loss: 0.44405\n",
      "Epoch 157: | Train Loss: 0.45678 | Test Loss: 0.45389\n",
      "Epoch 158: | Train Loss: 0.44730 | Test Loss: 0.44817\n",
      "Epoch 159: | Train Loss: 0.42087 | Test Loss: 0.47276\n",
      "Epoch 160: | Train Loss: 0.44064 | Test Loss: 0.43535\n",
      "Epoch 161: | Train Loss: 0.43404 | Test Loss: 0.44722\n",
      "Epoch 162: | Train Loss: 0.42929 | Test Loss: 0.42482\n",
      "Epoch 163: | Train Loss: 0.45603 | Test Loss: 0.44564\n",
      "Epoch 164: | Train Loss: 0.43633 | Test Loss: 0.42373\n",
      "Epoch 165: | Train Loss: 0.45286 | Test Loss: 0.44777\n",
      "Epoch 166: | Train Loss: 0.43499 | Test Loss: 0.45031\n",
      "Epoch 167: | Train Loss: 0.43860 | Test Loss: 0.44572\n",
      "Epoch 168: | Train Loss: 0.43204 | Test Loss: 0.45541\n",
      "Epoch 169: | Train Loss: 0.41861 | Test Loss: 0.41716\n",
      "Epoch 170: | Train Loss: 0.43647 | Test Loss: 0.42011\n",
      "Epoch 171: | Train Loss: 0.43963 | Test Loss: 0.42065\n",
      "Epoch 172: | Train Loss: 0.43031 | Test Loss: 0.47959\n",
      "Epoch 173: | Train Loss: 0.44884 | Test Loss: 0.46241\n",
      "Epoch 174: | Train Loss: 0.43528 | Test Loss: 0.46434\n",
      "Epoch 175: | Train Loss: 0.43305 | Test Loss: 0.41062\n",
      "Epoch 176: | Train Loss: 0.43900 | Test Loss: 0.42157\n",
      "Epoch 177: | Train Loss: 0.43036 | Test Loss: 0.46319\n",
      "Epoch 178: | Train Loss: 0.43275 | Test Loss: 0.63383\n",
      "Epoch 179: | Train Loss: 0.43680 | Test Loss: 0.41747\n",
      "Epoch 180: | Train Loss: 0.44185 | Test Loss: 0.44298\n",
      "Epoch 181: | Train Loss: 0.41781 | Test Loss: 0.45806\n",
      "Epoch 182: | Train Loss: 0.44036 | Test Loss: 0.47534\n",
      "Epoch 183: | Train Loss: 0.44193 | Test Loss: 0.44386\n",
      "Epoch 184: | Train Loss: 0.42822 | Test Loss: 0.46140\n",
      "Epoch 185: | Train Loss: 0.45837 | Test Loss: 0.44324\n",
      "Epoch 186: | Train Loss: 0.42733 | Test Loss: 0.44228\n",
      "Epoch 187: | Train Loss: 0.43475 | Test Loss: 0.45371\n",
      "Epoch 188: | Train Loss: 0.45136 | Test Loss: 0.44671\n",
      "Epoch 189: | Train Loss: 0.43413 | Test Loss: 0.45310\n",
      "Epoch 190: | Train Loss: 0.45513 | Test Loss: 0.46116\n",
      "Epoch 191: | Train Loss: 0.47625 | Test Loss: 0.44908\n",
      "Epoch 192: | Train Loss: 0.42204 | Test Loss: 0.45513\n",
      "Epoch 193: | Train Loss: 0.43524 | Test Loss: 0.52847\n",
      "Epoch 194: | Train Loss: 0.43119 | Test Loss: 0.44408\n",
      "Epoch 195: | Train Loss: 0.41404 | Test Loss: 0.45017\n",
      "Epoch 196: | Train Loss: 0.42960 | Test Loss: 0.44414\n",
      "Epoch 197: | Train Loss: 0.44051 | Test Loss: 0.46248\n",
      "Epoch 198: | Train Loss: 0.43667 | Test Loss: 0.54209\n",
      "Epoch 199: | Train Loss: 0.44135 | Test Loss: 0.46313\n",
      "Epoch 200: | Train Loss: 0.42324 | Test Loss: 0.45896\n",
      "Epoch 201: | Train Loss: 0.43448 | Test Loss: 0.44513\n",
      "Epoch 202: | Train Loss: 0.46837 | Test Loss: 0.45987\n",
      "Epoch 203: | Train Loss: 0.44962 | Test Loss: 0.43952\n",
      "Epoch 204: | Train Loss: 0.45965 | Test Loss: 0.42574\n",
      "Epoch 205: | Train Loss: 0.43723 | Test Loss: 0.45163\n",
      "Epoch 206: | Train Loss: 0.43367 | Test Loss: 0.45555\n",
      "Epoch 207: | Train Loss: 0.43654 | Test Loss: 0.44019\n",
      "Epoch 208: | Train Loss: 0.43540 | Test Loss: 0.45094\n",
      "Epoch 209: | Train Loss: 0.43703 | Test Loss: 0.44570\n",
      "Epoch 210: | Train Loss: 0.47138 | Test Loss: 0.45585\n",
      "Epoch 211: | Train Loss: 0.43773 | Test Loss: 0.44888\n",
      "Epoch 212: | Train Loss: 0.41504 | Test Loss: 0.41604\n",
      "Epoch 213: | Train Loss: 0.41777 | Test Loss: 0.47462\n",
      "Epoch 214: | Train Loss: 0.41765 | Test Loss: 0.41932\n",
      "Epoch 215: | Train Loss: 0.43317 | Test Loss: 0.43533\n",
      "Epoch 216: | Train Loss: 0.43471 | Test Loss: 0.41344\n",
      "Epoch 217: | Train Loss: 0.42572 | Test Loss: 0.44564\n",
      "Epoch 218: | Train Loss: 0.41547 | Test Loss: 0.41832\n",
      "Epoch 219: | Train Loss: 0.46016 | Test Loss: 0.44301\n",
      "Epoch 220: | Train Loss: 0.42030 | Test Loss: 0.46500\n",
      "Epoch 221: | Train Loss: 0.41288 | Test Loss: 0.45713\n",
      "Epoch 222: | Train Loss: 0.47542 | Test Loss: 0.41740\n",
      "Epoch 223: | Train Loss: 0.43008 | Test Loss: 0.44573\n",
      "Epoch 224: | Train Loss: 0.44251 | Test Loss: 0.42463\n",
      "Epoch 225: | Train Loss: 0.44961 | Test Loss: 0.43761\n",
      "Epoch 226: | Train Loss: 0.45765 | Test Loss: 0.41901\n",
      "Epoch 227: | Train Loss: 0.47334 | Test Loss: 0.41654\n",
      "Epoch 228: | Train Loss: 0.45166 | Test Loss: 0.44420\n",
      "Epoch 229: | Train Loss: 0.45699 | Test Loss: 0.43749\n",
      "Epoch 230: | Train Loss: 0.42751 | Test Loss: 0.43963\n",
      "Epoch 231: | Train Loss: 0.43152 | Test Loss: 0.44050\n",
      "Epoch 232: | Train Loss: 0.42995 | Test Loss: 0.50411\n",
      "Epoch 233: | Train Loss: 0.41954 | Test Loss: 0.43734\n",
      "Epoch 234: | Train Loss: 0.43981 | Test Loss: 0.41314\n",
      "Epoch 235: | Train Loss: 0.43727 | Test Loss: 0.41011\n",
      "Epoch 236: | Train Loss: 0.43095 | Test Loss: 0.41083\n",
      "Epoch 237: | Train Loss: 0.44559 | Test Loss: 0.41846\n",
      "Epoch 238: | Train Loss: 0.45790 | Test Loss: 0.46557\n",
      "Epoch 239: | Train Loss: 0.43574 | Test Loss: 0.45899\n",
      "Epoch 240: | Train Loss: 0.44767 | Test Loss: 0.41920\n",
      "stats of l2reg of  0.3 are [0.90423 0.89679 0.36103 0.37764]\n",
      "full stats are [[3.0000e-05 9.9484e-01 9.5057e-01 2.5780e-02 4.7746e-01]\n",
      " [1.0000e-04 9.9828e-01 9.6614e-01 1.5130e-02 2.8561e-01]\n",
      " [3.0000e-04 9.9943e-01 9.6558e-01 4.7500e-03 3.0086e-01]\n",
      " [1.0000e-03 9.9382e-01 9.6750e-01 2.9290e-02 1.8863e-01]\n",
      " [3.0000e-03 9.8400e-01 9.6826e-01 6.4850e-02 1.4957e-01]\n",
      " [1.0000e-02 9.7817e-01 9.6538e-01 1.0727e-01 1.7890e-01]\n",
      " [3.0000e-02 9.6289e-01 9.5639e-01 1.8411e-01 2.4181e-01]\n",
      " [1.0000e-01 9.5041e-01 9.4118e-01 2.4904e-01 2.6722e-01]\n",
      " [3.0000e-01 9.0423e-01 8.9679e-01 3.6103e-01 3.7764e-01]]\n"
     ]
    }
   ],
   "source": [
    "regs=[0.00003,0.0001,0.0003,0.001,0.003,0.01,0.03,0.1,0.3]\n",
    "stats_4cn=run_loop_torch2(CNNBinary4,train_im_loader,test_im_loader,train_im_loader_pred,target_train,target_test,240,64,0.001,regs)\n",
    "np.savetxt(\"conv2d_4n_v2_full_gal_240.txt\",stats_4cn)\n",
    "#200 not fully enough to converge for smnall regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff5e01d",
   "metadata": {},
   "source": [
    "Should save how long a method takes and possible optimize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7092baa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running reg of 3e-05\n",
      "initial run of high regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789929cffe2841cebb5116522bf7603f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.62530 | Test Loss: 0.54813\n",
      "Epoch 002: | Train Loss: 0.55243 | Test Loss: 0.65748\n",
      "Epoch 003: | Train Loss: 0.52725 | Test Loss: 0.63462\n",
      "Epoch 004: | Train Loss: 0.60679 | Test Loss: 0.62239\n",
      "Epoch 005: | Train Loss: 0.61382 | Test Loss: 0.61611\n",
      "Epoch 006: | Train Loss: 0.61027 | Test Loss: 0.61598\n",
      "Epoch 007: | Train Loss: 0.61031 | Test Loss: 0.61731\n",
      "Epoch 008: | Train Loss: 0.61177 | Test Loss: 0.61772\n",
      "Epoch 009: | Train Loss: 0.61132 | Test Loss: 0.61814\n",
      "Epoch 010: | Train Loss: 0.61240 | Test Loss: 0.61837\n",
      "Epoch 011: | Train Loss: 0.61253 | Test Loss: 0.61819\n",
      "Epoch 012: | Train Loss: 0.61181 | Test Loss: 0.61877\n",
      "Epoch 013: | Train Loss: 0.61316 | Test Loss: 0.61859\n",
      "Epoch 014: | Train Loss: 0.61243 | Test Loss: 0.61849\n",
      "Epoch 015: | Train Loss: 0.61286 | Test Loss: 0.61912\n",
      "Epoch 016: | Train Loss: 0.61245 | Test Loss: 0.61900\n",
      "Epoch 017: | Train Loss: 0.61341 | Test Loss: 0.61931\n",
      "Epoch 018: | Train Loss: 0.61296 | Test Loss: 0.61899\n",
      "Epoch 019: | Train Loss: 0.61307 | Test Loss: 0.61888\n",
      "Epoch 020: | Train Loss: 0.61291 | Test Loss: 0.61906\n",
      "run with given regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b82b4257d5b4367b4b30a3cdb76da96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.58568 | Test Loss: 0.52036\n",
      "Epoch 002: | Train Loss: 0.57693 | Test Loss: 0.66777\n",
      "Epoch 003: | Train Loss: 0.46963 | Test Loss: 0.38988\n",
      "Epoch 004: | Train Loss: 0.32577 | Test Loss: 0.35789\n",
      "Epoch 005: | Train Loss: 0.27584 | Test Loss: 0.40460\n",
      "Epoch 006: | Train Loss: 0.27943 | Test Loss: 0.48157\n",
      "Epoch 007: | Train Loss: 0.25407 | Test Loss: 0.40784\n",
      "Epoch 008: | Train Loss: 0.25977 | Test Loss: 0.44302\n",
      "Epoch 009: | Train Loss: 0.31496 | Test Loss: 0.45569\n",
      "Epoch 010: | Train Loss: 0.26309 | Test Loss: 0.53386\n",
      "Epoch 011: | Train Loss: 0.24731 | Test Loss: 0.58034\n",
      "Epoch 012: | Train Loss: 0.21866 | Test Loss: 0.37714\n",
      "Epoch 013: | Train Loss: 0.22648 | Test Loss: 0.44088\n",
      "Epoch 014: | Train Loss: 0.21589 | Test Loss: 0.63756\n",
      "Epoch 015: | Train Loss: 0.24014 | Test Loss: 0.40167\n",
      "Epoch 016: | Train Loss: 0.21477 | Test Loss: 0.50258\n",
      "Epoch 017: | Train Loss: 0.22311 | Test Loss: 0.42515\n",
      "Epoch 018: | Train Loss: 0.20160 | Test Loss: 0.45904\n",
      "Epoch 019: | Train Loss: 0.22521 | Test Loss: 0.44104\n",
      "Epoch 020: | Train Loss: 0.21275 | Test Loss: 0.41612\n",
      "Epoch 021: | Train Loss: 0.21898 | Test Loss: 0.54558\n",
      "Epoch 022: | Train Loss: 0.19908 | Test Loss: 0.52182\n",
      "Epoch 023: | Train Loss: 0.19859 | Test Loss: 0.52049\n",
      "Epoch 024: | Train Loss: 0.22889 | Test Loss: 0.53421\n",
      "Epoch 025: | Train Loss: 0.20691 | Test Loss: 0.43864\n",
      "Epoch 026: | Train Loss: 0.19148 | Test Loss: 0.41997\n",
      "Epoch 027: | Train Loss: 0.19189 | Test Loss: 0.42572\n",
      "Epoch 028: | Train Loss: 0.18804 | Test Loss: 0.49944\n",
      "Epoch 029: | Train Loss: 0.23513 | Test Loss: 0.61572\n",
      "Epoch 030: | Train Loss: 0.19698 | Test Loss: 0.47151\n",
      "Epoch 031: | Train Loss: 0.18383 | Test Loss: 0.53744\n",
      "Epoch 032: | Train Loss: 0.18585 | Test Loss: 0.67285\n",
      "Epoch 033: | Train Loss: 0.18077 | Test Loss: 0.58060\n",
      "Epoch 034: | Train Loss: 0.18363 | Test Loss: 0.53168\n",
      "Epoch 035: | Train Loss: 0.18192 | Test Loss: 0.47599\n",
      "Epoch 036: | Train Loss: 0.19087 | Test Loss: 0.75868\n",
      "Epoch 037: | Train Loss: 0.16786 | Test Loss: 0.67597\n",
      "Epoch 038: | Train Loss: 0.17797 | Test Loss: 0.47326\n",
      "Epoch 039: | Train Loss: 0.17407 | Test Loss: 0.46931\n",
      "Epoch 040: | Train Loss: 0.19481 | Test Loss: 0.48067\n",
      "Epoch 041: | Train Loss: 0.20870 | Test Loss: 0.56050\n",
      "Epoch 042: | Train Loss: 0.19202 | Test Loss: 0.63262\n",
      "Epoch 043: | Train Loss: 0.21121 | Test Loss: 0.51785\n",
      "Epoch 044: | Train Loss: 0.20993 | Test Loss: 0.46602\n",
      "Epoch 045: | Train Loss: 0.19065 | Test Loss: 0.51532\n",
      "Epoch 046: | Train Loss: 0.17850 | Test Loss: 0.55817\n",
      "Epoch 047: | Train Loss: 0.16983 | Test Loss: 0.52436\n",
      "Epoch 048: | Train Loss: 0.16766 | Test Loss: 0.42485\n",
      "Epoch 049: | Train Loss: 0.16287 | Test Loss: 0.50357\n",
      "Epoch 050: | Train Loss: 0.15561 | Test Loss: 0.58769\n",
      "Epoch 051: | Train Loss: 0.16694 | Test Loss: 0.47650\n",
      "Epoch 052: | Train Loss: 0.16112 | Test Loss: 0.57693\n",
      "Epoch 053: | Train Loss: 0.16837 | Test Loss: 0.46027\n",
      "Epoch 054: | Train Loss: 0.18182 | Test Loss: 0.59661\n",
      "Epoch 055: | Train Loss: 0.15780 | Test Loss: 0.44553\n",
      "Epoch 056: | Train Loss: 0.17967 | Test Loss: 0.52769\n",
      "Epoch 057: | Train Loss: 0.15918 | Test Loss: 0.52009\n",
      "Epoch 058: | Train Loss: 0.15912 | Test Loss: 0.56069\n",
      "Epoch 059: | Train Loss: 0.15159 | Test Loss: 0.65354\n",
      "Epoch 060: | Train Loss: 0.15113 | Test Loss: 0.66808\n",
      "Epoch 061: | Train Loss: 0.17440 | Test Loss: 0.43659\n",
      "Epoch 062: | Train Loss: 0.16579 | Test Loss: 0.64147\n",
      "Epoch 063: | Train Loss: 0.17414 | Test Loss: 0.74330\n",
      "Epoch 064: | Train Loss: 0.20296 | Test Loss: 0.90938\n",
      "Epoch 065: | Train Loss: 0.21969 | Test Loss: 0.55787\n",
      "Epoch 066: | Train Loss: 0.17440 | Test Loss: 0.51438\n",
      "Epoch 067: | Train Loss: 0.17917 | Test Loss: 0.67310\n",
      "Epoch 068: | Train Loss: 0.17064 | Test Loss: 0.50954\n",
      "Epoch 069: | Train Loss: 0.16546 | Test Loss: 0.61211\n",
      "Epoch 070: | Train Loss: 0.18241 | Test Loss: 0.63649\n",
      "Epoch 071: | Train Loss: 0.19309 | Test Loss: 0.61229\n",
      "Epoch 072: | Train Loss: 0.18111 | Test Loss: 0.42038\n",
      "Epoch 073: | Train Loss: 0.18673 | Test Loss: 0.49833\n",
      "Epoch 074: | Train Loss: 0.16822 | Test Loss: 0.55311\n",
      "Epoch 075: | Train Loss: 0.15578 | Test Loss: 0.82094\n",
      "Epoch 076: | Train Loss: 0.16311 | Test Loss: 0.45102\n",
      "Epoch 077: | Train Loss: 0.16282 | Test Loss: 0.48173\n",
      "Epoch 078: | Train Loss: 0.14975 | Test Loss: 0.39991\n",
      "Epoch 079: | Train Loss: 0.15143 | Test Loss: 0.43669\n",
      "Epoch 080: | Train Loss: 0.14954 | Test Loss: 0.37052\n",
      "Epoch 081: | Train Loss: 0.16017 | Test Loss: 0.52919\n",
      "Epoch 082: | Train Loss: 0.15428 | Test Loss: 0.47530\n",
      "Epoch 083: | Train Loss: 0.15516 | Test Loss: 0.39794\n",
      "Epoch 084: | Train Loss: 0.15354 | Test Loss: 0.63572\n",
      "Epoch 085: | Train Loss: 0.14080 | Test Loss: 0.37137\n",
      "Epoch 086: | Train Loss: 0.15550 | Test Loss: 0.51869\n",
      "Epoch 087: | Train Loss: 0.16291 | Test Loss: 0.86009\n",
      "Epoch 088: | Train Loss: 0.15505 | Test Loss: 0.56953\n",
      "Epoch 089: | Train Loss: 0.17331 | Test Loss: 0.48772\n",
      "Epoch 090: | Train Loss: 0.16523 | Test Loss: 0.44161\n",
      "Epoch 091: | Train Loss: 0.15453 | Test Loss: 0.61289\n",
      "Epoch 092: | Train Loss: 0.15629 | Test Loss: 0.71469\n",
      "Epoch 093: | Train Loss: 0.14863 | Test Loss: 0.72023\n",
      "Epoch 094: | Train Loss: 0.15220 | Test Loss: 0.59400\n",
      "Epoch 095: | Train Loss: 0.13567 | Test Loss: 0.52237\n",
      "Epoch 096: | Train Loss: 0.13455 | Test Loss: 0.51816\n",
      "Epoch 097: | Train Loss: 0.13898 | Test Loss: 0.64142\n",
      "Epoch 098: | Train Loss: 0.18053 | Test Loss: 0.45484\n",
      "Epoch 099: | Train Loss: 0.15539 | Test Loss: 0.40542\n",
      "Epoch 100: | Train Loss: 0.17119 | Test Loss: 0.67316\n",
      "Epoch 101: | Train Loss: 0.14690 | Test Loss: 0.41565\n",
      "Epoch 102: | Train Loss: 0.14738 | Test Loss: 0.61975\n",
      "Epoch 103: | Train Loss: 0.15657 | Test Loss: 0.45249\n",
      "Epoch 104: | Train Loss: 0.13256 | Test Loss: 0.57311\n",
      "Epoch 105: | Train Loss: 0.15642 | Test Loss: 0.34669\n",
      "Epoch 106: | Train Loss: 0.15542 | Test Loss: 0.44022\n",
      "Epoch 107: | Train Loss: 0.18672 | Test Loss: 0.42393\n",
      "Epoch 108: | Train Loss: 0.15932 | Test Loss: 0.62412\n",
      "Epoch 109: | Train Loss: 0.14570 | Test Loss: 0.55737\n",
      "Epoch 110: | Train Loss: 0.20866 | Test Loss: 0.72637\n",
      "Epoch 111: | Train Loss: 0.15507 | Test Loss: 0.62999\n",
      "Epoch 112: | Train Loss: 0.12958 | Test Loss: 1.00232\n",
      "Epoch 113: | Train Loss: 0.14697 | Test Loss: 0.70679\n",
      "Epoch 114: | Train Loss: 0.16230 | Test Loss: 0.59634\n",
      "Epoch 115: | Train Loss: 0.12271 | Test Loss: 0.56038\n",
      "Epoch 116: | Train Loss: 0.12543 | Test Loss: 0.71338\n",
      "Epoch 117: | Train Loss: 0.13435 | Test Loss: 0.64816\n",
      "Epoch 118: | Train Loss: 0.13949 | Test Loss: 0.58080\n",
      "Epoch 119: | Train Loss: 0.12225 | Test Loss: 0.56285\n",
      "Epoch 120: | Train Loss: 0.11585 | Test Loss: 0.69603\n",
      "Epoch 121: | Train Loss: 0.12622 | Test Loss: 0.46430\n",
      "Epoch 122: | Train Loss: 0.12233 | Test Loss: 0.53065\n",
      "Epoch 123: | Train Loss: 0.11792 | Test Loss: 0.72513\n",
      "Epoch 124: | Train Loss: 0.13293 | Test Loss: 0.55265\n",
      "Epoch 125: | Train Loss: 0.12545 | Test Loss: 0.59565\n",
      "Epoch 126: | Train Loss: 0.14731 | Test Loss: 0.78434\n",
      "Epoch 127: | Train Loss: 0.14645 | Test Loss: 0.69473\n",
      "Epoch 128: | Train Loss: 0.17209 | Test Loss: 0.41341\n",
      "Epoch 129: | Train Loss: 0.11436 | Test Loss: 0.51233\n",
      "Epoch 130: | Train Loss: 0.11554 | Test Loss: 0.58481\n",
      "Epoch 131: | Train Loss: 0.13759 | Test Loss: 0.67931\n",
      "Epoch 132: | Train Loss: 0.12830 | Test Loss: 0.80719\n",
      "Epoch 133: | Train Loss: 0.11208 | Test Loss: 0.60650\n",
      "Epoch 134: | Train Loss: 0.11573 | Test Loss: 0.50344\n",
      "Epoch 135: | Train Loss: 0.14452 | Test Loss: 0.46865\n",
      "Epoch 136: | Train Loss: 0.13737 | Test Loss: 0.67078\n",
      "Epoch 137: | Train Loss: 0.13786 | Test Loss: 0.59328\n",
      "Epoch 138: | Train Loss: 0.17293 | Test Loss: 0.54617\n",
      "Epoch 139: | Train Loss: 0.11784 | Test Loss: 0.60526\n",
      "Epoch 140: | Train Loss: 0.12273 | Test Loss: 0.64009\n",
      "Epoch 141: | Train Loss: 0.13309 | Test Loss: 0.53475\n",
      "Epoch 142: | Train Loss: 0.11520 | Test Loss: 0.56138\n",
      "Epoch 143: | Train Loss: 0.11030 | Test Loss: 0.42623\n",
      "Epoch 144: | Train Loss: 0.12336 | Test Loss: 0.52951\n",
      "Epoch 145: | Train Loss: 0.11001 | Test Loss: 0.57104\n",
      "Epoch 146: | Train Loss: 0.10888 | Test Loss: 0.59920\n",
      "Epoch 147: | Train Loss: 0.11563 | Test Loss: 0.48736\n",
      "Epoch 148: | Train Loss: 0.11551 | Test Loss: 0.68132\n",
      "Epoch 149: | Train Loss: 0.14232 | Test Loss: 0.82047\n",
      "Epoch 150: | Train Loss: 0.11018 | Test Loss: 0.57891\n",
      "Epoch 151: | Train Loss: 0.12636 | Test Loss: 0.72112\n",
      "Epoch 152: | Train Loss: 0.16404 | Test Loss: 0.94675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: | Train Loss: 0.14740 | Test Loss: 0.63356\n",
      "Epoch 154: | Train Loss: 0.13702 | Test Loss: 0.69624\n",
      "Epoch 155: | Train Loss: 0.13984 | Test Loss: 1.00346\n",
      "Epoch 156: | Train Loss: 0.12886 | Test Loss: 0.46436\n",
      "Epoch 157: | Train Loss: 0.11456 | Test Loss: 0.57289\n",
      "Epoch 158: | Train Loss: 0.13018 | Test Loss: 0.52338\n",
      "Epoch 159: | Train Loss: 0.10839 | Test Loss: 0.38667\n",
      "Epoch 160: | Train Loss: 0.12132 | Test Loss: 0.40404\n",
      "Epoch 161: | Train Loss: 0.12700 | Test Loss: 0.48841\n",
      "Epoch 162: | Train Loss: 0.14471 | Test Loss: 0.58066\n",
      "Epoch 163: | Train Loss: 0.12967 | Test Loss: 0.57529\n",
      "Epoch 164: | Train Loss: 0.12452 | Test Loss: 0.54302\n",
      "Epoch 165: | Train Loss: 0.13745 | Test Loss: 0.45998\n",
      "Epoch 166: | Train Loss: 0.12063 | Test Loss: 0.77990\n",
      "Epoch 167: | Train Loss: 0.14191 | Test Loss: 0.38773\n",
      "Epoch 168: | Train Loss: 0.13490 | Test Loss: 0.40738\n",
      "Epoch 169: | Train Loss: 0.11509 | Test Loss: 0.45310\n",
      "Epoch 170: | Train Loss: 0.10799 | Test Loss: 0.46481\n",
      "Epoch 171: | Train Loss: 0.10528 | Test Loss: 0.47013\n",
      "Epoch 172: | Train Loss: 0.11022 | Test Loss: 0.72185\n",
      "Epoch 173: | Train Loss: 0.15070 | Test Loss: 0.44338\n",
      "Epoch 174: | Train Loss: 0.09751 | Test Loss: 0.46200\n",
      "Epoch 175: | Train Loss: 0.10218 | Test Loss: 0.55489\n",
      "Epoch 176: | Train Loss: 0.10525 | Test Loss: 0.46712\n",
      "Epoch 177: | Train Loss: 0.10920 | Test Loss: 0.57872\n",
      "Epoch 178: | Train Loss: 0.13789 | Test Loss: 0.53712\n",
      "Epoch 179: | Train Loss: 0.11070 | Test Loss: 0.59482\n",
      "Epoch 180: | Train Loss: 0.22402 | Test Loss: 0.71204\n",
      "Epoch 181: | Train Loss: 0.12889 | Test Loss: 0.73536\n",
      "Epoch 182: | Train Loss: 0.14309 | Test Loss: 0.61654\n",
      "Epoch 183: | Train Loss: 0.12444 | Test Loss: 0.65921\n",
      "Epoch 184: | Train Loss: 0.12640 | Test Loss: 0.62098\n",
      "Epoch 185: | Train Loss: 0.13790 | Test Loss: 0.87034\n",
      "Epoch 186: | Train Loss: 0.15729 | Test Loss: 0.60581\n",
      "Epoch 187: | Train Loss: 0.12527 | Test Loss: 0.78714\n",
      "Epoch 188: | Train Loss: 0.12460 | Test Loss: 0.67471\n",
      "Epoch 189: | Train Loss: 0.11568 | Test Loss: 0.81205\n",
      "Epoch 190: | Train Loss: 0.11513 | Test Loss: 0.83873\n",
      "Epoch 191: | Train Loss: 0.11399 | Test Loss: 0.94328\n",
      "Epoch 192: | Train Loss: 0.13138 | Test Loss: 0.79467\n",
      "Epoch 193: | Train Loss: 0.12840 | Test Loss: 0.87193\n",
      "Epoch 194: | Train Loss: 0.12454 | Test Loss: 0.98982\n",
      "Epoch 195: | Train Loss: 0.12554 | Test Loss: 0.88115\n",
      "Epoch 196: | Train Loss: 0.13960 | Test Loss: 0.98919\n",
      "Epoch 197: | Train Loss: 0.11636 | Test Loss: 0.78371\n",
      "Epoch 198: | Train Loss: 0.13794 | Test Loss: 0.81907\n",
      "Epoch 199: | Train Loss: 0.13735 | Test Loss: 1.09031\n",
      "Epoch 200: | Train Loss: 0.13573 | Test Loss: 0.71770\n",
      "Epoch 201: | Train Loss: 0.14092 | Test Loss: 0.90699\n",
      "Epoch 202: | Train Loss: 0.16679 | Test Loss: 0.52742\n",
      "Epoch 203: | Train Loss: 0.12601 | Test Loss: 0.70534\n",
      "Epoch 204: | Train Loss: 0.13728 | Test Loss: 0.82087\n",
      "Epoch 205: | Train Loss: 0.14971 | Test Loss: 0.62494\n",
      "Epoch 206: | Train Loss: 0.12370 | Test Loss: 0.58827\n",
      "Epoch 207: | Train Loss: 0.12191 | Test Loss: 0.49919\n",
      "Epoch 208: | Train Loss: 0.11164 | Test Loss: 0.60432\n",
      "Epoch 209: | Train Loss: 0.14681 | Test Loss: 0.52096\n",
      "Epoch 210: | Train Loss: 0.13158 | Test Loss: 0.38311\n",
      "Epoch 211: | Train Loss: 0.12121 | Test Loss: 0.77897\n",
      "Epoch 212: | Train Loss: 0.11798 | Test Loss: 0.66348\n",
      "Epoch 213: | Train Loss: 0.14079 | Test Loss: 0.60996\n",
      "Epoch 214: | Train Loss: 0.13563 | Test Loss: 0.51525\n",
      "Epoch 215: | Train Loss: 0.13723 | Test Loss: 0.52205\n",
      "Epoch 216: | Train Loss: 0.14259 | Test Loss: 0.55879\n",
      "Epoch 217: | Train Loss: 0.11244 | Test Loss: 0.55857\n",
      "Epoch 218: | Train Loss: 0.14867 | Test Loss: 0.50317\n",
      "Epoch 219: | Train Loss: 0.12813 | Test Loss: 0.57221\n",
      "Epoch 220: | Train Loss: 0.11788 | Test Loss: 0.55312\n",
      "Epoch 221: | Train Loss: 0.12328 | Test Loss: 0.55527\n",
      "Epoch 222: | Train Loss: 0.11760 | Test Loss: 0.89862\n",
      "Epoch 223: | Train Loss: 0.13468 | Test Loss: 0.47667\n",
      "Epoch 224: | Train Loss: 0.13217 | Test Loss: 0.51706\n",
      "Epoch 225: | Train Loss: 0.11421 | Test Loss: 0.52197\n",
      "Epoch 226: | Train Loss: 0.12370 | Test Loss: 0.50392\n",
      "Epoch 227: | Train Loss: 0.22010 | Test Loss: 0.84570\n",
      "Epoch 228: | Train Loss: 0.21504 | Test Loss: 1.03564\n",
      "Epoch 229: | Train Loss: 0.22075 | Test Loss: 0.84186\n",
      "Epoch 230: | Train Loss: 0.19279 | Test Loss: 0.92999\n",
      "Epoch 231: | Train Loss: 0.21575 | Test Loss: 0.89439\n",
      "Epoch 232: | Train Loss: 0.23212 | Test Loss: 0.65949\n",
      "Epoch 233: | Train Loss: 0.17542 | Test Loss: 0.68238\n",
      "Epoch 234: | Train Loss: 0.13136 | Test Loss: 0.55475\n",
      "Epoch 235: | Train Loss: 0.11124 | Test Loss: 0.64953\n",
      "Epoch 236: | Train Loss: 0.09863 | Test Loss: 0.54840\n",
      "Epoch 237: | Train Loss: 0.09352 | Test Loss: 0.52744\n",
      "Epoch 238: | Train Loss: 0.10783 | Test Loss: 0.55981\n",
      "Epoch 239: | Train Loss: 0.12123 | Test Loss: 0.55282\n",
      "Epoch 240: | Train Loss: 0.11108 | Test Loss: 0.72226\n",
      "stats of l2reg of  3e-05 are [0.98671 0.94926 0.07634 0.43522]\n",
      "running reg of 0.0001\n",
      "initial run of high regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d01005aca2a4b6aa2523a9f3486617a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.70727 | Test Loss: 0.53889\n",
      "Epoch 002: | Train Loss: 0.55685 | Test Loss: 0.54362\n",
      "Epoch 003: | Train Loss: 0.59686 | Test Loss: 0.57051\n",
      "Epoch 004: | Train Loss: 0.54207 | Test Loss: 0.69037\n",
      "Epoch 005: | Train Loss: 0.59096 | Test Loss: 0.62509\n",
      "Epoch 006: | Train Loss: 0.61672 | Test Loss: 0.62059\n",
      "Epoch 007: | Train Loss: 0.61455 | Test Loss: 0.61944\n",
      "Epoch 008: | Train Loss: 0.61307 | Test Loss: 0.61870\n",
      "Epoch 009: | Train Loss: 0.61263 | Test Loss: 0.61893\n",
      "Epoch 010: | Train Loss: 0.61277 | Test Loss: 0.61897\n",
      "Epoch 011: | Train Loss: 0.61227 | Test Loss: 0.61905\n",
      "Epoch 012: | Train Loss: 0.61261 | Test Loss: 0.61941\n",
      "Epoch 013: | Train Loss: 0.61343 | Test Loss: 0.61948\n",
      "Epoch 014: | Train Loss: 0.61324 | Test Loss: 0.61895\n",
      "Epoch 015: | Train Loss: 0.61306 | Test Loss: 0.61909\n",
      "Epoch 016: | Train Loss: 0.61316 | Test Loss: 0.61856\n",
      "Epoch 017: | Train Loss: 0.61274 | Test Loss: 0.61932\n",
      "Epoch 018: | Train Loss: 0.61239 | Test Loss: 0.61901\n",
      "Epoch 019: | Train Loss: 0.61354 | Test Loss: 0.61943\n",
      "Epoch 020: | Train Loss: 0.61329 | Test Loss: 0.61905\n",
      "run with given regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e91097052324583b9096545c1ebdb51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.58928 | Test Loss: 0.47795\n",
      "Epoch 002: | Train Loss: 0.56418 | Test Loss: 0.53269\n",
      "Epoch 003: | Train Loss: 0.57207 | Test Loss: 0.44266\n",
      "Epoch 004: | Train Loss: 0.42006 | Test Loss: 0.33883\n",
      "Epoch 005: | Train Loss: 0.33827 | Test Loss: 0.43634\n",
      "Epoch 006: | Train Loss: 0.27220 | Test Loss: 0.38403\n",
      "Epoch 007: | Train Loss: 0.30430 | Test Loss: 0.44687\n",
      "Epoch 008: | Train Loss: 0.26855 | Test Loss: 0.44226\n",
      "Epoch 009: | Train Loss: 0.29391 | Test Loss: 0.57440\n",
      "Epoch 010: | Train Loss: 0.30532 | Test Loss: 0.59144\n",
      "Epoch 011: | Train Loss: 0.25703 | Test Loss: 0.46791\n",
      "Epoch 012: | Train Loss: 0.24685 | Test Loss: 0.43523\n",
      "Epoch 013: | Train Loss: 0.27648 | Test Loss: 0.47159\n",
      "Epoch 014: | Train Loss: 0.27025 | Test Loss: 0.68124\n",
      "Epoch 015: | Train Loss: 0.27116 | Test Loss: 0.42668\n",
      "Epoch 016: | Train Loss: 0.24591 | Test Loss: 0.41511\n",
      "Epoch 017: | Train Loss: 0.24467 | Test Loss: 0.56477\n",
      "Epoch 018: | Train Loss: 0.25170 | Test Loss: 0.41170\n",
      "Epoch 019: | Train Loss: 0.31315 | Test Loss: 0.44473\n",
      "Epoch 020: | Train Loss: 0.22208 | Test Loss: 0.44699\n",
      "Epoch 021: | Train Loss: 0.22959 | Test Loss: 0.40335\n",
      "Epoch 022: | Train Loss: 0.22758 | Test Loss: 0.47136\n",
      "Epoch 023: | Train Loss: 0.22149 | Test Loss: 0.41448\n",
      "Epoch 024: | Train Loss: 0.21574 | Test Loss: 0.49457\n",
      "Epoch 025: | Train Loss: 0.22286 | Test Loss: 0.60949\n",
      "Epoch 026: | Train Loss: 0.23928 | Test Loss: 0.50294\n",
      "Epoch 027: | Train Loss: 0.22443 | Test Loss: 0.50155\n",
      "Epoch 028: | Train Loss: 0.20830 | Test Loss: 0.41358\n",
      "Epoch 029: | Train Loss: 0.20782 | Test Loss: 0.48304\n",
      "Epoch 030: | Train Loss: 0.21385 | Test Loss: 0.49090\n",
      "Epoch 031: | Train Loss: 0.21650 | Test Loss: 0.50890\n",
      "Epoch 032: | Train Loss: 0.21847 | Test Loss: 0.56185\n",
      "Epoch 033: | Train Loss: 0.21106 | Test Loss: 0.52434\n",
      "Epoch 034: | Train Loss: 0.23244 | Test Loss: 0.45575\n",
      "Epoch 035: | Train Loss: 0.21884 | Test Loss: 0.55370\n",
      "Epoch 036: | Train Loss: 0.24437 | Test Loss: 0.50550\n",
      "Epoch 037: | Train Loss: 0.21137 | Test Loss: 0.44045\n",
      "Epoch 038: | Train Loss: 0.20726 | Test Loss: 0.59625\n",
      "Epoch 039: | Train Loss: 0.23121 | Test Loss: 0.44745\n",
      "Epoch 040: | Train Loss: 0.20507 | Test Loss: 0.50867\n",
      "Epoch 041: | Train Loss: 0.23303 | Test Loss: 0.60355\n",
      "Epoch 042: | Train Loss: 0.20514 | Test Loss: 0.51330\n",
      "Epoch 043: | Train Loss: 0.21778 | Test Loss: 0.55519\n",
      "Epoch 044: | Train Loss: 0.21865 | Test Loss: 0.42279\n",
      "Epoch 045: | Train Loss: 0.21534 | Test Loss: 0.47617\n",
      "Epoch 046: | Train Loss: 0.19866 | Test Loss: 0.59689\n",
      "Epoch 047: | Train Loss: 0.20488 | Test Loss: 0.51574\n",
      "Epoch 048: | Train Loss: 0.20349 | Test Loss: 0.42242\n",
      "Epoch 049: | Train Loss: 0.21086 | Test Loss: 0.63618\n",
      "Epoch 050: | Train Loss: 0.24183 | Test Loss: 0.41548\n",
      "Epoch 051: | Train Loss: 0.21620 | Test Loss: 0.43306\n",
      "Epoch 052: | Train Loss: 0.20959 | Test Loss: 0.45414\n",
      "Epoch 053: | Train Loss: 0.21695 | Test Loss: 0.41186\n",
      "Epoch 054: | Train Loss: 0.20597 | Test Loss: 0.59479\n",
      "Epoch 055: | Train Loss: 0.22045 | Test Loss: 0.37308\n",
      "Epoch 056: | Train Loss: 0.21474 | Test Loss: 0.53658\n",
      "Epoch 057: | Train Loss: 0.19914 | Test Loss: 0.45987\n",
      "Epoch 058: | Train Loss: 0.19578 | Test Loss: 0.49081\n",
      "Epoch 059: | Train Loss: 0.22050 | Test Loss: 0.52729\n",
      "Epoch 060: | Train Loss: 0.19910 | Test Loss: 0.44903\n",
      "Epoch 061: | Train Loss: 0.18913 | Test Loss: 0.62908\n",
      "Epoch 062: | Train Loss: 0.19845 | Test Loss: 0.59459\n",
      "Epoch 063: | Train Loss: 0.20258 | Test Loss: 0.57358\n",
      "Epoch 064: | Train Loss: 0.22385 | Test Loss: 0.60762\n",
      "Epoch 065: | Train Loss: 0.18040 | Test Loss: 0.52127\n",
      "Epoch 066: | Train Loss: 0.18978 | Test Loss: 0.46360\n",
      "Epoch 067: | Train Loss: 0.18285 | Test Loss: 0.55349\n",
      "Epoch 068: | Train Loss: 0.20770 | Test Loss: 0.45118\n",
      "Epoch 069: | Train Loss: 0.18779 | Test Loss: 0.43386\n",
      "Epoch 070: | Train Loss: 0.20357 | Test Loss: 0.46428\n",
      "Epoch 071: | Train Loss: 0.21572 | Test Loss: 0.57186\n",
      "Epoch 072: | Train Loss: 0.21937 | Test Loss: 0.53242\n",
      "Epoch 073: | Train Loss: 0.21150 | Test Loss: 0.47987\n",
      "Epoch 074: | Train Loss: 0.18881 | Test Loss: 0.43797\n",
      "Epoch 075: | Train Loss: 0.20143 | Test Loss: 0.43790\n",
      "Epoch 076: | Train Loss: 0.19991 | Test Loss: 0.39643\n",
      "Epoch 077: | Train Loss: 0.19276 | Test Loss: 0.43456\n",
      "Epoch 078: | Train Loss: 0.19577 | Test Loss: 0.49498\n",
      "Epoch 079: | Train Loss: 0.19429 | Test Loss: 0.44008\n",
      "Epoch 080: | Train Loss: 0.18108 | Test Loss: 0.47571\n",
      "Epoch 081: | Train Loss: 0.18000 | Test Loss: 0.40406\n",
      "Epoch 082: | Train Loss: 0.20214 | Test Loss: 0.92256\n",
      "Epoch 083: | Train Loss: 0.20609 | Test Loss: 0.62320\n",
      "Epoch 084: | Train Loss: 0.20399 | Test Loss: 0.53347\n",
      "Epoch 085: | Train Loss: 0.20095 | Test Loss: 0.50601\n",
      "Epoch 086: | Train Loss: 0.19425 | Test Loss: 0.39123\n",
      "Epoch 087: | Train Loss: 0.19450 | Test Loss: 0.39696\n",
      "Epoch 088: | Train Loss: 0.20531 | Test Loss: 0.46652\n",
      "Epoch 089: | Train Loss: 0.18633 | Test Loss: 0.53729\n",
      "Epoch 090: | Train Loss: 0.18888 | Test Loss: 0.41881\n",
      "Epoch 091: | Train Loss: 0.19792 | Test Loss: 0.60288\n",
      "Epoch 092: | Train Loss: 0.22433 | Test Loss: 0.55163\n",
      "Epoch 093: | Train Loss: 0.20424 | Test Loss: 0.40076\n",
      "Epoch 094: | Train Loss: 0.20504 | Test Loss: 0.47886\n",
      "Epoch 095: | Train Loss: 0.21070 | Test Loss: 0.38254\n",
      "Epoch 096: | Train Loss: 0.20975 | Test Loss: 0.43577\n",
      "Epoch 097: | Train Loss: 0.18053 | Test Loss: 0.67884\n",
      "Epoch 098: | Train Loss: 0.18208 | Test Loss: 0.46017\n",
      "Epoch 099: | Train Loss: 0.18125 | Test Loss: 0.50585\n",
      "Epoch 100: | Train Loss: 0.17915 | Test Loss: 0.45535\n",
      "Epoch 101: | Train Loss: 0.18192 | Test Loss: 0.53026\n",
      "Epoch 102: | Train Loss: 0.18336 | Test Loss: 0.45376\n",
      "Epoch 103: | Train Loss: 0.28482 | Test Loss: 0.43888\n",
      "Epoch 104: | Train Loss: 0.26345 | Test Loss: 0.60747\n",
      "Epoch 105: | Train Loss: 0.20943 | Test Loss: 0.62039\n",
      "Epoch 106: | Train Loss: 0.16969 | Test Loss: 0.40733\n",
      "Epoch 107: | Train Loss: 0.18744 | Test Loss: 0.50650\n",
      "Epoch 108: | Train Loss: 0.20688 | Test Loss: 0.72826\n",
      "Epoch 109: | Train Loss: 0.22368 | Test Loss: 0.33367\n",
      "Epoch 110: | Train Loss: 0.18278 | Test Loss: 0.39309\n",
      "Epoch 111: | Train Loss: 0.16913 | Test Loss: 0.39347\n",
      "Epoch 112: | Train Loss: 0.16369 | Test Loss: 0.47775\n",
      "Epoch 113: | Train Loss: 0.17332 | Test Loss: 0.42329\n",
      "Epoch 114: | Train Loss: 0.16304 | Test Loss: 0.42655\n",
      "Epoch 115: | Train Loss: 0.15952 | Test Loss: 0.54859\n",
      "Epoch 116: | Train Loss: 0.15781 | Test Loss: 0.53147\n",
      "Epoch 117: | Train Loss: 0.16596 | Test Loss: 0.49550\n",
      "Epoch 118: | Train Loss: 0.23003 | Test Loss: 0.43366\n",
      "Epoch 119: | Train Loss: 0.18194 | Test Loss: 0.41355\n",
      "Epoch 120: | Train Loss: 0.18168 | Test Loss: 0.45187\n",
      "Epoch 121: | Train Loss: 0.22182 | Test Loss: 0.50160\n",
      "Epoch 122: | Train Loss: 0.17823 | Test Loss: 0.40999\n",
      "Epoch 123: | Train Loss: 0.27388 | Test Loss: 0.99923\n",
      "Epoch 124: | Train Loss: 0.33127 | Test Loss: 0.54960\n",
      "Epoch 125: | Train Loss: 0.16744 | Test Loss: 0.38539\n",
      "Epoch 126: | Train Loss: 0.17602 | Test Loss: 0.40302\n",
      "Epoch 127: | Train Loss: 0.15491 | Test Loss: 0.42425\n",
      "Epoch 128: | Train Loss: 0.15805 | Test Loss: 0.40262\n",
      "Epoch 129: | Train Loss: 0.20728 | Test Loss: 0.40413\n",
      "Epoch 130: | Train Loss: 0.15412 | Test Loss: 0.43739\n",
      "Epoch 131: | Train Loss: 0.16899 | Test Loss: 0.41195\n",
      "Epoch 132: | Train Loss: 0.15500 | Test Loss: 0.43721\n",
      "Epoch 133: | Train Loss: 0.15453 | Test Loss: 0.43949\n",
      "Epoch 134: | Train Loss: 0.15457 | Test Loss: 0.53947\n",
      "Epoch 135: | Train Loss: 0.17660 | Test Loss: 0.39343\n",
      "Epoch 136: | Train Loss: 0.19636 | Test Loss: 0.47322\n",
      "Epoch 137: | Train Loss: 0.16264 | Test Loss: 0.49626\n",
      "Epoch 138: | Train Loss: 0.17429 | Test Loss: 0.46220\n",
      "Epoch 139: | Train Loss: 0.16631 | Test Loss: 0.39518\n",
      "Epoch 140: | Train Loss: 0.14734 | Test Loss: 0.42782\n",
      "Epoch 141: | Train Loss: 0.14883 | Test Loss: 0.45461\n",
      "Epoch 142: | Train Loss: 0.15006 | Test Loss: 0.52450\n",
      "Epoch 143: | Train Loss: 0.15575 | Test Loss: 0.53731\n",
      "Epoch 144: | Train Loss: 0.14518 | Test Loss: 0.52959\n",
      "Epoch 145: | Train Loss: 0.15796 | Test Loss: 0.43639\n",
      "Epoch 146: | Train Loss: 0.15863 | Test Loss: 0.41054\n",
      "Epoch 147: | Train Loss: 0.17394 | Test Loss: 0.37028\n",
      "Epoch 148: | Train Loss: 0.17659 | Test Loss: 0.43259\n",
      "Epoch 149: | Train Loss: 0.15158 | Test Loss: 0.48508\n",
      "Epoch 150: | Train Loss: 0.18795 | Test Loss: 0.39403\n",
      "Epoch 151: | Train Loss: 0.15091 | Test Loss: 0.50719\n",
      "Epoch 152: | Train Loss: 0.15992 | Test Loss: 0.39271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: | Train Loss: 0.15473 | Test Loss: 0.54366\n",
      "Epoch 154: | Train Loss: 0.14960 | Test Loss: 0.44131\n",
      "Epoch 155: | Train Loss: 0.16639 | Test Loss: 0.38702\n",
      "Epoch 156: | Train Loss: 0.14953 | Test Loss: 0.48223\n",
      "Epoch 157: | Train Loss: 0.16894 | Test Loss: 0.52771\n",
      "Epoch 158: | Train Loss: 0.17375 | Test Loss: 0.38521\n",
      "Epoch 159: | Train Loss: 0.16478 | Test Loss: 0.40507\n",
      "Epoch 160: | Train Loss: 0.15181 | Test Loss: 0.58258\n",
      "Epoch 161: | Train Loss: 0.17857 | Test Loss: 0.47415\n",
      "Epoch 162: | Train Loss: 0.18477 | Test Loss: 0.35888\n",
      "Epoch 163: | Train Loss: 0.32213 | Test Loss: 1.09736\n",
      "Epoch 164: | Train Loss: 0.39471 | Test Loss: 0.36476\n",
      "Epoch 165: | Train Loss: 0.19570 | Test Loss: 0.41537\n",
      "Epoch 166: | Train Loss: 0.17162 | Test Loss: 0.39649\n",
      "Epoch 167: | Train Loss: 0.20281 | Test Loss: 0.50844\n",
      "Epoch 168: | Train Loss: 0.26456 | Test Loss: 0.87588\n",
      "Epoch 169: | Train Loss: 0.21541 | Test Loss: 0.40107\n",
      "Epoch 170: | Train Loss: 0.21931 | Test Loss: 0.67441\n",
      "Epoch 171: | Train Loss: 0.16481 | Test Loss: 0.48913\n",
      "Epoch 172: | Train Loss: 0.17406 | Test Loss: 0.49688\n",
      "Epoch 173: | Train Loss: 0.15408 | Test Loss: 0.43784\n",
      "Epoch 174: | Train Loss: 0.18854 | Test Loss: 0.44686\n",
      "Epoch 175: | Train Loss: 0.16559 | Test Loss: 0.37236\n",
      "Epoch 176: | Train Loss: 0.21073 | Test Loss: 0.41240\n",
      "Epoch 177: | Train Loss: 0.16352 | Test Loss: 0.42581\n",
      "Epoch 178: | Train Loss: 0.15243 | Test Loss: 0.39018\n",
      "Epoch 179: | Train Loss: 0.17278 | Test Loss: 0.49275\n",
      "Epoch 180: | Train Loss: 0.15115 | Test Loss: 0.39002\n",
      "Epoch 181: | Train Loss: 0.17649 | Test Loss: 0.35861\n",
      "Epoch 182: | Train Loss: 0.16786 | Test Loss: 0.36255\n",
      "Epoch 183: | Train Loss: 0.15403 | Test Loss: 0.39158\n",
      "Epoch 184: | Train Loss: 0.15663 | Test Loss: 0.48118\n",
      "Epoch 185: | Train Loss: 0.17932 | Test Loss: 0.56331\n",
      "Epoch 186: | Train Loss: 0.18689 | Test Loss: 0.41556\n",
      "Epoch 187: | Train Loss: 0.15895 | Test Loss: 0.41248\n",
      "Epoch 188: | Train Loss: 0.15625 | Test Loss: 0.43987\n",
      "Epoch 189: | Train Loss: 0.16239 | Test Loss: 0.55132\n",
      "Epoch 190: | Train Loss: 0.14305 | Test Loss: 0.48557\n",
      "Epoch 191: | Train Loss: 0.14711 | Test Loss: 0.41257\n",
      "Epoch 192: | Train Loss: 0.15538 | Test Loss: 0.37821\n",
      "Epoch 193: | Train Loss: 0.15681 | Test Loss: 1.00022\n",
      "Epoch 194: | Train Loss: 0.18225 | Test Loss: 0.48570\n",
      "Epoch 195: | Train Loss: 0.15093 | Test Loss: 0.43366\n",
      "Epoch 196: | Train Loss: 0.14090 | Test Loss: 0.58333\n",
      "Epoch 197: | Train Loss: 0.14408 | Test Loss: 0.53383\n",
      "Epoch 198: | Train Loss: 0.15464 | Test Loss: 0.58260\n",
      "Epoch 199: | Train Loss: 0.14699 | Test Loss: 0.43721\n",
      "Epoch 200: | Train Loss: 0.19871 | Test Loss: 0.34145\n",
      "Epoch 201: | Train Loss: 0.16006 | Test Loss: 0.54059\n",
      "Epoch 202: | Train Loss: 0.16329 | Test Loss: 0.38502\n",
      "Epoch 203: | Train Loss: 0.14862 | Test Loss: 0.43976\n",
      "Epoch 204: | Train Loss: 0.15573 | Test Loss: 0.48659\n",
      "Epoch 205: | Train Loss: 0.21298 | Test Loss: 0.39200\n",
      "Epoch 206: | Train Loss: 0.15089 | Test Loss: 0.39674\n",
      "Epoch 207: | Train Loss: 0.14481 | Test Loss: 0.40606\n",
      "Epoch 208: | Train Loss: 0.22765 | Test Loss: 0.92143\n",
      "Epoch 209: | Train Loss: 0.23725 | Test Loss: 0.46429\n",
      "Epoch 210: | Train Loss: 0.19120 | Test Loss: 0.36017\n",
      "Epoch 211: | Train Loss: 0.14949 | Test Loss: 0.47370\n",
      "Epoch 212: | Train Loss: 0.15026 | Test Loss: 0.36971\n",
      "Epoch 213: | Train Loss: 0.17187 | Test Loss: 0.41845\n",
      "Epoch 214: | Train Loss: 0.16337 | Test Loss: 0.41316\n",
      "Epoch 215: | Train Loss: 0.17786 | Test Loss: 0.40836\n",
      "Epoch 216: | Train Loss: 0.18335 | Test Loss: 0.40568\n",
      "Epoch 217: | Train Loss: 0.15151 | Test Loss: 0.40940\n",
      "Epoch 218: | Train Loss: 0.14257 | Test Loss: 0.38392\n",
      "Epoch 219: | Train Loss: 0.14694 | Test Loss: 0.52495\n",
      "Epoch 220: | Train Loss: 0.14889 | Test Loss: 0.56111\n",
      "Epoch 221: | Train Loss: 0.14792 | Test Loss: 0.37523\n",
      "Epoch 222: | Train Loss: 0.14454 | Test Loss: 0.39268\n",
      "Epoch 223: | Train Loss: 0.18260 | Test Loss: 0.37512\n",
      "Epoch 224: | Train Loss: 0.14065 | Test Loss: 0.39739\n",
      "Epoch 225: | Train Loss: 0.19769 | Test Loss: 0.43985\n",
      "Epoch 226: | Train Loss: 0.25430 | Test Loss: 0.40006\n",
      "Epoch 227: | Train Loss: 0.15870 | Test Loss: 0.63010\n",
      "Epoch 228: | Train Loss: 0.18727 | Test Loss: 0.37272\n",
      "Epoch 229: | Train Loss: 0.15914 | Test Loss: 0.38900\n",
      "Epoch 230: | Train Loss: 0.16591 | Test Loss: 0.52931\n",
      "Epoch 231: | Train Loss: 0.14736 | Test Loss: 0.36572\n",
      "Epoch 232: | Train Loss: 0.15075 | Test Loss: 1.17724\n",
      "Epoch 233: | Train Loss: 0.30204 | Test Loss: 0.91515\n",
      "Epoch 234: | Train Loss: 0.29893 | Test Loss: 0.50525\n",
      "Epoch 235: | Train Loss: 0.23298 | Test Loss: 0.45214\n",
      "Epoch 236: | Train Loss: 0.22379 | Test Loss: 0.37273\n",
      "Epoch 237: | Train Loss: 0.17342 | Test Loss: 0.37287\n",
      "Epoch 238: | Train Loss: 0.16619 | Test Loss: 0.39693\n",
      "Epoch 239: | Train Loss: 0.17634 | Test Loss: 0.65139\n",
      "Epoch 240: | Train Loss: 0.33138 | Test Loss: 0.95399\n",
      "stats of l2reg of  0.0001 are [0.92615 0.90298 0.29351 0.51758]\n",
      "running reg of 0.0003\n",
      "initial run of high regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75b5031c598470da352ab046f887e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.64648 | Test Loss: 0.58279\n",
      "Epoch 002: | Train Loss: 0.60945 | Test Loss: 0.66607\n",
      "Epoch 003: | Train Loss: 0.65033 | Test Loss: 0.64496\n",
      "Epoch 004: | Train Loss: 0.63541 | Test Loss: 0.63475\n",
      "Epoch 005: | Train Loss: 0.62594 | Test Loss: 0.62789\n",
      "Epoch 006: | Train Loss: 0.62041 | Test Loss: 0.62386\n",
      "Epoch 007: | Train Loss: 0.61709 | Test Loss: 0.62185\n",
      "Epoch 008: | Train Loss: 0.61511 | Test Loss: 0.62040\n",
      "Epoch 009: | Train Loss: 0.61426 | Test Loss: 0.61944\n",
      "Epoch 010: | Train Loss: 0.61378 | Test Loss: 0.61918\n",
      "Epoch 011: | Train Loss: 0.61296 | Test Loss: 0.61925\n",
      "Epoch 012: | Train Loss: 0.61317 | Test Loss: 0.61923\n",
      "Epoch 013: | Train Loss: 0.61324 | Test Loss: 0.61903\n",
      "Epoch 014: | Train Loss: 0.61274 | Test Loss: 0.61922\n",
      "Epoch 015: | Train Loss: 0.61337 | Test Loss: 0.61919\n",
      "Epoch 016: | Train Loss: 0.61273 | Test Loss: 0.61925\n",
      "Epoch 017: | Train Loss: 0.61363 | Test Loss: 0.61959\n",
      "Epoch 018: | Train Loss: 0.61315 | Test Loss: 0.61929\n",
      "Epoch 019: | Train Loss: 0.61354 | Test Loss: 0.61930\n",
      "Epoch 020: | Train Loss: 0.61317 | Test Loss: 0.61901\n",
      "run with given regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a0eae28cee451293dd1d2cd03f69e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.60276 | Test Loss: 0.57462\n",
      "Epoch 002: | Train Loss: 0.58723 | Test Loss: 0.44296\n",
      "Epoch 003: | Train Loss: 0.51678 | Test Loss: 0.66327\n",
      "Epoch 004: | Train Loss: 0.41692 | Test Loss: 0.30122\n",
      "Epoch 005: | Train Loss: 0.35464 | Test Loss: 0.32965\n",
      "Epoch 006: | Train Loss: 0.31829 | Test Loss: 0.34194\n",
      "Epoch 007: | Train Loss: 0.28100 | Test Loss: 0.51536\n",
      "Epoch 008: | Train Loss: 0.32429 | Test Loss: 0.63971\n",
      "Epoch 009: | Train Loss: 0.32170 | Test Loss: 0.32966\n",
      "Epoch 010: | Train Loss: 0.26913 | Test Loss: 0.34195\n",
      "Epoch 011: | Train Loss: 0.29869 | Test Loss: 0.34673\n",
      "Epoch 012: | Train Loss: 0.26859 | Test Loss: 0.40633\n",
      "Epoch 013: | Train Loss: 0.26647 | Test Loss: 0.36107\n",
      "Epoch 014: | Train Loss: 0.28792 | Test Loss: 0.34767\n",
      "Epoch 015: | Train Loss: 0.29810 | Test Loss: 0.32605\n",
      "Epoch 016: | Train Loss: 0.26816 | Test Loss: 0.40095\n",
      "Epoch 017: | Train Loss: 0.26580 | Test Loss: 0.36452\n",
      "Epoch 018: | Train Loss: 0.25185 | Test Loss: 0.50370\n",
      "Epoch 019: | Train Loss: 0.26067 | Test Loss: 0.42591\n",
      "Epoch 020: | Train Loss: 0.29902 | Test Loss: 0.43934\n",
      "Epoch 021: | Train Loss: 0.26586 | Test Loss: 0.39455\n",
      "Epoch 022: | Train Loss: 0.25405 | Test Loss: 0.39952\n",
      "Epoch 023: | Train Loss: 0.26513 | Test Loss: 0.37217\n",
      "Epoch 024: | Train Loss: 0.24570 | Test Loss: 0.43111\n",
      "Epoch 025: | Train Loss: 0.24785 | Test Loss: 0.30762\n",
      "Epoch 026: | Train Loss: 0.23278 | Test Loss: 0.36913\n",
      "Epoch 027: | Train Loss: 0.24029 | Test Loss: 0.39195\n",
      "Epoch 028: | Train Loss: 0.24684 | Test Loss: 0.37013\n",
      "Epoch 029: | Train Loss: 0.23516 | Test Loss: 0.52186\n",
      "Epoch 030: | Train Loss: 0.28493 | Test Loss: 0.52421\n",
      "Epoch 031: | Train Loss: 0.27365 | Test Loss: 0.47535\n",
      "Epoch 032: | Train Loss: 0.26051 | Test Loss: 0.43653\n",
      "Epoch 033: | Train Loss: 0.23216 | Test Loss: 0.49690\n",
      "Epoch 034: | Train Loss: 0.23207 | Test Loss: 0.47370\n",
      "Epoch 035: | Train Loss: 0.25179 | Test Loss: 0.45328\n",
      "Epoch 036: | Train Loss: 0.26257 | Test Loss: 0.37684\n",
      "Epoch 037: | Train Loss: 0.25807 | Test Loss: 0.38523\n",
      "Epoch 038: | Train Loss: 0.25173 | Test Loss: 0.43722\n",
      "Epoch 039: | Train Loss: 0.22001 | Test Loss: 0.49948\n",
      "Epoch 040: | Train Loss: 0.22206 | Test Loss: 0.36134\n",
      "Epoch 041: | Train Loss: 0.22775 | Test Loss: 0.40365\n",
      "Epoch 042: | Train Loss: 0.22484 | Test Loss: 0.52860\n",
      "Epoch 043: | Train Loss: 0.22081 | Test Loss: 0.53868\n",
      "Epoch 044: | Train Loss: 0.22649 | Test Loss: 0.55957\n",
      "Epoch 045: | Train Loss: 0.22542 | Test Loss: 0.57084\n",
      "Epoch 046: | Train Loss: 0.21683 | Test Loss: 0.38761\n",
      "Epoch 047: | Train Loss: 0.21051 | Test Loss: 0.45661\n",
      "Epoch 048: | Train Loss: 0.23050 | Test Loss: 0.47994\n",
      "Epoch 049: | Train Loss: 0.25356 | Test Loss: 0.40871\n",
      "Epoch 050: | Train Loss: 0.21570 | Test Loss: 0.42809\n",
      "Epoch 051: | Train Loss: 0.31815 | Test Loss: 0.47385\n",
      "Epoch 052: | Train Loss: 0.24804 | Test Loss: 0.51941\n",
      "Epoch 053: | Train Loss: 0.23514 | Test Loss: 0.40653\n",
      "Epoch 054: | Train Loss: 0.21257 | Test Loss: 0.35748\n",
      "Epoch 055: | Train Loss: 0.18903 | Test Loss: 0.52080\n",
      "Epoch 056: | Train Loss: 0.20033 | Test Loss: 0.47941\n",
      "Epoch 057: | Train Loss: 0.20184 | Test Loss: 0.43201\n",
      "Epoch 058: | Train Loss: 0.20390 | Test Loss: 0.38346\n",
      "Epoch 059: | Train Loss: 0.23372 | Test Loss: 0.53071\n",
      "Epoch 060: | Train Loss: 0.19147 | Test Loss: 0.40169\n",
      "Epoch 061: | Train Loss: 0.18930 | Test Loss: 0.49543\n",
      "Epoch 062: | Train Loss: 0.20972 | Test Loss: 0.56900\n",
      "Epoch 063: | Train Loss: 0.22043 | Test Loss: 0.56178\n",
      "Epoch 064: | Train Loss: 0.25394 | Test Loss: 0.52022\n",
      "Epoch 065: | Train Loss: 0.28521 | Test Loss: 0.50732\n",
      "Epoch 066: | Train Loss: 0.20577 | Test Loss: 0.57083\n",
      "Epoch 067: | Train Loss: 0.23699 | Test Loss: 0.42014\n",
      "Epoch 068: | Train Loss: 0.22959 | Test Loss: 0.57427\n",
      "Epoch 069: | Train Loss: 0.22826 | Test Loss: 0.41581\n",
      "Epoch 070: | Train Loss: 0.22988 | Test Loss: 0.40674\n",
      "Epoch 071: | Train Loss: 0.22477 | Test Loss: 0.34309\n",
      "Epoch 072: | Train Loss: 0.26866 | Test Loss: 0.55030\n",
      "Epoch 073: | Train Loss: 0.19234 | Test Loss: 0.38880\n",
      "Epoch 074: | Train Loss: 0.19935 | Test Loss: 0.41124\n",
      "Epoch 075: | Train Loss: 0.22856 | Test Loss: 0.46459\n",
      "Epoch 076: | Train Loss: 0.20424 | Test Loss: 0.46767\n",
      "Epoch 077: | Train Loss: 0.22803 | Test Loss: 0.39435\n",
      "Epoch 078: | Train Loss: 0.19750 | Test Loss: 0.35781\n",
      "Epoch 079: | Train Loss: 0.17553 | Test Loss: 0.40946\n",
      "Epoch 080: | Train Loss: 0.19935 | Test Loss: 0.29659\n",
      "Epoch 081: | Train Loss: 0.19694 | Test Loss: 0.36760\n",
      "Epoch 082: | Train Loss: 0.19444 | Test Loss: 0.37057\n",
      "Epoch 083: | Train Loss: 0.20107 | Test Loss: 0.36426\n",
      "Epoch 084: | Train Loss: 0.19004 | Test Loss: 0.40032\n",
      "Epoch 085: | Train Loss: 0.20681 | Test Loss: 0.62089\n",
      "Epoch 086: | Train Loss: 0.19962 | Test Loss: 0.50197\n",
      "Epoch 087: | Train Loss: 0.22859 | Test Loss: 0.55417\n",
      "Epoch 088: | Train Loss: 0.21260 | Test Loss: 0.39203\n",
      "Epoch 089: | Train Loss: 0.18665 | Test Loss: 0.44483\n",
      "Epoch 090: | Train Loss: 0.20528 | Test Loss: 0.45392\n",
      "Epoch 091: | Train Loss: 0.18711 | Test Loss: 0.40629\n",
      "Epoch 092: | Train Loss: 0.22670 | Test Loss: 0.48537\n",
      "Epoch 093: | Train Loss: 0.29268 | Test Loss: 0.38998\n",
      "Epoch 094: | Train Loss: 0.34044 | Test Loss: 0.79953\n",
      "Epoch 095: | Train Loss: 0.40873 | Test Loss: 0.57697\n",
      "Epoch 096: | Train Loss: 0.37580 | Test Loss: 0.41460\n",
      "Epoch 097: | Train Loss: 0.35418 | Test Loss: 0.38889\n",
      "Epoch 098: | Train Loss: 0.28262 | Test Loss: 0.38030\n",
      "Epoch 099: | Train Loss: 0.26386 | Test Loss: 0.51553\n",
      "Epoch 100: | Train Loss: 0.25462 | Test Loss: 0.40841\n",
      "Epoch 101: | Train Loss: 0.30244 | Test Loss: 0.36972\n",
      "Epoch 102: | Train Loss: 0.27261 | Test Loss: 0.39819\n",
      "Epoch 103: | Train Loss: 0.29355 | Test Loss: 0.55096\n",
      "Epoch 104: | Train Loss: 0.35069 | Test Loss: 0.50540\n",
      "Epoch 105: | Train Loss: 0.29806 | Test Loss: 0.37826\n",
      "Epoch 106: | Train Loss: 0.35039 | Test Loss: 0.36736\n",
      "Epoch 107: | Train Loss: 0.33374 | Test Loss: 0.36543\n",
      "Epoch 108: | Train Loss: 0.25914 | Test Loss: 0.31492\n",
      "Epoch 109: | Train Loss: 0.28376 | Test Loss: 0.36366\n",
      "Epoch 110: | Train Loss: 0.27924 | Test Loss: 0.37975\n",
      "Epoch 111: | Train Loss: 0.25801 | Test Loss: 0.35761\n",
      "Epoch 112: | Train Loss: 0.27068 | Test Loss: 0.41277\n",
      "Epoch 113: | Train Loss: 0.25472 | Test Loss: 0.41730\n",
      "Epoch 114: | Train Loss: 0.24373 | Test Loss: 0.43642\n",
      "Epoch 115: | Train Loss: 0.38812 | Test Loss: 0.54020\n",
      "Epoch 116: | Train Loss: 0.28581 | Test Loss: 0.62107\n",
      "Epoch 117: | Train Loss: 0.29805 | Test Loss: 0.46577\n",
      "Epoch 118: | Train Loss: 0.26048 | Test Loss: 0.38854\n",
      "Epoch 119: | Train Loss: 0.24133 | Test Loss: 0.62392\n",
      "Epoch 120: | Train Loss: 0.25747 | Test Loss: 0.34962\n",
      "Epoch 121: | Train Loss: 0.23632 | Test Loss: 0.40443\n",
      "Epoch 122: | Train Loss: 0.22677 | Test Loss: 0.41125\n",
      "Epoch 123: | Train Loss: 0.23626 | Test Loss: 0.62828\n",
      "Epoch 124: | Train Loss: 0.29755 | Test Loss: 0.40872\n",
      "Epoch 125: | Train Loss: 0.25027 | Test Loss: 0.55750\n",
      "Epoch 126: | Train Loss: 0.28533 | Test Loss: 0.41676\n",
      "Epoch 127: | Train Loss: 0.24284 | Test Loss: 0.49423\n",
      "Epoch 128: | Train Loss: 0.40492 | Test Loss: 0.61465\n",
      "Epoch 129: | Train Loss: 0.39378 | Test Loss: 0.38545\n",
      "Epoch 130: | Train Loss: 0.30979 | Test Loss: 0.72109\n",
      "Epoch 131: | Train Loss: 0.33035 | Test Loss: 0.52695\n",
      "Epoch 132: | Train Loss: 0.29230 | Test Loss: 0.51424\n",
      "Epoch 133: | Train Loss: 0.32759 | Test Loss: 0.40268\n",
      "Epoch 134: | Train Loss: 0.24815 | Test Loss: 0.39254\n",
      "Epoch 135: | Train Loss: 0.23501 | Test Loss: 0.38648\n",
      "Epoch 136: | Train Loss: 0.36551 | Test Loss: 0.40599\n",
      "Epoch 137: | Train Loss: 0.31771 | Test Loss: 0.36080\n",
      "Epoch 138: | Train Loss: 0.55354 | Test Loss: 1.57077\n",
      "Epoch 139: | Train Loss: 0.67426 | Test Loss: 0.96532\n",
      "Epoch 140: | Train Loss: 0.50365 | Test Loss: 0.51981\n",
      "Epoch 141: | Train Loss: 0.34019 | Test Loss: 0.42642\n",
      "Epoch 142: | Train Loss: 0.25031 | Test Loss: 0.41835\n",
      "Epoch 143: | Train Loss: 0.33398 | Test Loss: 0.38244\n",
      "Epoch 144: | Train Loss: 0.28214 | Test Loss: 0.63137\n",
      "Epoch 145: | Train Loss: 0.33945 | Test Loss: 0.47809\n",
      "Epoch 146: | Train Loss: 0.30672 | Test Loss: 0.36932\n",
      "Epoch 147: | Train Loss: 0.35896 | Test Loss: 0.45984\n",
      "Epoch 148: | Train Loss: 0.29845 | Test Loss: 0.45242\n",
      "Epoch 149: | Train Loss: 0.32215 | Test Loss: 0.40445\n",
      "Epoch 150: | Train Loss: 0.46491 | Test Loss: 0.39476\n",
      "Epoch 151: | Train Loss: 0.36366 | Test Loss: 0.38627\n",
      "Epoch 152: | Train Loss: 0.28924 | Test Loss: 0.37055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: | Train Loss: 0.30840 | Test Loss: 0.65305\n",
      "Epoch 154: | Train Loss: 0.32474 | Test Loss: 0.38882\n",
      "Epoch 155: | Train Loss: 0.29593 | Test Loss: 0.34687\n",
      "Epoch 156: | Train Loss: 0.23813 | Test Loss: 0.50703\n",
      "Epoch 157: | Train Loss: 0.41305 | Test Loss: 0.63954\n",
      "Epoch 158: | Train Loss: 0.37674 | Test Loss: 0.40583\n",
      "Epoch 159: | Train Loss: 0.24139 | Test Loss: 0.33431\n",
      "Epoch 160: | Train Loss: 0.26443 | Test Loss: 0.54371\n",
      "Epoch 161: | Train Loss: 0.43151 | Test Loss: 0.45504\n",
      "Epoch 162: | Train Loss: 0.34820 | Test Loss: 0.46502\n",
      "Epoch 163: | Train Loss: 0.32431 | Test Loss: 0.94294\n",
      "Epoch 164: | Train Loss: 0.38663 | Test Loss: 0.62952\n",
      "Epoch 165: | Train Loss: 0.32972 | Test Loss: 0.39618\n",
      "Epoch 166: | Train Loss: 0.27988 | Test Loss: 0.40292\n",
      "Epoch 167: | Train Loss: 0.25374 | Test Loss: 0.35286\n",
      "Epoch 168: | Train Loss: 0.24252 | Test Loss: 0.49190\n",
      "Epoch 169: | Train Loss: 0.25997 | Test Loss: 0.35157\n",
      "Epoch 170: | Train Loss: 0.24856 | Test Loss: 0.44200\n",
      "Epoch 171: | Train Loss: 0.23809 | Test Loss: 0.44784\n",
      "Epoch 172: | Train Loss: 0.33220 | Test Loss: 0.37306\n",
      "Epoch 173: | Train Loss: 0.23215 | Test Loss: 0.34260\n",
      "Epoch 174: | Train Loss: 0.32228 | Test Loss: 0.39698\n",
      "Epoch 175: | Train Loss: 0.25475 | Test Loss: 0.50966\n",
      "Epoch 176: | Train Loss: 0.25220 | Test Loss: 0.37660\n",
      "Epoch 177: | Train Loss: 0.22663 | Test Loss: 0.38122\n",
      "Epoch 178: | Train Loss: 0.24372 | Test Loss: 0.48951\n",
      "Epoch 179: | Train Loss: 0.25736 | Test Loss: 0.38769\n",
      "Epoch 180: | Train Loss: 0.22959 | Test Loss: 0.37142\n",
      "Epoch 181: | Train Loss: 0.25632 | Test Loss: 0.55368\n",
      "Epoch 182: | Train Loss: 0.25628 | Test Loss: 0.87341\n",
      "Epoch 183: | Train Loss: 0.27884 | Test Loss: 0.41659\n",
      "Epoch 184: | Train Loss: 0.25930 | Test Loss: 0.56333\n",
      "Epoch 185: | Train Loss: 0.30013 | Test Loss: 0.47313\n",
      "Epoch 186: | Train Loss: 0.25458 | Test Loss: 0.37953\n",
      "Epoch 187: | Train Loss: 0.25347 | Test Loss: 0.44350\n",
      "Epoch 188: | Train Loss: 0.25009 | Test Loss: 0.37812\n",
      "Epoch 189: | Train Loss: 0.24206 | Test Loss: 0.56539\n",
      "Epoch 190: | Train Loss: 0.53460 | Test Loss: 0.57696\n",
      "Epoch 191: | Train Loss: 0.29776 | Test Loss: 0.52921\n",
      "Epoch 192: | Train Loss: 0.25256 | Test Loss: 0.43134\n",
      "Epoch 193: | Train Loss: 0.30859 | Test Loss: 0.56525\n",
      "Epoch 194: | Train Loss: 0.33283 | Test Loss: 0.54257\n",
      "Epoch 195: | Train Loss: 0.28049 | Test Loss: 0.31761\n",
      "Epoch 196: | Train Loss: 0.22346 | Test Loss: 0.34923\n",
      "Epoch 197: | Train Loss: 0.24013 | Test Loss: 0.36109\n",
      "Epoch 198: | Train Loss: 0.22200 | Test Loss: 0.34610\n",
      "Epoch 199: | Train Loss: 0.21203 | Test Loss: 0.35241\n",
      "Epoch 200: | Train Loss: 0.20368 | Test Loss: 0.41017\n",
      "Epoch 201: | Train Loss: 0.23562 | Test Loss: 0.33269\n",
      "Epoch 202: | Train Loss: 0.25702 | Test Loss: 0.43663\n",
      "Epoch 203: | Train Loss: 0.28696 | Test Loss: 0.35418\n",
      "Epoch 204: | Train Loss: 0.22844 | Test Loss: 0.35413\n",
      "Epoch 205: | Train Loss: 0.20646 | Test Loss: 0.34396\n",
      "Epoch 206: | Train Loss: 0.27681 | Test Loss: 0.80797\n",
      "Epoch 207: | Train Loss: 0.27264 | Test Loss: 0.37752\n",
      "Epoch 208: | Train Loss: 0.23489 | Test Loss: 0.39567\n",
      "Epoch 209: | Train Loss: 0.21976 | Test Loss: 0.37451\n",
      "Epoch 210: | Train Loss: 0.24753 | Test Loss: 0.37715\n",
      "Epoch 211: | Train Loss: 0.22031 | Test Loss: 0.52299\n",
      "Epoch 212: | Train Loss: 0.27495 | Test Loss: 0.37684\n",
      "Epoch 213: | Train Loss: 0.20970 | Test Loss: 0.35253\n",
      "Epoch 214: | Train Loss: 0.22267 | Test Loss: 0.49192\n",
      "Epoch 215: | Train Loss: 0.31739 | Test Loss: 0.65030\n",
      "Epoch 216: | Train Loss: 0.25928 | Test Loss: 0.35106\n",
      "Epoch 217: | Train Loss: 0.20388 | Test Loss: 0.40324\n",
      "Epoch 218: | Train Loss: 0.32346 | Test Loss: 0.39917\n",
      "Epoch 219: | Train Loss: 0.29808 | Test Loss: 0.38679\n",
      "Epoch 220: | Train Loss: 0.27406 | Test Loss: 0.39425\n",
      "Epoch 221: | Train Loss: 0.28391 | Test Loss: 0.36280\n",
      "Epoch 222: | Train Loss: 0.28222 | Test Loss: 0.38568\n",
      "Epoch 223: | Train Loss: 0.27063 | Test Loss: 0.37211\n",
      "Epoch 224: | Train Loss: 0.22430 | Test Loss: 0.56623\n",
      "Epoch 225: | Train Loss: 0.44620 | Test Loss: 0.77812\n",
      "Epoch 226: | Train Loss: 0.29486 | Test Loss: 0.57643\n",
      "Epoch 227: | Train Loss: 0.31591 | Test Loss: 0.40415\n",
      "Epoch 228: | Train Loss: 0.36268 | Test Loss: 0.63949\n",
      "Epoch 229: | Train Loss: 0.31225 | Test Loss: 0.38157\n",
      "Epoch 230: | Train Loss: 0.23724 | Test Loss: 0.36072\n",
      "Epoch 231: | Train Loss: 0.30013 | Test Loss: 0.33932\n",
      "Epoch 232: | Train Loss: 0.33663 | Test Loss: 0.40331\n",
      "Epoch 233: | Train Loss: 0.27867 | Test Loss: 0.31049\n",
      "Epoch 234: | Train Loss: 0.27374 | Test Loss: 0.34018\n",
      "Epoch 235: | Train Loss: 0.21414 | Test Loss: 0.31447\n",
      "Epoch 236: | Train Loss: 0.20403 | Test Loss: 0.32253\n",
      "Epoch 237: | Train Loss: 0.22214 | Test Loss: 0.35892\n",
      "Epoch 238: | Train Loss: 0.20644 | Test Loss: 0.36411\n",
      "Epoch 239: | Train Loss: 0.22422 | Test Loss: 0.38803\n",
      "Epoch 240: | Train Loss: 0.20951 | Test Loss: 0.35872\n",
      "stats of l2reg of  0.0003 are [0.95767 0.94281 0.18841 0.2756 ]\n",
      "running reg of 0.001\n",
      "initial run of high regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ab1bc87b0648459a92d911fa71c30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.70582 | Test Loss: 0.65438\n",
      "Epoch 002: | Train Loss: 0.62496 | Test Loss: 0.67662\n",
      "Epoch 003: | Train Loss: 0.59822 | Test Loss: 0.64158\n",
      "Epoch 004: | Train Loss: 0.57319 | Test Loss: 0.66557\n",
      "Epoch 005: | Train Loss: 0.58659 | Test Loss: 0.64160\n",
      "Epoch 006: | Train Loss: 0.56046 | Test Loss: 0.54602\n",
      "Epoch 007: | Train Loss: 0.53205 | Test Loss: 0.65980\n",
      "Epoch 008: | Train Loss: 0.55318 | Test Loss: 0.53929\n",
      "Epoch 009: | Train Loss: 0.54036 | Test Loss: 0.64680\n",
      "Epoch 010: | Train Loss: 0.60823 | Test Loss: 0.57453\n",
      "Epoch 011: | Train Loss: 0.55397 | Test Loss: 0.68145\n",
      "Epoch 012: | Train Loss: 0.54318 | Test Loss: 0.55481\n",
      "Epoch 013: | Train Loss: 0.56255 | Test Loss: 0.63882\n",
      "Epoch 014: | Train Loss: 0.54973 | Test Loss: 0.53522\n",
      "Epoch 015: | Train Loss: 0.56357 | Test Loss: 0.56439\n",
      "Epoch 016: | Train Loss: 0.53561 | Test Loss: 0.54802\n",
      "Epoch 017: | Train Loss: 0.56487 | Test Loss: 0.57388\n",
      "Epoch 018: | Train Loss: 0.56176 | Test Loss: 0.63950\n",
      "Epoch 019: | Train Loss: 0.62650 | Test Loss: 0.62671\n",
      "Epoch 020: | Train Loss: 0.61864 | Test Loss: 0.62196\n",
      "run with given regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec3d605f545447194acba890aad78c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.56214 | Test Loss: 0.45836\n",
      "Epoch 002: | Train Loss: 0.53057 | Test Loss: 0.44929\n",
      "Epoch 003: | Train Loss: 0.51779 | Test Loss: 0.44820\n",
      "Epoch 004: | Train Loss: 0.44238 | Test Loss: 0.44342\n",
      "Epoch 005: | Train Loss: 0.42102 | Test Loss: 0.34113\n",
      "Epoch 006: | Train Loss: 0.35557 | Test Loss: 0.44026\n",
      "Epoch 007: | Train Loss: 0.33099 | Test Loss: 0.39964\n",
      "Epoch 008: | Train Loss: 0.32617 | Test Loss: 0.37278\n",
      "Epoch 009: | Train Loss: 0.35935 | Test Loss: 0.41970\n",
      "Epoch 010: | Train Loss: 0.30616 | Test Loss: 0.54483\n",
      "Epoch 011: | Train Loss: 0.34445 | Test Loss: 0.46682\n",
      "Epoch 012: | Train Loss: 0.28617 | Test Loss: 0.38182\n",
      "Epoch 013: | Train Loss: 0.26588 | Test Loss: 0.40946\n",
      "Epoch 014: | Train Loss: 0.28400 | Test Loss: 0.41990\n",
      "Epoch 015: | Train Loss: 0.25883 | Test Loss: 0.38505\n",
      "Epoch 016: | Train Loss: 0.25495 | Test Loss: 0.41793\n",
      "Epoch 017: | Train Loss: 0.29869 | Test Loss: 0.35347\n",
      "Epoch 018: | Train Loss: 0.24581 | Test Loss: 0.37166\n",
      "Epoch 019: | Train Loss: 0.23449 | Test Loss: 0.41511\n",
      "Epoch 020: | Train Loss: 0.23580 | Test Loss: 0.35406\n",
      "Epoch 021: | Train Loss: 0.24757 | Test Loss: 0.37616\n",
      "Epoch 022: | Train Loss: 0.22260 | Test Loss: 0.34108\n",
      "Epoch 023: | Train Loss: 0.22095 | Test Loss: 0.38821\n",
      "Epoch 024: | Train Loss: 0.23606 | Test Loss: 0.35657\n",
      "Epoch 025: | Train Loss: 0.22584 | Test Loss: 0.41352\n",
      "Epoch 026: | Train Loss: 0.24066 | Test Loss: 0.34314\n",
      "Epoch 027: | Train Loss: 0.21392 | Test Loss: 0.39580\n",
      "Epoch 028: | Train Loss: 0.21609 | Test Loss: 0.39364\n",
      "Epoch 029: | Train Loss: 0.19800 | Test Loss: 0.34976\n",
      "Epoch 030: | Train Loss: 0.22521 | Test Loss: 0.44569\n",
      "Epoch 031: | Train Loss: 0.20673 | Test Loss: 0.43483\n",
      "Epoch 032: | Train Loss: 0.21183 | Test Loss: 0.27705\n",
      "Epoch 033: | Train Loss: 0.24797 | Test Loss: 0.41613\n",
      "Epoch 034: | Train Loss: 0.19460 | Test Loss: 0.35855\n",
      "Epoch 035: | Train Loss: 0.20738 | Test Loss: 0.38019\n",
      "Epoch 036: | Train Loss: 0.22078 | Test Loss: 0.38024\n",
      "Epoch 037: | Train Loss: 0.19858 | Test Loss: 0.52241\n",
      "Epoch 038: | Train Loss: 0.20984 | Test Loss: 0.33532\n",
      "Epoch 039: | Train Loss: 0.19964 | Test Loss: 0.38441\n",
      "Epoch 040: | Train Loss: 0.20919 | Test Loss: 0.29285\n",
      "Epoch 041: | Train Loss: 0.19320 | Test Loss: 0.33482\n",
      "Epoch 042: | Train Loss: 0.19003 | Test Loss: 0.33012\n",
      "Epoch 043: | Train Loss: 0.20703 | Test Loss: 0.33757\n",
      "Epoch 044: | Train Loss: 0.18951 | Test Loss: 0.32846\n",
      "Epoch 045: | Train Loss: 0.20167 | Test Loss: 0.32948\n",
      "Epoch 046: | Train Loss: 0.20089 | Test Loss: 0.39155\n",
      "Epoch 047: | Train Loss: 0.18949 | Test Loss: 0.32000\n",
      "Epoch 048: | Train Loss: 0.23505 | Test Loss: 0.32427\n",
      "Epoch 049: | Train Loss: 0.20112 | Test Loss: 0.33533\n",
      "Epoch 050: | Train Loss: 0.20366 | Test Loss: 0.40839\n",
      "Epoch 051: | Train Loss: 0.20524 | Test Loss: 0.45985\n",
      "Epoch 052: | Train Loss: 0.19327 | Test Loss: 0.32910\n",
      "Epoch 053: | Train Loss: 0.18414 | Test Loss: 0.34991\n",
      "Epoch 054: | Train Loss: 0.17408 | Test Loss: 0.32300\n",
      "Epoch 055: | Train Loss: 0.18060 | Test Loss: 0.35334\n",
      "Epoch 056: | Train Loss: 0.20182 | Test Loss: 0.32139\n",
      "Epoch 057: | Train Loss: 0.19046 | Test Loss: 0.34155\n",
      "Epoch 058: | Train Loss: 0.21238 | Test Loss: 0.34129\n",
      "Epoch 059: | Train Loss: 0.17424 | Test Loss: 0.34198\n",
      "Epoch 060: | Train Loss: 0.17791 | Test Loss: 0.47462\n",
      "Epoch 061: | Train Loss: 0.21587 | Test Loss: 0.37187\n",
      "Epoch 062: | Train Loss: 0.21280 | Test Loss: 0.38491\n",
      "Epoch 063: | Train Loss: 0.20968 | Test Loss: 0.44326\n",
      "Epoch 064: | Train Loss: 0.20603 | Test Loss: 0.32418\n",
      "Epoch 065: | Train Loss: 0.20188 | Test Loss: 0.37833\n",
      "Epoch 066: | Train Loss: 0.19318 | Test Loss: 0.36318\n",
      "Epoch 067: | Train Loss: 0.18731 | Test Loss: 0.36821\n",
      "Epoch 068: | Train Loss: 0.18008 | Test Loss: 0.40071\n",
      "Epoch 069: | Train Loss: 0.18213 | Test Loss: 0.49110\n",
      "Epoch 070: | Train Loss: 0.18665 | Test Loss: 0.47385\n",
      "Epoch 071: | Train Loss: 0.19091 | Test Loss: 0.42825\n",
      "Epoch 072: | Train Loss: 0.23579 | Test Loss: 0.32906\n",
      "Epoch 073: | Train Loss: 0.17702 | Test Loss: 0.33405\n",
      "Epoch 074: | Train Loss: 0.18308 | Test Loss: 0.40111\n",
      "Epoch 075: | Train Loss: 0.18984 | Test Loss: 0.45298\n",
      "Epoch 076: | Train Loss: 0.18990 | Test Loss: 0.35623\n",
      "Epoch 077: | Train Loss: 0.20667 | Test Loss: 0.75553\n",
      "Epoch 078: | Train Loss: 0.24712 | Test Loss: 0.39402\n",
      "Epoch 079: | Train Loss: 0.19488 | Test Loss: 0.33978\n",
      "Epoch 080: | Train Loss: 0.21931 | Test Loss: 0.39604\n",
      "Epoch 081: | Train Loss: 0.21290 | Test Loss: 0.40489\n",
      "Epoch 082: | Train Loss: 0.21716 | Test Loss: 0.38711\n",
      "Epoch 083: | Train Loss: 0.22955 | Test Loss: 0.42841\n",
      "Epoch 084: | Train Loss: 0.19828 | Test Loss: 0.35600\n",
      "Epoch 085: | Train Loss: 0.16467 | Test Loss: 0.35943\n",
      "Epoch 086: | Train Loss: 0.19068 | Test Loss: 0.45941\n",
      "Epoch 087: | Train Loss: 0.19963 | Test Loss: 0.37966\n",
      "Epoch 088: | Train Loss: 0.17377 | Test Loss: 0.37138\n",
      "Epoch 089: | Train Loss: 0.17469 | Test Loss: 0.43502\n",
      "Epoch 090: | Train Loss: 0.16836 | Test Loss: 0.43723\n",
      "Epoch 091: | Train Loss: 0.18698 | Test Loss: 0.32128\n",
      "Epoch 092: | Train Loss: 0.19574 | Test Loss: 0.35632\n",
      "Epoch 093: | Train Loss: 0.19508 | Test Loss: 0.37323\n",
      "Epoch 094: | Train Loss: 0.18353 | Test Loss: 0.30529\n",
      "Epoch 095: | Train Loss: 0.19273 | Test Loss: 0.50171\n",
      "Epoch 096: | Train Loss: 0.16794 | Test Loss: 0.33355\n",
      "Epoch 097: | Train Loss: 0.18040 | Test Loss: 0.35775\n",
      "Epoch 098: | Train Loss: 0.18457 | Test Loss: 0.35504\n",
      "Epoch 099: | Train Loss: 0.18242 | Test Loss: 0.39454\n",
      "Epoch 100: | Train Loss: 0.16439 | Test Loss: 0.33582\n",
      "Epoch 101: | Train Loss: 0.16776 | Test Loss: 0.47774\n",
      "Epoch 102: | Train Loss: 0.17242 | Test Loss: 0.51702\n",
      "Epoch 103: | Train Loss: 0.17259 | Test Loss: 0.47010\n",
      "Epoch 104: | Train Loss: 0.19825 | Test Loss: 0.30695\n",
      "Epoch 105: | Train Loss: 0.19335 | Test Loss: 0.40121\n",
      "Epoch 106: | Train Loss: 0.18965 | Test Loss: 0.40120\n",
      "Epoch 107: | Train Loss: 0.18812 | Test Loss: 0.36194\n",
      "Epoch 108: | Train Loss: 0.16517 | Test Loss: 0.35050\n",
      "Epoch 109: | Train Loss: 0.16420 | Test Loss: 0.37264\n",
      "Epoch 110: | Train Loss: 0.19345 | Test Loss: 0.47028\n",
      "Epoch 111: | Train Loss: 0.18884 | Test Loss: 0.76214\n",
      "Epoch 112: | Train Loss: 0.17486 | Test Loss: 0.44736\n",
      "Epoch 113: | Train Loss: 0.16777 | Test Loss: 0.43220\n",
      "Epoch 114: | Train Loss: 0.20708 | Test Loss: 0.48252\n",
      "Epoch 115: | Train Loss: 0.19569 | Test Loss: 0.38829\n",
      "Epoch 116: | Train Loss: 0.18201 | Test Loss: 0.35594\n",
      "Epoch 117: | Train Loss: 0.16623 | Test Loss: 0.42471\n",
      "Epoch 118: | Train Loss: 0.20298 | Test Loss: 0.43681\n",
      "Epoch 119: | Train Loss: 0.20371 | Test Loss: 0.43354\n",
      "Epoch 120: | Train Loss: 0.16621 | Test Loss: 0.37653\n",
      "Epoch 121: | Train Loss: 0.18864 | Test Loss: 0.40071\n",
      "Epoch 122: | Train Loss: 0.17559 | Test Loss: 0.51019\n",
      "Epoch 123: | Train Loss: 0.21347 | Test Loss: 0.41307\n",
      "Epoch 124: | Train Loss: 0.17265 | Test Loss: 0.41793\n",
      "Epoch 125: | Train Loss: 0.20963 | Test Loss: 0.34585\n",
      "Epoch 126: | Train Loss: 0.16641 | Test Loss: 0.40020\n",
      "Epoch 127: | Train Loss: 0.22077 | Test Loss: 0.33374\n",
      "Epoch 128: | Train Loss: 0.17363 | Test Loss: 0.43198\n",
      "Epoch 129: | Train Loss: 0.21799 | Test Loss: 0.42540\n",
      "Epoch 130: | Train Loss: 0.17546 | Test Loss: 0.36406\n",
      "Epoch 131: | Train Loss: 0.17107 | Test Loss: 0.31939\n",
      "Epoch 132: | Train Loss: 0.16547 | Test Loss: 0.41656\n",
      "Epoch 133: | Train Loss: 0.27356 | Test Loss: 0.33142\n",
      "Epoch 134: | Train Loss: 0.18968 | Test Loss: 0.40821\n",
      "Epoch 135: | Train Loss: 0.18837 | Test Loss: 0.27231\n",
      "Epoch 136: | Train Loss: 0.17544 | Test Loss: 0.39446\n",
      "Epoch 137: | Train Loss: 0.19839 | Test Loss: 0.34955\n",
      "Epoch 138: | Train Loss: 0.15656 | Test Loss: 0.36279\n",
      "Epoch 139: | Train Loss: 0.16478 | Test Loss: 0.39441\n",
      "Epoch 140: | Train Loss: 0.18207 | Test Loss: 0.37216\n",
      "Epoch 141: | Train Loss: 0.17870 | Test Loss: 0.36627\n",
      "Epoch 142: | Train Loss: 0.16173 | Test Loss: 0.35031\n",
      "Epoch 143: | Train Loss: 0.16138 | Test Loss: 0.42944\n",
      "Epoch 144: | Train Loss: 0.19117 | Test Loss: 0.57883\n",
      "Epoch 145: | Train Loss: 0.19383 | Test Loss: 0.45381\n",
      "Epoch 146: | Train Loss: 0.19489 | Test Loss: 0.36539\n",
      "Epoch 147: | Train Loss: 0.16169 | Test Loss: 0.37630\n",
      "Epoch 148: | Train Loss: 0.18362 | Test Loss: 0.32090\n",
      "Epoch 149: | Train Loss: 0.16674 | Test Loss: 0.35157\n",
      "Epoch 150: | Train Loss: 0.17232 | Test Loss: 0.33009\n",
      "Epoch 151: | Train Loss: 0.17606 | Test Loss: 0.35886\n",
      "Epoch 152: | Train Loss: 0.16502 | Test Loss: 0.33443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: | Train Loss: 0.17879 | Test Loss: 0.33033\n",
      "Epoch 154: | Train Loss: 0.15809 | Test Loss: 0.35850\n",
      "Epoch 155: | Train Loss: 0.16678 | Test Loss: 0.37742\n",
      "Epoch 156: | Train Loss: 0.16904 | Test Loss: 0.31367\n",
      "Epoch 157: | Train Loss: 0.16476 | Test Loss: 0.34600\n",
      "Epoch 158: | Train Loss: 0.16716 | Test Loss: 0.33026\n",
      "Epoch 159: | Train Loss: 0.17284 | Test Loss: 0.40984\n",
      "Epoch 160: | Train Loss: 0.17095 | Test Loss: 0.39119\n",
      "Epoch 161: | Train Loss: 0.17082 | Test Loss: 0.35139\n",
      "Epoch 162: | Train Loss: 0.16381 | Test Loss: 0.51473\n",
      "Epoch 163: | Train Loss: 0.16299 | Test Loss: 0.34899\n",
      "Epoch 164: | Train Loss: 0.17533 | Test Loss: 0.33931\n",
      "Epoch 165: | Train Loss: 0.16982 | Test Loss: 0.63228\n",
      "Epoch 166: | Train Loss: 0.16544 | Test Loss: 0.34636\n",
      "Epoch 167: | Train Loss: 0.17876 | Test Loss: 0.32155\n",
      "Epoch 168: | Train Loss: 0.17556 | Test Loss: 0.45454\n",
      "Epoch 169: | Train Loss: 0.17709 | Test Loss: 0.32655\n",
      "Epoch 170: | Train Loss: 0.16591 | Test Loss: 0.32213\n",
      "Epoch 171: | Train Loss: 0.18632 | Test Loss: 0.33269\n",
      "Epoch 172: | Train Loss: 0.17071 | Test Loss: 0.38760\n",
      "Epoch 173: | Train Loss: 0.19507 | Test Loss: 0.50624\n",
      "Epoch 174: | Train Loss: 0.22414 | Test Loss: 0.46789\n",
      "Epoch 175: | Train Loss: 0.19537 | Test Loss: 0.43155\n",
      "Epoch 176: | Train Loss: 0.20681 | Test Loss: 0.52969\n",
      "Epoch 177: | Train Loss: 0.20156 | Test Loss: 0.34747\n",
      "Epoch 178: | Train Loss: 0.17302 | Test Loss: 0.35954\n",
      "Epoch 179: | Train Loss: 0.16786 | Test Loss: 0.33601\n",
      "Epoch 180: | Train Loss: 0.17005 | Test Loss: 0.50015\n",
      "Epoch 181: | Train Loss: 0.16859 | Test Loss: 0.34061\n",
      "Epoch 182: | Train Loss: 0.18323 | Test Loss: 0.34433\n",
      "Epoch 183: | Train Loss: 0.16755 | Test Loss: 0.35155\n",
      "Epoch 184: | Train Loss: 0.17489 | Test Loss: 0.31433\n",
      "Epoch 185: | Train Loss: 0.16753 | Test Loss: 0.36736\n",
      "Epoch 186: | Train Loss: 0.17405 | Test Loss: 0.34813\n",
      "Epoch 187: | Train Loss: 0.23269 | Test Loss: 0.37894\n",
      "Epoch 188: | Train Loss: 0.19695 | Test Loss: 0.39201\n",
      "Epoch 189: | Train Loss: 0.18470 | Test Loss: 0.55229\n",
      "Epoch 190: | Train Loss: 0.19272 | Test Loss: 0.35947\n",
      "Epoch 191: | Train Loss: 0.22413 | Test Loss: 0.38115\n",
      "Epoch 192: | Train Loss: 0.19494 | Test Loss: 0.32122\n",
      "Epoch 193: | Train Loss: 0.16535 | Test Loss: 0.31209\n",
      "Epoch 194: | Train Loss: 0.18266 | Test Loss: 0.31859\n",
      "Epoch 195: | Train Loss: 0.18673 | Test Loss: 0.31833\n",
      "Epoch 196: | Train Loss: 0.17276 | Test Loss: 0.33355\n",
      "Epoch 197: | Train Loss: 0.15743 | Test Loss: 0.35741\n",
      "Epoch 198: | Train Loss: 0.16201 | Test Loss: 0.31707\n",
      "Epoch 199: | Train Loss: 0.16386 | Test Loss: 0.36621\n",
      "Epoch 200: | Train Loss: 0.17606 | Test Loss: 0.34312\n",
      "Epoch 201: | Train Loss: 0.16651 | Test Loss: 0.51703\n",
      "Epoch 202: | Train Loss: 0.36143 | Test Loss: 0.43765\n",
      "Epoch 203: | Train Loss: 0.17921 | Test Loss: 0.31396\n",
      "Epoch 204: | Train Loss: 0.16539 | Test Loss: 0.38402\n",
      "Epoch 205: | Train Loss: 0.20287 | Test Loss: 0.55232\n",
      "Epoch 206: | Train Loss: 0.32993 | Test Loss: 0.35618\n",
      "Epoch 207: | Train Loss: 0.21175 | Test Loss: 0.33197\n",
      "Epoch 208: | Train Loss: 0.18420 | Test Loss: 0.38612\n",
      "Epoch 209: | Train Loss: 0.19003 | Test Loss: 0.37558\n",
      "Epoch 210: | Train Loss: 0.19881 | Test Loss: 0.37348\n",
      "Epoch 211: | Train Loss: 0.16708 | Test Loss: 0.34930\n",
      "Epoch 212: | Train Loss: 0.15663 | Test Loss: 0.37802\n",
      "Epoch 213: | Train Loss: 0.17978 | Test Loss: 0.38841\n",
      "Epoch 214: | Train Loss: 0.23083 | Test Loss: 0.40438\n",
      "Epoch 215: | Train Loss: 0.22577 | Test Loss: 0.38090\n",
      "Epoch 216: | Train Loss: 0.17496 | Test Loss: 0.41409\n",
      "Epoch 217: | Train Loss: 0.19677 | Test Loss: 0.49438\n",
      "Epoch 218: | Train Loss: 0.22448 | Test Loss: 0.35523\n",
      "Epoch 219: | Train Loss: 0.16669 | Test Loss: 0.36305\n",
      "Epoch 220: | Train Loss: 0.22633 | Test Loss: 0.37629\n",
      "Epoch 221: | Train Loss: 0.18452 | Test Loss: 0.38848\n",
      "Epoch 222: | Train Loss: 0.22341 | Test Loss: 0.55898\n",
      "Epoch 223: | Train Loss: 0.27262 | Test Loss: 0.81495\n",
      "Epoch 224: | Train Loss: 0.19997 | Test Loss: 0.35640\n",
      "Epoch 225: | Train Loss: 0.18550 | Test Loss: 0.34413\n",
      "Epoch 226: | Train Loss: 0.17433 | Test Loss: 0.46528\n",
      "Epoch 227: | Train Loss: 0.30679 | Test Loss: 0.38104\n",
      "Epoch 228: | Train Loss: 0.28287 | Test Loss: 0.33726\n",
      "Epoch 229: | Train Loss: 0.18125 | Test Loss: 0.35081\n",
      "Epoch 230: | Train Loss: 0.19409 | Test Loss: 0.34780\n",
      "Epoch 231: | Train Loss: 0.18369 | Test Loss: 0.34062\n",
      "Epoch 232: | Train Loss: 0.17241 | Test Loss: 0.40137\n",
      "Epoch 233: | Train Loss: 0.20652 | Test Loss: 0.31780\n",
      "Epoch 234: | Train Loss: 0.17231 | Test Loss: 0.35711\n",
      "Epoch 235: | Train Loss: 0.17851 | Test Loss: 0.31664\n",
      "Epoch 236: | Train Loss: 0.20535 | Test Loss: 0.31699\n",
      "Epoch 237: | Train Loss: 0.16214 | Test Loss: 0.37922\n",
      "Epoch 238: | Train Loss: 0.18234 | Test Loss: 0.36221\n",
      "Epoch 239: | Train Loss: 0.24446 | Test Loss: 0.46249\n",
      "Epoch 240: | Train Loss: 0.52826 | Test Loss: 0.80383\n",
      "stats of l2reg of  0.001 are [0.95167 0.93106 0.38223 0.53368]\n",
      "running reg of 0.003\n",
      "initial run of high regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07464853e43542838bb65627e0f3d976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.61797 | Test Loss: 0.74468\n",
      "Epoch 002: | Train Loss: 0.64165 | Test Loss: 0.63954\n",
      "Epoch 003: | Train Loss: 0.59119 | Test Loss: 0.66584\n",
      "Epoch 004: | Train Loss: 0.58325 | Test Loss: 0.56883\n",
      "Epoch 005: | Train Loss: 0.59638 | Test Loss: 0.56505\n",
      "Epoch 006: | Train Loss: 0.57620 | Test Loss: 0.55724\n",
      "Epoch 007: | Train Loss: 0.53420 | Test Loss: 0.62740\n",
      "Epoch 008: | Train Loss: 0.56271 | Test Loss: 0.53450\n",
      "Epoch 009: | Train Loss: 0.53595 | Test Loss: 0.56281\n",
      "Epoch 010: | Train Loss: 0.53126 | Test Loss: 0.55886\n",
      "Epoch 011: | Train Loss: 0.53130 | Test Loss: 0.52149\n",
      "Epoch 012: | Train Loss: 0.53554 | Test Loss: 0.63037\n",
      "Epoch 013: | Train Loss: 0.55681 | Test Loss: 0.64326\n",
      "Epoch 014: | Train Loss: 0.62809 | Test Loss: 0.62720\n",
      "Epoch 015: | Train Loss: 0.61873 | Test Loss: 0.62244\n",
      "Epoch 016: | Train Loss: 0.61545 | Test Loss: 0.62056\n",
      "Epoch 017: | Train Loss: 0.61414 | Test Loss: 0.61999\n",
      "Epoch 018: | Train Loss: 0.61365 | Test Loss: 0.61963\n",
      "Epoch 019: | Train Loss: 0.61301 | Test Loss: 0.61945\n",
      "Epoch 020: | Train Loss: 0.61348 | Test Loss: 0.61919\n",
      "run with given regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb7fe8ee28642d38969d51bf406d6db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.61782 | Test Loss: 0.60532\n",
      "Epoch 002: | Train Loss: 0.58930 | Test Loss: 0.58886\n",
      "Epoch 003: | Train Loss: 0.55255 | Test Loss: 0.50977\n",
      "Epoch 004: | Train Loss: 0.49511 | Test Loss: 0.49379\n",
      "Epoch 005: | Train Loss: 0.43882 | Test Loss: 0.57305\n",
      "Epoch 006: | Train Loss: 0.44934 | Test Loss: 0.44760\n",
      "Epoch 007: | Train Loss: 0.40381 | Test Loss: 0.36518\n",
      "Epoch 008: | Train Loss: 0.36284 | Test Loss: 0.35183\n",
      "Epoch 009: | Train Loss: 0.32766 | Test Loss: 0.45012\n",
      "Epoch 010: | Train Loss: 0.31479 | Test Loss: 0.32795\n",
      "Epoch 011: | Train Loss: 0.29666 | Test Loss: 0.33415\n",
      "Epoch 012: | Train Loss: 0.35754 | Test Loss: 0.33865\n",
      "Epoch 013: | Train Loss: 0.33340 | Test Loss: 0.35409\n",
      "Epoch 014: | Train Loss: 0.25715 | Test Loss: 0.31067\n",
      "Epoch 015: | Train Loss: 0.28250 | Test Loss: 0.37636\n",
      "Epoch 016: | Train Loss: 0.29919 | Test Loss: 0.38393\n",
      "Epoch 017: | Train Loss: 0.23563 | Test Loss: 0.36652\n",
      "Epoch 018: | Train Loss: 0.28240 | Test Loss: 0.36635\n",
      "Epoch 019: | Train Loss: 0.29432 | Test Loss: 0.32315\n",
      "Epoch 020: | Train Loss: 0.30704 | Test Loss: 0.31427\n",
      "Epoch 021: | Train Loss: 0.24476 | Test Loss: 0.32164\n",
      "Epoch 022: | Train Loss: 0.26443 | Test Loss: 0.28341\n",
      "Epoch 023: | Train Loss: 0.24403 | Test Loss: 0.37012\n",
      "Epoch 024: | Train Loss: 0.23315 | Test Loss: 0.39010\n",
      "Epoch 025: | Train Loss: 0.23987 | Test Loss: 0.37058\n",
      "Epoch 026: | Train Loss: 0.21878 | Test Loss: 0.34701\n",
      "Epoch 027: | Train Loss: 0.22242 | Test Loss: 0.36253\n",
      "Epoch 028: | Train Loss: 0.22888 | Test Loss: 0.39400\n",
      "Epoch 029: | Train Loss: 0.21536 | Test Loss: 0.37716\n",
      "Epoch 030: | Train Loss: 0.23503 | Test Loss: 0.35051\n",
      "Epoch 031: | Train Loss: 0.22395 | Test Loss: 0.38091\n",
      "Epoch 032: | Train Loss: 0.26075 | Test Loss: 0.31383\n",
      "Epoch 033: | Train Loss: 0.20286 | Test Loss: 0.31972\n",
      "Epoch 034: | Train Loss: 0.26856 | Test Loss: 0.40124\n",
      "Epoch 035: | Train Loss: 0.27713 | Test Loss: 0.27241\n",
      "Epoch 036: | Train Loss: 0.24417 | Test Loss: 0.30918\n",
      "Epoch 037: | Train Loss: 0.22863 | Test Loss: 0.28605\n",
      "Epoch 038: | Train Loss: 0.21502 | Test Loss: 0.35529\n",
      "Epoch 039: | Train Loss: 0.20590 | Test Loss: 0.32780\n",
      "Epoch 040: | Train Loss: 0.24718 | Test Loss: 0.32795\n",
      "Epoch 041: | Train Loss: 0.20340 | Test Loss: 0.34452\n",
      "Epoch 042: | Train Loss: 0.23455 | Test Loss: 0.34518\n",
      "Epoch 043: | Train Loss: 0.19872 | Test Loss: 0.39782\n",
      "Epoch 044: | Train Loss: 0.19059 | Test Loss: 0.32869\n",
      "Epoch 045: | Train Loss: 0.24010 | Test Loss: 0.24542\n",
      "Epoch 046: | Train Loss: 0.19196 | Test Loss: 0.39351\n",
      "Epoch 047: | Train Loss: 0.22597 | Test Loss: 0.48335\n",
      "Epoch 048: | Train Loss: 0.21813 | Test Loss: 0.29308\n",
      "Epoch 049: | Train Loss: 0.21377 | Test Loss: 0.33365\n",
      "Epoch 050: | Train Loss: 0.20662 | Test Loss: 0.38316\n",
      "Epoch 051: | Train Loss: 0.28278 | Test Loss: 0.32368\n",
      "Epoch 052: | Train Loss: 0.23487 | Test Loss: 0.35129\n",
      "Epoch 053: | Train Loss: 0.19474 | Test Loss: 0.32183\n",
      "Epoch 054: | Train Loss: 0.18596 | Test Loss: 0.34967\n",
      "Epoch 055: | Train Loss: 0.20670 | Test Loss: 0.26078\n",
      "Epoch 056: | Train Loss: 0.20646 | Test Loss: 0.33614\n",
      "Epoch 057: | Train Loss: 0.23530 | Test Loss: 0.29111\n",
      "Epoch 058: | Train Loss: 0.21232 | Test Loss: 0.57856\n",
      "Epoch 059: | Train Loss: 0.19612 | Test Loss: 0.30277\n",
      "Epoch 060: | Train Loss: 0.21533 | Test Loss: 0.23890\n",
      "Epoch 061: | Train Loss: 0.23850 | Test Loss: 0.42662\n",
      "Epoch 062: | Train Loss: 0.20153 | Test Loss: 0.26260\n",
      "Epoch 063: | Train Loss: 0.62365 | Test Loss: 0.63696\n",
      "Epoch 064: | Train Loss: 0.48151 | Test Loss: 0.40497\n",
      "Epoch 065: | Train Loss: 0.33742 | Test Loss: 0.51421\n",
      "Epoch 066: | Train Loss: 0.35002 | Test Loss: 0.39319\n",
      "Epoch 067: | Train Loss: 0.30739 | Test Loss: 0.37994\n",
      "Epoch 068: | Train Loss: 0.32359 | Test Loss: 0.60606\n",
      "Epoch 069: | Train Loss: 0.36272 | Test Loss: 0.51323\n",
      "Epoch 070: | Train Loss: 0.33550 | Test Loss: 0.55561\n",
      "Epoch 071: | Train Loss: 0.29409 | Test Loss: 0.40156\n",
      "Epoch 072: | Train Loss: 0.23313 | Test Loss: 0.36802\n",
      "Epoch 073: | Train Loss: 0.24682 | Test Loss: 0.35626\n",
      "Epoch 074: | Train Loss: 0.21589 | Test Loss: 0.44482\n",
      "Epoch 075: | Train Loss: 0.26659 | Test Loss: 0.41794\n",
      "Epoch 076: | Train Loss: 0.27235 | Test Loss: 0.42015\n",
      "Epoch 077: | Train Loss: 0.25396 | Test Loss: 1.79718\n",
      "Epoch 078: | Train Loss: 0.23641 | Test Loss: 0.32453\n",
      "Epoch 079: | Train Loss: 0.26622 | Test Loss: 0.35247\n",
      "Epoch 080: | Train Loss: 0.24428 | Test Loss: 0.34498\n",
      "Epoch 081: | Train Loss: 0.26316 | Test Loss: 0.35130\n",
      "Epoch 082: | Train Loss: 0.23828 | Test Loss: 0.49217\n",
      "Epoch 083: | Train Loss: 0.22422 | Test Loss: 0.44511\n",
      "Epoch 084: | Train Loss: 0.22786 | Test Loss: 0.41635\n",
      "Epoch 085: | Train Loss: 0.30075 | Test Loss: 0.50391\n",
      "Epoch 086: | Train Loss: 0.21228 | Test Loss: 0.65957\n",
      "Epoch 087: | Train Loss: 0.23548 | Test Loss: 0.38681\n",
      "Epoch 088: | Train Loss: 0.29085 | Test Loss: 0.37773\n",
      "Epoch 089: | Train Loss: 0.23540 | Test Loss: 0.38076\n",
      "Epoch 090: | Train Loss: 0.23814 | Test Loss: 1.11373\n",
      "Epoch 091: | Train Loss: 0.33764 | Test Loss: 0.35766\n",
      "Epoch 092: | Train Loss: 0.31689 | Test Loss: 0.40863\n",
      "Epoch 093: | Train Loss: 0.27494 | Test Loss: 0.47234\n",
      "Epoch 094: | Train Loss: 0.32537 | Test Loss: 0.48234\n",
      "Epoch 095: | Train Loss: 0.29928 | Test Loss: 0.44725\n",
      "Epoch 096: | Train Loss: 0.25533 | Test Loss: 0.39887\n",
      "Epoch 097: | Train Loss: 0.22824 | Test Loss: 0.52654\n",
      "Epoch 098: | Train Loss: 0.27353 | Test Loss: 0.43313\n",
      "Epoch 099: | Train Loss: 0.22892 | Test Loss: 0.58585\n",
      "Epoch 100: | Train Loss: 0.26652 | Test Loss: 0.35928\n",
      "Epoch 101: | Train Loss: 0.21698 | Test Loss: 0.42473\n",
      "Epoch 102: | Train Loss: 0.27999 | Test Loss: 0.36780\n",
      "Epoch 103: | Train Loss: 0.19185 | Test Loss: 0.41277\n",
      "Epoch 104: | Train Loss: 0.22158 | Test Loss: 0.49643\n",
      "Epoch 105: | Train Loss: 0.19496 | Test Loss: 0.78233\n",
      "Epoch 106: | Train Loss: 0.20343 | Test Loss: 0.36049\n",
      "Epoch 107: | Train Loss: 0.20088 | Test Loss: 0.32940\n",
      "Epoch 108: | Train Loss: 0.22076 | Test Loss: 0.73253\n",
      "Epoch 109: | Train Loss: 0.23625 | Test Loss: 0.38063\n",
      "Epoch 110: | Train Loss: 0.21098 | Test Loss: 0.37761\n",
      "Epoch 111: | Train Loss: 0.43052 | Test Loss: 0.37700\n",
      "Epoch 112: | Train Loss: 0.34782 | Test Loss: 0.24607\n",
      "Epoch 113: | Train Loss: 0.26569 | Test Loss: 0.39312\n",
      "Epoch 114: | Train Loss: 0.20501 | Test Loss: 0.36705\n",
      "Epoch 115: | Train Loss: 0.25838 | Test Loss: 0.35658\n",
      "Epoch 116: | Train Loss: 0.24553 | Test Loss: 0.38610\n",
      "Epoch 117: | Train Loss: 0.20487 | Test Loss: 0.25487\n",
      "Epoch 118: | Train Loss: 0.19734 | Test Loss: 0.35597\n",
      "Epoch 119: | Train Loss: 0.20615 | Test Loss: 0.37622\n",
      "Epoch 120: | Train Loss: 0.23978 | Test Loss: 0.33326\n",
      "Epoch 121: | Train Loss: 0.22821 | Test Loss: 0.35440\n",
      "Epoch 122: | Train Loss: 0.20682 | Test Loss: 0.35864\n",
      "Epoch 123: | Train Loss: 0.23148 | Test Loss: 0.39161\n",
      "Epoch 124: | Train Loss: 0.19538 | Test Loss: 0.40305\n",
      "Epoch 125: | Train Loss: 0.21036 | Test Loss: 0.71795\n",
      "Epoch 126: | Train Loss: 0.27495 | Test Loss: 0.32138\n",
      "Epoch 127: | Train Loss: 0.20305 | Test Loss: 0.34085\n",
      "Epoch 128: | Train Loss: 0.24018 | Test Loss: 0.36798\n",
      "Epoch 129: | Train Loss: 0.21277 | Test Loss: 0.44131\n",
      "Epoch 130: | Train Loss: 0.22104 | Test Loss: 0.34244\n",
      "Epoch 131: | Train Loss: 0.19354 | Test Loss: 0.36835\n",
      "Epoch 132: | Train Loss: 0.21125 | Test Loss: 0.36771\n",
      "Epoch 133: | Train Loss: 0.21060 | Test Loss: 0.38005\n",
      "Epoch 134: | Train Loss: 0.18259 | Test Loss: 0.45635\n",
      "Epoch 135: | Train Loss: 0.21657 | Test Loss: 0.46446\n",
      "Epoch 136: | Train Loss: 0.21693 | Test Loss: 0.36832\n",
      "Epoch 137: | Train Loss: 0.17569 | Test Loss: 0.44530\n",
      "Epoch 138: | Train Loss: 0.19895 | Test Loss: 0.38878\n",
      "Epoch 139: | Train Loss: 0.18770 | Test Loss: 0.35354\n",
      "Epoch 140: | Train Loss: 0.22077 | Test Loss: 0.35953\n",
      "Epoch 141: | Train Loss: 0.20915 | Test Loss: 0.49140\n",
      "Epoch 142: | Train Loss: 0.20064 | Test Loss: 0.36590\n",
      "Epoch 143: | Train Loss: 0.19908 | Test Loss: 0.39914\n",
      "Epoch 144: | Train Loss: 0.21316 | Test Loss: 0.35740\n",
      "Epoch 145: | Train Loss: 0.22464 | Test Loss: 0.34180\n",
      "Epoch 146: | Train Loss: 0.19014 | Test Loss: 0.47498\n",
      "Epoch 147: | Train Loss: 0.20459 | Test Loss: 0.39780\n",
      "Epoch 148: | Train Loss: 0.20548 | Test Loss: 0.38502\n",
      "Epoch 149: | Train Loss: 0.19391 | Test Loss: 0.39388\n",
      "Epoch 150: | Train Loss: 0.22198 | Test Loss: 0.45617\n",
      "Epoch 151: | Train Loss: 0.21409 | Test Loss: 0.41415\n",
      "Epoch 152: | Train Loss: 0.26978 | Test Loss: 0.32265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: | Train Loss: 0.20340 | Test Loss: 0.42409\n",
      "Epoch 154: | Train Loss: 0.19231 | Test Loss: 0.37746\n",
      "Epoch 155: | Train Loss: 0.23463 | Test Loss: 0.46761\n",
      "Epoch 156: | Train Loss: 0.26277 | Test Loss: 0.32962\n",
      "Epoch 157: | Train Loss: 0.24759 | Test Loss: 0.39442\n",
      "Epoch 158: | Train Loss: 0.19998 | Test Loss: 0.48714\n",
      "Epoch 159: | Train Loss: 0.19238 | Test Loss: 0.42543\n",
      "Epoch 160: | Train Loss: 0.18783 | Test Loss: 0.43639\n",
      "Epoch 161: | Train Loss: 0.22003 | Test Loss: 0.34821\n",
      "Epoch 162: | Train Loss: 0.18944 | Test Loss: 0.46128\n",
      "Epoch 163: | Train Loss: 0.21644 | Test Loss: 0.43524\n",
      "Epoch 164: | Train Loss: 0.19456 | Test Loss: 0.48100\n",
      "Epoch 165: | Train Loss: 0.24256 | Test Loss: 0.42890\n",
      "Epoch 166: | Train Loss: 0.23037 | Test Loss: 0.36696\n",
      "Epoch 167: | Train Loss: 0.22504 | Test Loss: 0.37418\n",
      "Epoch 168: | Train Loss: 0.20375 | Test Loss: 0.37447\n",
      "Epoch 169: | Train Loss: 0.20404 | Test Loss: 0.37383\n",
      "Epoch 170: | Train Loss: 0.19998 | Test Loss: 0.39937\n",
      "Epoch 171: | Train Loss: 0.26604 | Test Loss: 0.39666\n",
      "Epoch 172: | Train Loss: 0.19230 | Test Loss: 0.32529\n",
      "Epoch 173: | Train Loss: 0.18068 | Test Loss: 0.34096\n",
      "Epoch 174: | Train Loss: 0.19565 | Test Loss: 0.29996\n",
      "Epoch 175: | Train Loss: 0.18062 | Test Loss: 0.31954\n",
      "Epoch 176: | Train Loss: 0.19053 | Test Loss: 0.38937\n",
      "Epoch 177: | Train Loss: 0.20265 | Test Loss: 0.36587\n",
      "Epoch 178: | Train Loss: 0.21468 | Test Loss: 0.43167\n",
      "Epoch 179: | Train Loss: 0.19502 | Test Loss: 0.35626\n",
      "Epoch 180: | Train Loss: 0.19773 | Test Loss: 0.38982\n",
      "Epoch 181: | Train Loss: 0.18191 | Test Loss: 0.43833\n",
      "Epoch 182: | Train Loss: 0.21811 | Test Loss: 0.31663\n",
      "Epoch 183: | Train Loss: 0.19864 | Test Loss: 0.31812\n",
      "Epoch 184: | Train Loss: 0.20777 | Test Loss: 0.31545\n",
      "Epoch 185: | Train Loss: 0.19022 | Test Loss: 0.34508\n",
      "Epoch 186: | Train Loss: 0.24053 | Test Loss: 0.33157\n",
      "Epoch 187: | Train Loss: 0.18918 | Test Loss: 0.33451\n",
      "Epoch 188: | Train Loss: 0.22244 | Test Loss: 0.32554\n",
      "Epoch 189: | Train Loss: 0.24351 | Test Loss: 0.49628\n",
      "Epoch 190: | Train Loss: 0.23219 | Test Loss: 0.36624\n",
      "Epoch 191: | Train Loss: 0.18774 | Test Loss: 0.38147\n",
      "Epoch 192: | Train Loss: 0.21395 | Test Loss: 1.59794\n",
      "Epoch 193: | Train Loss: 0.26719 | Test Loss: 0.25502\n",
      "Epoch 194: | Train Loss: 0.20473 | Test Loss: 0.36144\n",
      "Epoch 195: | Train Loss: 0.16989 | Test Loss: 0.35381\n",
      "Epoch 196: | Train Loss: 0.23042 | Test Loss: 0.36157\n",
      "Epoch 197: | Train Loss: 0.17341 | Test Loss: 0.35561\n",
      "Epoch 198: | Train Loss: 0.18681 | Test Loss: 0.36748\n",
      "Epoch 199: | Train Loss: 0.18796 | Test Loss: 0.32316\n",
      "Epoch 200: | Train Loss: 0.22790 | Test Loss: 0.33065\n",
      "Epoch 201: | Train Loss: 0.18903 | Test Loss: 0.32422\n",
      "Epoch 202: | Train Loss: 0.24054 | Test Loss: 0.32715\n",
      "Epoch 203: | Train Loss: 0.19378 | Test Loss: 0.33119\n",
      "Epoch 204: | Train Loss: 0.17468 | Test Loss: 0.37968\n",
      "Epoch 205: | Train Loss: 0.20888 | Test Loss: 0.38998\n",
      "Epoch 206: | Train Loss: 0.34087 | Test Loss: 0.35844\n",
      "Epoch 207: | Train Loss: 0.21706 | Test Loss: 0.53905\n",
      "Epoch 208: | Train Loss: 0.18833 | Test Loss: 0.37367\n",
      "Epoch 209: | Train Loss: 0.24253 | Test Loss: 0.50330\n",
      "Epoch 210: | Train Loss: 0.33114 | Test Loss: 0.36817\n",
      "Epoch 211: | Train Loss: 0.26498 | Test Loss: 0.32014\n",
      "Epoch 212: | Train Loss: 0.21120 | Test Loss: 0.34228\n",
      "Epoch 213: | Train Loss: 0.27377 | Test Loss: 0.33069\n",
      "Epoch 214: | Train Loss: 0.18712 | Test Loss: 0.27093\n",
      "Epoch 215: | Train Loss: 0.16770 | Test Loss: 0.37563\n",
      "Epoch 216: | Train Loss: 0.18252 | Test Loss: 0.38074\n",
      "Epoch 217: | Train Loss: 0.18485 | Test Loss: 0.43375\n",
      "Epoch 218: | Train Loss: 0.20433 | Test Loss: 0.50909\n",
      "Epoch 219: | Train Loss: 0.25877 | Test Loss: 0.27022\n",
      "Epoch 220: | Train Loss: 0.22925 | Test Loss: 0.44495\n",
      "Epoch 221: | Train Loss: 0.26210 | Test Loss: 0.31767\n",
      "Epoch 222: | Train Loss: 0.19226 | Test Loss: 0.34215\n",
      "Epoch 223: | Train Loss: 0.17487 | Test Loss: 0.38354\n",
      "Epoch 224: | Train Loss: 0.19442 | Test Loss: 0.34543\n",
      "Epoch 225: | Train Loss: 0.29522 | Test Loss: 0.36507\n",
      "Epoch 226: | Train Loss: 0.18680 | Test Loss: 0.28666\n",
      "Epoch 227: | Train Loss: 0.18805 | Test Loss: 0.55501\n",
      "Epoch 228: | Train Loss: 0.19113 | Test Loss: 0.32308\n",
      "Epoch 229: | Train Loss: 0.17453 | Test Loss: 0.34571\n",
      "Epoch 230: | Train Loss: 0.19534 | Test Loss: 0.44458\n",
      "Epoch 231: | Train Loss: 0.21002 | Test Loss: 0.35104\n",
      "Epoch 232: | Train Loss: 0.18758 | Test Loss: 0.37277\n",
      "Epoch 233: | Train Loss: 0.19446 | Test Loss: 0.35658\n",
      "Epoch 234: | Train Loss: 0.19812 | Test Loss: 0.37883\n",
      "Epoch 235: | Train Loss: 0.20507 | Test Loss: 0.48467\n",
      "Epoch 236: | Train Loss: 0.30904 | Test Loss: 0.30048\n",
      "Epoch 237: | Train Loss: 0.20111 | Test Loss: 0.39606\n",
      "Epoch 238: | Train Loss: 0.24045 | Test Loss: 0.32607\n",
      "Epoch 239: | Train Loss: 0.17002 | Test Loss: 0.34155\n",
      "Epoch 240: | Train Loss: 0.17117 | Test Loss: 0.33830\n",
      "stats of l2reg of  0.003 are [0.94912 0.93187 0.19344 0.27596]\n",
      "running reg of 0.01\n",
      "initial run of high regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5971987dcc1441aa9a61eabacfc560e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.63700 | Test Loss: 0.62317\n",
      "Epoch 002: | Train Loss: 0.62622 | Test Loss: 0.60092\n",
      "Epoch 003: | Train Loss: 0.60624 | Test Loss: 0.63895\n",
      "Epoch 004: | Train Loss: 0.62883 | Test Loss: 0.62818\n",
      "Epoch 005: | Train Loss: 0.62000 | Test Loss: 0.62328\n",
      "Epoch 006: | Train Loss: 0.61603 | Test Loss: 0.62107\n",
      "Epoch 007: | Train Loss: 0.61486 | Test Loss: 0.61987\n",
      "Epoch 008: | Train Loss: 0.61335 | Test Loss: 0.61961\n",
      "Epoch 009: | Train Loss: 0.61321 | Test Loss: 0.61945\n",
      "Epoch 010: | Train Loss: 0.61298 | Test Loss: 0.61923\n",
      "Epoch 011: | Train Loss: 0.61349 | Test Loss: 0.61914\n",
      "Epoch 012: | Train Loss: 0.61304 | Test Loss: 0.61931\n",
      "Epoch 013: | Train Loss: 0.61360 | Test Loss: 0.61933\n",
      "Epoch 014: | Train Loss: 0.61308 | Test Loss: 0.61909\n",
      "Epoch 015: | Train Loss: 0.61332 | Test Loss: 0.61928\n",
      "Epoch 016: | Train Loss: 0.61332 | Test Loss: 0.61895\n",
      "Epoch 017: | Train Loss: 0.61310 | Test Loss: 0.61888\n",
      "Epoch 018: | Train Loss: 0.61301 | Test Loss: 0.61928\n",
      "Epoch 019: | Train Loss: 0.61330 | Test Loss: 0.61947\n",
      "Epoch 020: | Train Loss: 0.61409 | Test Loss: 0.61891\n",
      "run with given regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f8a7fbc9234f57b42236612a802bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.60183 | Test Loss: 0.59867\n",
      "Epoch 002: | Train Loss: 0.58165 | Test Loss: 0.55882\n",
      "Epoch 003: | Train Loss: 0.53873 | Test Loss: 0.96502\n",
      "Epoch 004: | Train Loss: 0.60340 | Test Loss: 0.52587\n",
      "Epoch 005: | Train Loss: 0.49294 | Test Loss: 0.46966\n",
      "Epoch 006: | Train Loss: 0.50635 | Test Loss: 0.50760\n",
      "Epoch 007: | Train Loss: 0.48624 | Test Loss: 0.43784\n",
      "Epoch 008: | Train Loss: 0.47507 | Test Loss: 0.44945\n",
      "Epoch 009: | Train Loss: 0.45496 | Test Loss: 0.43755\n",
      "Epoch 010: | Train Loss: 0.47090 | Test Loss: 0.41973\n",
      "Epoch 011: | Train Loss: 0.45426 | Test Loss: 0.47349\n",
      "Epoch 012: | Train Loss: 0.42714 | Test Loss: 0.42619\n",
      "Epoch 013: | Train Loss: 0.39397 | Test Loss: 0.38557\n",
      "Epoch 014: | Train Loss: 0.38660 | Test Loss: 0.37319\n",
      "Epoch 015: | Train Loss: 0.35165 | Test Loss: 0.37281\n",
      "Epoch 016: | Train Loss: 0.34707 | Test Loss: 0.34357\n",
      "Epoch 017: | Train Loss: 0.32879 | Test Loss: 0.32967\n",
      "Epoch 018: | Train Loss: 0.31358 | Test Loss: 0.41482\n",
      "Epoch 019: | Train Loss: 0.29309 | Test Loss: 0.30825\n",
      "Epoch 020: | Train Loss: 0.30807 | Test Loss: 0.35141\n",
      "Epoch 021: | Train Loss: 0.29984 | Test Loss: 0.34620\n",
      "Epoch 022: | Train Loss: 0.31009 | Test Loss: 0.34228\n",
      "Epoch 023: | Train Loss: 0.30143 | Test Loss: 0.32023\n",
      "Epoch 024: | Train Loss: 0.27094 | Test Loss: 0.32807\n",
      "Epoch 025: | Train Loss: 0.27052 | Test Loss: 0.51405\n",
      "Epoch 026: | Train Loss: 0.30362 | Test Loss: 0.33503\n",
      "Epoch 027: | Train Loss: 0.27957 | Test Loss: 0.41204\n",
      "Epoch 028: | Train Loss: 0.26789 | Test Loss: 0.35907\n",
      "Epoch 029: | Train Loss: 0.31003 | Test Loss: 0.39062\n",
      "Epoch 030: | Train Loss: 0.29982 | Test Loss: 0.35707\n",
      "Epoch 031: | Train Loss: 0.29384 | Test Loss: 0.40444\n",
      "Epoch 032: | Train Loss: 0.37505 | Test Loss: 0.38945\n",
      "Epoch 033: | Train Loss: 0.29014 | Test Loss: 0.35662\n",
      "Epoch 034: | Train Loss: 0.26801 | Test Loss: 0.33840\n",
      "Epoch 035: | Train Loss: 0.35638 | Test Loss: 0.37004\n",
      "Epoch 036: | Train Loss: 0.27472 | Test Loss: 0.37875\n",
      "Epoch 037: | Train Loss: 0.25996 | Test Loss: 0.47817\n",
      "Epoch 038: | Train Loss: 0.25381 | Test Loss: 0.37360\n",
      "Epoch 039: | Train Loss: 0.27465 | Test Loss: 0.35539\n",
      "Epoch 040: | Train Loss: 0.24855 | Test Loss: 0.34588\n",
      "Epoch 041: | Train Loss: 0.26690 | Test Loss: 0.32718\n",
      "Epoch 042: | Train Loss: 0.27046 | Test Loss: 0.59442\n",
      "Epoch 043: | Train Loss: 0.23908 | Test Loss: 0.42698\n",
      "Epoch 044: | Train Loss: 0.22972 | Test Loss: 0.55795\n",
      "Epoch 045: | Train Loss: 0.27695 | Test Loss: 0.39819\n",
      "Epoch 046: | Train Loss: 0.26570 | Test Loss: 0.37613\n",
      "Epoch 047: | Train Loss: 0.22829 | Test Loss: 0.48556\n",
      "Epoch 048: | Train Loss: 0.22936 | Test Loss: 0.37321\n",
      "Epoch 049: | Train Loss: 0.33467 | Test Loss: 0.39057\n",
      "Epoch 050: | Train Loss: 0.24189 | Test Loss: 0.38422\n",
      "Epoch 051: | Train Loss: 0.28139 | Test Loss: 0.36094\n",
      "Epoch 052: | Train Loss: 0.25394 | Test Loss: 0.33827\n",
      "Epoch 053: | Train Loss: 0.25508 | Test Loss: 0.39985\n",
      "Epoch 054: | Train Loss: 0.26479 | Test Loss: 0.37212\n",
      "Epoch 055: | Train Loss: 0.24664 | Test Loss: 0.47420\n",
      "Epoch 056: | Train Loss: 0.25031 | Test Loss: 0.53959\n",
      "Epoch 057: | Train Loss: 0.24051 | Test Loss: 0.30719\n",
      "Epoch 058: | Train Loss: 0.23842 | Test Loss: 0.36048\n",
      "Epoch 059: | Train Loss: 0.25371 | Test Loss: 0.47104\n",
      "Epoch 060: | Train Loss: 0.27038 | Test Loss: 0.43984\n",
      "Epoch 061: | Train Loss: 0.21512 | Test Loss: 0.40242\n",
      "Epoch 062: | Train Loss: 0.30884 | Test Loss: 0.37569\n",
      "Epoch 063: | Train Loss: 0.23646 | Test Loss: 0.51485\n",
      "Epoch 064: | Train Loss: 0.24269 | Test Loss: 0.44145\n",
      "Epoch 065: | Train Loss: 0.23065 | Test Loss: 0.35572\n",
      "Epoch 066: | Train Loss: 0.27033 | Test Loss: 0.34669\n",
      "Epoch 067: | Train Loss: 0.24915 | Test Loss: 0.51017\n",
      "Epoch 068: | Train Loss: 0.23695 | Test Loss: 0.39050\n",
      "Epoch 069: | Train Loss: 0.23573 | Test Loss: 0.39724\n",
      "Epoch 070: | Train Loss: 0.21865 | Test Loss: 0.35122\n",
      "Epoch 071: | Train Loss: 0.23122 | Test Loss: 0.44143\n",
      "Epoch 072: | Train Loss: 0.21891 | Test Loss: 0.40699\n",
      "Epoch 073: | Train Loss: 0.26104 | Test Loss: 0.41972\n",
      "Epoch 074: | Train Loss: 0.21915 | Test Loss: 0.49532\n",
      "Epoch 075: | Train Loss: 0.24832 | Test Loss: 0.61226\n",
      "Epoch 076: | Train Loss: 0.25702 | Test Loss: 0.36543\n",
      "Epoch 077: | Train Loss: 0.26064 | Test Loss: 0.44490\n",
      "Epoch 078: | Train Loss: 0.26896 | Test Loss: 0.41599\n",
      "Epoch 079: | Train Loss: 0.31127 | Test Loss: 0.37659\n",
      "Epoch 080: | Train Loss: 0.25958 | Test Loss: 0.36290\n",
      "Epoch 081: | Train Loss: 0.26766 | Test Loss: 0.36133\n",
      "Epoch 082: | Train Loss: 0.22557 | Test Loss: 0.39631\n",
      "Epoch 083: | Train Loss: 0.24786 | Test Loss: 0.36599\n",
      "Epoch 084: | Train Loss: 0.29511 | Test Loss: 0.40758\n",
      "Epoch 085: | Train Loss: 0.25856 | Test Loss: 0.43438\n",
      "Epoch 086: | Train Loss: 0.27916 | Test Loss: 0.39602\n",
      "Epoch 087: | Train Loss: 0.25443 | Test Loss: 0.41780\n",
      "Epoch 088: | Train Loss: 0.27287 | Test Loss: 0.32259\n",
      "Epoch 089: | Train Loss: 0.27857 | Test Loss: 0.43972\n",
      "Epoch 090: | Train Loss: 0.26232 | Test Loss: 0.45719\n",
      "Epoch 091: | Train Loss: 0.25819 | Test Loss: 0.35991\n",
      "Epoch 092: | Train Loss: 0.26241 | Test Loss: 0.93754\n",
      "Epoch 093: | Train Loss: 0.25264 | Test Loss: 0.41232\n",
      "Epoch 094: | Train Loss: 0.24801 | Test Loss: 0.40749\n",
      "Epoch 095: | Train Loss: 0.24012 | Test Loss: 0.45117\n",
      "Epoch 096: | Train Loss: 0.27554 | Test Loss: 0.41813\n",
      "Epoch 097: | Train Loss: 0.26515 | Test Loss: 0.38147\n",
      "Epoch 098: | Train Loss: 0.24477 | Test Loss: 0.51894\n",
      "Epoch 099: | Train Loss: 0.25930 | Test Loss: 0.37274\n",
      "Epoch 100: | Train Loss: 0.23381 | Test Loss: 0.37606\n",
      "Epoch 101: | Train Loss: 0.22859 | Test Loss: 0.47738\n",
      "Epoch 102: | Train Loss: 0.23358 | Test Loss: 0.42659\n",
      "Epoch 103: | Train Loss: 0.28543 | Test Loss: 0.45838\n",
      "Epoch 104: | Train Loss: 0.22450 | Test Loss: 0.43059\n",
      "Epoch 105: | Train Loss: 0.26531 | Test Loss: 0.36708\n",
      "Epoch 106: | Train Loss: 0.24550 | Test Loss: 0.64868\n",
      "Epoch 107: | Train Loss: 0.25105 | Test Loss: 0.40571\n",
      "Epoch 108: | Train Loss: 0.27712 | Test Loss: 0.37367\n",
      "Epoch 109: | Train Loss: 0.29454 | Test Loss: 0.47018\n",
      "Epoch 110: | Train Loss: 0.25989 | Test Loss: 0.38806\n",
      "Epoch 111: | Train Loss: 0.25510 | Test Loss: 0.44728\n",
      "Epoch 112: | Train Loss: 0.22080 | Test Loss: 0.46040\n",
      "Epoch 113: | Train Loss: 0.27099 | Test Loss: 0.42118\n",
      "Epoch 114: | Train Loss: 0.25099 | Test Loss: 0.39711\n",
      "Epoch 115: | Train Loss: 0.22056 | Test Loss: 0.40176\n",
      "Epoch 116: | Train Loss: 0.25049 | Test Loss: 0.33445\n",
      "Epoch 117: | Train Loss: 0.28761 | Test Loss: 0.46337\n",
      "Epoch 118: | Train Loss: 0.23870 | Test Loss: 0.37482\n",
      "Epoch 119: | Train Loss: 0.22056 | Test Loss: 0.40391\n",
      "Epoch 120: | Train Loss: 0.22979 | Test Loss: 0.34011\n",
      "Epoch 121: | Train Loss: 0.24159 | Test Loss: 0.38052\n",
      "Epoch 122: | Train Loss: 0.21958 | Test Loss: 0.47849\n",
      "Epoch 123: | Train Loss: 0.24366 | Test Loss: 0.46343\n",
      "Epoch 124: | Train Loss: 0.29303 | Test Loss: 0.74144\n",
      "Epoch 125: | Train Loss: 0.37170 | Test Loss: 0.41788\n",
      "Epoch 126: | Train Loss: 0.26837 | Test Loss: 0.35269\n",
      "Epoch 127: | Train Loss: 0.25377 | Test Loss: 0.29000\n",
      "Epoch 128: | Train Loss: 0.26487 | Test Loss: 0.51063\n",
      "Epoch 129: | Train Loss: 0.30450 | Test Loss: 0.43893\n",
      "Epoch 130: | Train Loss: 0.27102 | Test Loss: 0.35583\n",
      "Epoch 131: | Train Loss: 0.25782 | Test Loss: 0.38401\n",
      "Epoch 132: | Train Loss: 0.24133 | Test Loss: 0.34989\n",
      "Epoch 133: | Train Loss: 0.26172 | Test Loss: 0.36334\n",
      "Epoch 134: | Train Loss: 0.26467 | Test Loss: 0.36043\n",
      "Epoch 135: | Train Loss: 0.28431 | Test Loss: 0.39424\n",
      "Epoch 136: | Train Loss: 0.29584 | Test Loss: 0.39665\n",
      "Epoch 137: | Train Loss: 0.26344 | Test Loss: 0.46257\n",
      "Epoch 138: | Train Loss: 0.22086 | Test Loss: 0.32779\n",
      "Epoch 139: | Train Loss: 0.21594 | Test Loss: 0.41218\n",
      "Epoch 140: | Train Loss: 0.23004 | Test Loss: 0.40728\n",
      "Epoch 141: | Train Loss: 0.24749 | Test Loss: 0.40872\n",
      "Epoch 142: | Train Loss: 0.29234 | Test Loss: 0.37427\n",
      "Epoch 143: | Train Loss: 0.32429 | Test Loss: 0.32866\n",
      "Epoch 144: | Train Loss: 0.25230 | Test Loss: 0.32062\n",
      "Epoch 145: | Train Loss: 0.35302 | Test Loss: 0.32840\n",
      "Epoch 146: | Train Loss: 0.27513 | Test Loss: 0.32544\n",
      "Epoch 147: | Train Loss: 0.24862 | Test Loss: 0.33272\n",
      "Epoch 148: | Train Loss: 0.27379 | Test Loss: 0.69571\n",
      "Epoch 149: | Train Loss: 0.21903 | Test Loss: 0.36116\n",
      "Epoch 150: | Train Loss: 0.21413 | Test Loss: 0.42064\n",
      "Epoch 151: | Train Loss: 0.24615 | Test Loss: 0.39790\n",
      "Epoch 152: | Train Loss: 0.26648 | Test Loss: 0.38891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: | Train Loss: 0.25675 | Test Loss: 0.39084\n",
      "Epoch 154: | Train Loss: 0.25619 | Test Loss: 0.35908\n",
      "Epoch 155: | Train Loss: 0.25306 | Test Loss: 0.36114\n",
      "Epoch 156: | Train Loss: 0.29636 | Test Loss: 0.45612\n",
      "Epoch 157: | Train Loss: 0.26236 | Test Loss: 0.35946\n",
      "Epoch 158: | Train Loss: 0.26695 | Test Loss: 0.36324\n",
      "Epoch 159: | Train Loss: 0.24378 | Test Loss: 0.35865\n",
      "Epoch 160: | Train Loss: 0.31824 | Test Loss: 0.43901\n",
      "Epoch 161: | Train Loss: 0.23224 | Test Loss: 0.43241\n",
      "Epoch 162: | Train Loss: 0.24653 | Test Loss: 0.41161\n",
      "Epoch 163: | Train Loss: 0.27089 | Test Loss: 0.37917\n",
      "Epoch 164: | Train Loss: 0.24971 | Test Loss: 0.33844\n",
      "Epoch 165: | Train Loss: 0.27012 | Test Loss: 0.32512\n",
      "Epoch 166: | Train Loss: 0.25792 | Test Loss: 0.39512\n",
      "Epoch 167: | Train Loss: 0.27932 | Test Loss: 0.33997\n",
      "Epoch 168: | Train Loss: 0.26093 | Test Loss: 0.89729\n",
      "Epoch 169: | Train Loss: 0.35886 | Test Loss: 0.48830\n",
      "Epoch 170: | Train Loss: 0.29810 | Test Loss: 0.32465\n",
      "Epoch 171: | Train Loss: 0.26125 | Test Loss: 0.35333\n",
      "Epoch 172: | Train Loss: 0.26279 | Test Loss: 0.30611\n",
      "Epoch 173: | Train Loss: 0.25143 | Test Loss: 0.30526\n",
      "Epoch 174: | Train Loss: 0.25377 | Test Loss: 0.35766\n",
      "Epoch 175: | Train Loss: 0.23517 | Test Loss: 0.37916\n",
      "Epoch 176: | Train Loss: 0.23877 | Test Loss: 0.38074\n",
      "Epoch 177: | Train Loss: 0.23224 | Test Loss: 0.50452\n",
      "Epoch 178: | Train Loss: 0.23606 | Test Loss: 0.36676\n",
      "Epoch 179: | Train Loss: 0.25608 | Test Loss: 0.39901\n",
      "Epoch 180: | Train Loss: 0.28990 | Test Loss: 0.39786\n",
      "Epoch 181: | Train Loss: 0.28411 | Test Loss: 0.37641\n",
      "Epoch 182: | Train Loss: 0.24287 | Test Loss: 0.38347\n",
      "Epoch 183: | Train Loss: 0.26006 | Test Loss: 0.35657\n",
      "Epoch 184: | Train Loss: 0.26613 | Test Loss: 0.38567\n",
      "Epoch 185: | Train Loss: 0.24146 | Test Loss: 0.46948\n",
      "Epoch 186: | Train Loss: 0.29087 | Test Loss: 0.36335\n",
      "Epoch 187: | Train Loss: 0.25749 | Test Loss: 0.36794\n",
      "Epoch 188: | Train Loss: 0.26735 | Test Loss: 0.35448\n",
      "Epoch 189: | Train Loss: 0.27983 | Test Loss: 0.34151\n",
      "Epoch 190: | Train Loss: 0.35022 | Test Loss: 0.36322\n",
      "Epoch 191: | Train Loss: 0.22534 | Test Loss: 0.38631\n",
      "Epoch 192: | Train Loss: 0.29346 | Test Loss: 0.41998\n",
      "Epoch 193: | Train Loss: 0.28106 | Test Loss: 0.38923\n",
      "Epoch 194: | Train Loss: 0.24523 | Test Loss: 0.37827\n",
      "Epoch 195: | Train Loss: 0.27209 | Test Loss: 0.36147\n",
      "Epoch 196: | Train Loss: 0.22215 | Test Loss: 0.67194\n",
      "Epoch 197: | Train Loss: 0.28614 | Test Loss: 0.46358\n",
      "Epoch 198: | Train Loss: 0.28471 | Test Loss: 0.38203\n",
      "Epoch 199: | Train Loss: 0.28551 | Test Loss: 0.40738\n",
      "Epoch 200: | Train Loss: 0.24742 | Test Loss: 0.44857\n",
      "Epoch 201: | Train Loss: 0.28326 | Test Loss: 0.52892\n",
      "Epoch 202: | Train Loss: 0.28557 | Test Loss: 0.37061\n",
      "Epoch 203: | Train Loss: 0.24272 | Test Loss: 0.38233\n",
      "Epoch 204: | Train Loss: 0.25120 | Test Loss: 0.36977\n",
      "Epoch 205: | Train Loss: 0.29163 | Test Loss: 0.37498\n",
      "Epoch 206: | Train Loss: 0.25958 | Test Loss: 0.34817\n",
      "Epoch 207: | Train Loss: 0.27271 | Test Loss: 0.33532\n",
      "Epoch 208: | Train Loss: 0.25077 | Test Loss: 0.34885\n",
      "Epoch 209: | Train Loss: 0.27384 | Test Loss: 0.44893\n",
      "Epoch 210: | Train Loss: 0.27701 | Test Loss: 0.41178\n",
      "Epoch 211: | Train Loss: 0.26423 | Test Loss: 0.41103\n",
      "Epoch 212: | Train Loss: 0.26667 | Test Loss: 0.41817\n",
      "Epoch 213: | Train Loss: 0.26322 | Test Loss: 0.35774\n",
      "Epoch 214: | Train Loss: 0.24165 | Test Loss: 0.33523\n",
      "Epoch 215: | Train Loss: 0.23309 | Test Loss: 0.35233\n",
      "Epoch 216: | Train Loss: 0.26388 | Test Loss: 0.36365\n",
      "Epoch 217: | Train Loss: 0.27519 | Test Loss: 0.38120\n",
      "Epoch 218: | Train Loss: 0.24619 | Test Loss: 0.37676\n",
      "Epoch 219: | Train Loss: 0.27737 | Test Loss: 0.32568\n",
      "Epoch 220: | Train Loss: 0.23139 | Test Loss: 0.36246\n",
      "Epoch 221: | Train Loss: 0.24826 | Test Loss: 0.30449\n",
      "Epoch 222: | Train Loss: 0.26800 | Test Loss: 0.37592\n",
      "Epoch 223: | Train Loss: 0.24386 | Test Loss: 0.35863\n",
      "Epoch 224: | Train Loss: 0.23154 | Test Loss: 0.35582\n",
      "Epoch 225: | Train Loss: 0.27917 | Test Loss: 0.35666\n",
      "Epoch 226: | Train Loss: 0.25337 | Test Loss: 0.49110\n",
      "Epoch 227: | Train Loss: 0.29315 | Test Loss: 0.38603\n",
      "Epoch 228: | Train Loss: 0.29776 | Test Loss: 0.34279\n",
      "Epoch 229: | Train Loss: 0.29854 | Test Loss: 0.45590\n",
      "Epoch 230: | Train Loss: 0.27265 | Test Loss: 0.67736\n",
      "Epoch 231: | Train Loss: 0.26137 | Test Loss: 0.43359\n",
      "Epoch 232: | Train Loss: 0.28234 | Test Loss: 0.34087\n",
      "Epoch 233: | Train Loss: 0.28626 | Test Loss: 0.39004\n",
      "Epoch 234: | Train Loss: 0.25560 | Test Loss: 0.43390\n",
      "Epoch 235: | Train Loss: 0.24825 | Test Loss: 0.44375\n",
      "Epoch 236: | Train Loss: 0.32771 | Test Loss: 0.40870\n",
      "Epoch 237: | Train Loss: 0.33482 | Test Loss: 0.51955\n",
      "Epoch 238: | Train Loss: 0.23885 | Test Loss: 0.66075\n",
      "Epoch 239: | Train Loss: 0.29675 | Test Loss: 0.57714\n",
      "Epoch 240: | Train Loss: 0.26052 | Test Loss: 0.32267\n",
      "stats of l2reg of  0.01 are [0.95014 0.93348 0.19436 0.2811 ]\n",
      "running reg of 0.03\n",
      "initial run of high regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09b6da845ce462daa1551ca6a0116e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.67380 | Test Loss: 0.66733\n",
      "Epoch 002: | Train Loss: 0.61291 | Test Loss: 0.72559\n",
      "Epoch 003: | Train Loss: 0.64273 | Test Loss: 0.63404\n",
      "Epoch 004: | Train Loss: 0.58560 | Test Loss: 0.58074\n",
      "Epoch 005: | Train Loss: 0.61048 | Test Loss: 0.63514\n",
      "Epoch 006: | Train Loss: 0.62605 | Test Loss: 0.62797\n",
      "Epoch 007: | Train Loss: 0.62046 | Test Loss: 0.62298\n",
      "Epoch 008: | Train Loss: 0.61624 | Test Loss: 0.62095\n",
      "Epoch 009: | Train Loss: 0.61443 | Test Loss: 0.62034\n",
      "Epoch 010: | Train Loss: 0.61374 | Test Loss: 0.61964\n",
      "Epoch 011: | Train Loss: 0.61317 | Test Loss: 0.61946\n",
      "Epoch 012: | Train Loss: 0.61348 | Test Loss: 0.61924\n",
      "Epoch 013: | Train Loss: 0.61339 | Test Loss: 0.61896\n",
      "Epoch 014: | Train Loss: 0.61293 | Test Loss: 0.61888\n",
      "Epoch 015: | Train Loss: 0.61330 | Test Loss: 0.61914\n",
      "Epoch 016: | Train Loss: 0.61262 | Test Loss: 0.61917\n",
      "Epoch 017: | Train Loss: 0.61351 | Test Loss: 0.61941\n",
      "Epoch 018: | Train Loss: 0.61345 | Test Loss: 0.61889\n",
      "Epoch 019: | Train Loss: 0.61256 | Test Loss: 0.61914\n",
      "Epoch 020: | Train Loss: 0.61287 | Test Loss: 0.61911\n",
      "run with given regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63f32c0fca14deaa325bdb26ceb4f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.60245 | Test Loss: 0.59796\n",
      "Epoch 002: | Train Loss: 0.58174 | Test Loss: 0.59032\n",
      "Epoch 003: | Train Loss: 0.57770 | Test Loss: 0.58976\n",
      "Epoch 004: | Train Loss: 0.57808 | Test Loss: 0.58969\n",
      "Epoch 005: | Train Loss: 0.57738 | Test Loss: 0.58972\n",
      "Epoch 006: | Train Loss: 0.57752 | Test Loss: 0.58968\n",
      "Epoch 007: | Train Loss: 0.57743 | Test Loss: 0.58989\n",
      "Epoch 008: | Train Loss: 0.57729 | Test Loss: 0.58972\n",
      "Epoch 009: | Train Loss: 0.57739 | Test Loss: 0.58980\n",
      "Epoch 010: | Train Loss: 0.57775 | Test Loss: 0.58973\n",
      "Epoch 011: | Train Loss: 0.57687 | Test Loss: 0.58999\n",
      "Epoch 012: | Train Loss: 0.57746 | Test Loss: 0.58980\n",
      "Epoch 013: | Train Loss: 0.57734 | Test Loss: 0.58976\n",
      "Epoch 014: | Train Loss: 0.57729 | Test Loss: 0.58976\n",
      "Epoch 015: | Train Loss: 0.57727 | Test Loss: 0.58986\n",
      "Epoch 016: | Train Loss: 0.57796 | Test Loss: 0.58968\n",
      "Epoch 017: | Train Loss: 0.57737 | Test Loss: 0.58986\n",
      "Epoch 018: | Train Loss: 0.57728 | Test Loss: 0.58986\n",
      "Epoch 019: | Train Loss: 0.57750 | Test Loss: 0.58979\n",
      "Epoch 020: | Train Loss: 0.57737 | Test Loss: 0.58971\n",
      "Epoch 021: | Train Loss: 0.57681 | Test Loss: 0.58980\n",
      "Epoch 022: | Train Loss: 0.57746 | Test Loss: 0.58976\n",
      "Epoch 023: | Train Loss: 0.57746 | Test Loss: 0.58972\n",
      "Epoch 024: | Train Loss: 0.57757 | Test Loss: 0.58974\n",
      "Epoch 025: | Train Loss: 0.57755 | Test Loss: 0.58974\n",
      "Epoch 026: | Train Loss: 0.57715 | Test Loss: 0.58985\n",
      "Epoch 027: | Train Loss: 0.57739 | Test Loss: 0.58984\n",
      "Epoch 028: | Train Loss: 0.57765 | Test Loss: 0.58982\n",
      "Epoch 029: | Train Loss: 0.57739 | Test Loss: 0.58977\n",
      "Epoch 030: | Train Loss: 0.57727 | Test Loss: 0.58977\n",
      "Epoch 031: | Train Loss: 0.57700 | Test Loss: 0.58975\n",
      "Epoch 032: | Train Loss: 0.57690 | Test Loss: 0.58985\n",
      "Epoch 033: | Train Loss: 0.57728 | Test Loss: 0.58990\n",
      "Epoch 034: | Train Loss: 0.57713 | Test Loss: 0.58991\n",
      "Epoch 035: | Train Loss: 0.57715 | Test Loss: 0.58981\n",
      "Epoch 036: | Train Loss: 0.57791 | Test Loss: 0.58972\n",
      "Epoch 037: | Train Loss: 0.57707 | Test Loss: 0.58978\n",
      "Epoch 038: | Train Loss: 0.57713 | Test Loss: 0.58979\n",
      "Epoch 039: | Train Loss: 0.57731 | Test Loss: 0.58974\n",
      "Epoch 040: | Train Loss: 0.57724 | Test Loss: 0.58978\n",
      "Epoch 041: | Train Loss: 0.57726 | Test Loss: 0.58973\n",
      "Epoch 042: | Train Loss: 0.57724 | Test Loss: 0.58978\n",
      "Epoch 043: | Train Loss: 0.57681 | Test Loss: 0.58969\n",
      "Epoch 044: | Train Loss: 0.57774 | Test Loss: 0.58969\n",
      "Epoch 045: | Train Loss: 0.57732 | Test Loss: 0.58973\n",
      "Epoch 046: | Train Loss: 0.57734 | Test Loss: 0.58979\n",
      "Epoch 047: | Train Loss: 0.57733 | Test Loss: 0.58977\n",
      "Epoch 048: | Train Loss: 0.57768 | Test Loss: 0.58971\n",
      "Epoch 049: | Train Loss: 0.57707 | Test Loss: 0.58977\n",
      "Epoch 050: | Train Loss: 0.57726 | Test Loss: 0.58977\n",
      "Epoch 051: | Train Loss: 0.57734 | Test Loss: 0.58976\n",
      "Epoch 052: | Train Loss: 0.57754 | Test Loss: 0.58978\n",
      "Epoch 053: | Train Loss: 0.57771 | Test Loss: 0.58975\n",
      "Epoch 054: | Train Loss: 0.57745 | Test Loss: 0.58978\n",
      "Epoch 055: | Train Loss: 0.57709 | Test Loss: 0.58974\n",
      "Epoch 056: | Train Loss: 0.57706 | Test Loss: 0.58971\n",
      "Epoch 057: | Train Loss: 0.57721 | Test Loss: 0.58973\n",
      "Epoch 058: | Train Loss: 0.57717 | Test Loss: 0.58973\n",
      "Epoch 059: | Train Loss: 0.57700 | Test Loss: 0.58971\n",
      "Epoch 060: | Train Loss: 0.57724 | Test Loss: 0.58973\n",
      "Epoch 061: | Train Loss: 0.57707 | Test Loss: 0.58976\n",
      "Epoch 062: | Train Loss: 0.57748 | Test Loss: 0.58973\n",
      "Epoch 063: | Train Loss: 0.57737 | Test Loss: 0.58973\n",
      "Epoch 064: | Train Loss: 0.57758 | Test Loss: 0.58976\n",
      "Epoch 065: | Train Loss: 0.57750 | Test Loss: 0.58973\n",
      "Epoch 066: | Train Loss: 0.57720 | Test Loss: 0.58976\n",
      "Epoch 067: | Train Loss: 0.57728 | Test Loss: 0.58978\n",
      "Epoch 068: | Train Loss: 0.57730 | Test Loss: 0.58975\n",
      "Epoch 069: | Train Loss: 0.57719 | Test Loss: 0.58975\n",
      "Epoch 070: | Train Loss: 0.57735 | Test Loss: 0.58971\n",
      "Epoch 071: | Train Loss: 0.57715 | Test Loss: 0.58973\n",
      "Epoch 072: | Train Loss: 0.57722 | Test Loss: 0.58968\n",
      "Epoch 073: | Train Loss: 0.57692 | Test Loss: 0.58975\n",
      "Epoch 074: | Train Loss: 0.57720 | Test Loss: 0.58974\n",
      "Epoch 075: | Train Loss: 0.57705 | Test Loss: 0.58972\n",
      "Epoch 076: | Train Loss: 0.57712 | Test Loss: 0.58969\n",
      "Epoch 077: | Train Loss: 0.57735 | Test Loss: 0.58970\n",
      "Epoch 078: | Train Loss: 0.57714 | Test Loss: 0.58973\n",
      "Epoch 079: | Train Loss: 0.57723 | Test Loss: 0.58976\n",
      "Epoch 080: | Train Loss: 0.57746 | Test Loss: 0.58972\n",
      "Epoch 081: | Train Loss: 0.57759 | Test Loss: 0.58975\n",
      "Epoch 082: | Train Loss: 0.57742 | Test Loss: 0.58977\n",
      "Epoch 083: | Train Loss: 0.57723 | Test Loss: 0.58978\n",
      "Epoch 084: | Train Loss: 0.57726 | Test Loss: 0.58976\n",
      "Epoch 085: | Train Loss: 0.57731 | Test Loss: 0.58977\n",
      "Epoch 086: | Train Loss: 0.57687 | Test Loss: 0.58970\n",
      "Epoch 087: | Train Loss: 0.57719 | Test Loss: 0.58975\n",
      "Epoch 088: | Train Loss: 0.57733 | Test Loss: 0.58977\n",
      "Epoch 089: | Train Loss: 0.57686 | Test Loss: 0.58981\n",
      "Epoch 090: | Train Loss: 0.57712 | Test Loss: 0.58982\n",
      "Epoch 091: | Train Loss: 0.57740 | Test Loss: 0.58976\n",
      "Epoch 092: | Train Loss: 0.57731 | Test Loss: 0.58979\n",
      "Epoch 093: | Train Loss: 0.57717 | Test Loss: 0.58974\n",
      "Epoch 094: | Train Loss: 0.57738 | Test Loss: 0.58976\n",
      "Epoch 095: | Train Loss: 0.57725 | Test Loss: 0.58970\n",
      "Epoch 096: | Train Loss: 0.57735 | Test Loss: 0.58970\n",
      "Epoch 097: | Train Loss: 0.57728 | Test Loss: 0.58975\n",
      "Epoch 098: | Train Loss: 0.57701 | Test Loss: 0.58975\n",
      "Epoch 099: | Train Loss: 0.57743 | Test Loss: 0.58972\n",
      "Epoch 100: | Train Loss: 0.57754 | Test Loss: 0.58970\n",
      "Epoch 101: | Train Loss: 0.57691 | Test Loss: 0.58973\n",
      "Epoch 102: | Train Loss: 0.57717 | Test Loss: 0.58975\n",
      "Epoch 103: | Train Loss: 0.57723 | Test Loss: 0.58973\n",
      "Epoch 104: | Train Loss: 0.57700 | Test Loss: 0.58972\n",
      "Epoch 105: | Train Loss: 0.57731 | Test Loss: 0.58977\n",
      "Epoch 106: | Train Loss: 0.57718 | Test Loss: 0.58973\n",
      "Epoch 107: | Train Loss: 0.57696 | Test Loss: 0.58972\n",
      "Epoch 108: | Train Loss: 0.57701 | Test Loss: 0.58974\n",
      "Epoch 109: | Train Loss: 0.57702 | Test Loss: 0.58974\n",
      "Epoch 110: | Train Loss: 0.57741 | Test Loss: 0.58976\n",
      "Epoch 111: | Train Loss: 0.57744 | Test Loss: 0.58969\n",
      "Epoch 112: | Train Loss: 0.57684 | Test Loss: 0.58977\n",
      "Epoch 113: | Train Loss: 0.57714 | Test Loss: 0.58975\n",
      "Epoch 114: | Train Loss: 0.57715 | Test Loss: 0.58974\n",
      "Epoch 115: | Train Loss: 0.57688 | Test Loss: 0.58975\n",
      "Epoch 116: | Train Loss: 0.57761 | Test Loss: 0.58970\n",
      "Epoch 117: | Train Loss: 0.57732 | Test Loss: 0.58974\n",
      "Epoch 118: | Train Loss: 0.57717 | Test Loss: 0.58971\n",
      "Epoch 119: | Train Loss: 0.57706 | Test Loss: 0.58974\n",
      "Epoch 120: | Train Loss: 0.57691 | Test Loss: 0.58975\n",
      "Epoch 121: | Train Loss: 0.57740 | Test Loss: 0.58974\n",
      "Epoch 122: | Train Loss: 0.57745 | Test Loss: 0.58969\n",
      "Epoch 123: | Train Loss: 0.57732 | Test Loss: 0.58970\n",
      "Epoch 124: | Train Loss: 0.57664 | Test Loss: 0.58972\n",
      "Epoch 125: | Train Loss: 0.57705 | Test Loss: 0.58974\n",
      "Epoch 126: | Train Loss: 0.57705 | Test Loss: 0.58975\n",
      "Epoch 127: | Train Loss: 0.57718 | Test Loss: 0.58972\n",
      "Epoch 128: | Train Loss: 0.57752 | Test Loss: 0.58975\n",
      "Epoch 129: | Train Loss: 0.57703 | Test Loss: 0.58976\n",
      "Epoch 130: | Train Loss: 0.57713 | Test Loss: 0.58974\n",
      "Epoch 131: | Train Loss: 0.57732 | Test Loss: 0.58971\n",
      "Epoch 132: | Train Loss: 0.57741 | Test Loss: 0.58974\n",
      "Epoch 133: | Train Loss: 0.57727 | Test Loss: 0.58973\n",
      "Epoch 134: | Train Loss: 0.57702 | Test Loss: 0.58969\n",
      "Epoch 135: | Train Loss: 0.57701 | Test Loss: 0.58971\n",
      "Epoch 136: | Train Loss: 0.57714 | Test Loss: 0.58971\n",
      "Epoch 137: | Train Loss: 0.57688 | Test Loss: 0.58971\n",
      "Epoch 138: | Train Loss: 0.57724 | Test Loss: 0.58972\n",
      "Epoch 139: | Train Loss: 0.57744 | Test Loss: 0.58970\n",
      "Epoch 140: | Train Loss: 0.57725 | Test Loss: 0.58975\n",
      "Epoch 141: | Train Loss: 0.57733 | Test Loss: 0.58972\n",
      "Epoch 142: | Train Loss: 0.57724 | Test Loss: 0.58970\n",
      "Epoch 143: | Train Loss: 0.57668 | Test Loss: 0.58972\n",
      "Epoch 144: | Train Loss: 0.57702 | Test Loss: 0.58970\n",
      "Epoch 145: | Train Loss: 0.57721 | Test Loss: 0.58970\n",
      "Epoch 146: | Train Loss: 0.57719 | Test Loss: 0.58976\n",
      "Epoch 147: | Train Loss: 0.57775 | Test Loss: 0.58970\n",
      "Epoch 148: | Train Loss: 0.57703 | Test Loss: 0.58975\n",
      "Epoch 149: | Train Loss: 0.57719 | Test Loss: 0.58975\n",
      "Epoch 150: | Train Loss: 0.57739 | Test Loss: 0.58972\n",
      "Epoch 151: | Train Loss: 0.57705 | Test Loss: 0.58973\n",
      "Epoch 152: | Train Loss: 0.57710 | Test Loss: 0.58972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: | Train Loss: 0.57722 | Test Loss: 0.58975\n",
      "Epoch 154: | Train Loss: 0.57701 | Test Loss: 0.58978\n",
      "Epoch 155: | Train Loss: 0.57702 | Test Loss: 0.58976\n",
      "Epoch 156: | Train Loss: 0.57722 | Test Loss: 0.58972\n",
      "Epoch 157: | Train Loss: 0.57737 | Test Loss: 0.58976\n",
      "Epoch 158: | Train Loss: 0.57719 | Test Loss: 0.58973\n",
      "Epoch 159: | Train Loss: 0.57715 | Test Loss: 0.58975\n",
      "Epoch 160: | Train Loss: 0.57719 | Test Loss: 0.58973\n",
      "Epoch 161: | Train Loss: 0.57735 | Test Loss: 0.58976\n",
      "Epoch 162: | Train Loss: 0.57724 | Test Loss: 0.58976\n",
      "Epoch 163: | Train Loss: 0.57712 | Test Loss: 0.58977\n",
      "Epoch 164: | Train Loss: 0.57704 | Test Loss: 0.58974\n",
      "Epoch 165: | Train Loss: 0.57714 | Test Loss: 0.58974\n",
      "Epoch 166: | Train Loss: 0.57735 | Test Loss: 0.58979\n",
      "Epoch 167: | Train Loss: 0.57717 | Test Loss: 0.58976\n",
      "Epoch 168: | Train Loss: 0.57714 | Test Loss: 0.58970\n",
      "Epoch 169: | Train Loss: 0.57726 | Test Loss: 0.58973\n",
      "Epoch 170: | Train Loss: 0.57700 | Test Loss: 0.58972\n",
      "Epoch 171: | Train Loss: 0.57703 | Test Loss: 0.58969\n",
      "Epoch 172: | Train Loss: 0.57729 | Test Loss: 0.58975\n",
      "Epoch 173: | Train Loss: 0.57713 | Test Loss: 0.58972\n",
      "Epoch 174: | Train Loss: 0.57715 | Test Loss: 0.58978\n",
      "Epoch 175: | Train Loss: 0.57705 | Test Loss: 0.58972\n",
      "Epoch 176: | Train Loss: 0.57795 | Test Loss: 0.58969\n",
      "Epoch 177: | Train Loss: 0.57718 | Test Loss: 0.58971\n",
      "Epoch 178: | Train Loss: 0.57748 | Test Loss: 0.58969\n",
      "Epoch 179: | Train Loss: 0.57729 | Test Loss: 0.58973\n",
      "Epoch 180: | Train Loss: 0.57690 | Test Loss: 0.58974\n",
      "Epoch 181: | Train Loss: 0.57710 | Test Loss: 0.58971\n",
      "Epoch 182: | Train Loss: 0.57741 | Test Loss: 0.58974\n",
      "Epoch 183: | Train Loss: 0.57739 | Test Loss: 0.58977\n",
      "Epoch 184: | Train Loss: 0.57718 | Test Loss: 0.58976\n",
      "Epoch 185: | Train Loss: 0.57717 | Test Loss: 0.58979\n",
      "Epoch 186: | Train Loss: 0.57753 | Test Loss: 0.58973\n",
      "Epoch 187: | Train Loss: 0.57725 | Test Loss: 0.58974\n",
      "Epoch 188: | Train Loss: 0.57717 | Test Loss: 0.58977\n",
      "Epoch 189: | Train Loss: 0.57725 | Test Loss: 0.58976\n",
      "Epoch 190: | Train Loss: 0.57732 | Test Loss: 0.58975\n",
      "Epoch 191: | Train Loss: 0.57714 | Test Loss: 0.58971\n",
      "Epoch 192: | Train Loss: 0.57719 | Test Loss: 0.58972\n",
      "Epoch 193: | Train Loss: 0.57686 | Test Loss: 0.58972\n",
      "Epoch 194: | Train Loss: 0.57723 | Test Loss: 0.58972\n",
      "Epoch 195: | Train Loss: 0.57717 | Test Loss: 0.58971\n",
      "Epoch 196: | Train Loss: 0.57725 | Test Loss: 0.58970\n",
      "Epoch 197: | Train Loss: 0.57726 | Test Loss: 0.58971\n",
      "Epoch 198: | Train Loss: 0.57721 | Test Loss: 0.58970\n",
      "Epoch 199: | Train Loss: 0.57723 | Test Loss: 0.58969\n",
      "Epoch 200: | Train Loss: 0.57736 | Test Loss: 0.58974\n",
      "Epoch 201: | Train Loss: 0.57719 | Test Loss: 0.58978\n",
      "Epoch 202: | Train Loss: 0.57759 | Test Loss: 0.58970\n",
      "Epoch 203: | Train Loss: 0.57744 | Test Loss: 0.58966\n",
      "Epoch 204: | Train Loss: 0.57731 | Test Loss: 0.58972\n",
      "Epoch 205: | Train Loss: 0.57723 | Test Loss: 0.58972\n",
      "Epoch 206: | Train Loss: 0.57721 | Test Loss: 0.58975\n",
      "Epoch 207: | Train Loss: 0.57730 | Test Loss: 0.58974\n",
      "Epoch 208: | Train Loss: 0.57794 | Test Loss: 0.58972\n",
      "Epoch 209: | Train Loss: 0.57725 | Test Loss: 0.58975\n",
      "Epoch 210: | Train Loss: 0.57752 | Test Loss: 0.58971\n",
      "Epoch 211: | Train Loss: 0.57738 | Test Loss: 0.58973\n",
      "Epoch 212: | Train Loss: 0.57720 | Test Loss: 0.58973\n",
      "Epoch 213: | Train Loss: 0.57695 | Test Loss: 0.58974\n",
      "Epoch 214: | Train Loss: 0.57715 | Test Loss: 0.58972\n",
      "Epoch 215: | Train Loss: 0.57714 | Test Loss: 0.58969\n",
      "Epoch 216: | Train Loss: 0.57728 | Test Loss: 0.58969\n",
      "Epoch 217: | Train Loss: 0.57732 | Test Loss: 0.58975\n",
      "Epoch 218: | Train Loss: 0.57693 | Test Loss: 0.58973\n",
      "Epoch 219: | Train Loss: 0.57703 | Test Loss: 0.58977\n",
      "Epoch 220: | Train Loss: 0.57744 | Test Loss: 0.58975\n",
      "Epoch 221: | Train Loss: 0.57700 | Test Loss: 0.58973\n",
      "Epoch 222: | Train Loss: 0.57714 | Test Loss: 0.58975\n",
      "Epoch 223: | Train Loss: 0.57749 | Test Loss: 0.58973\n",
      "Epoch 224: | Train Loss: 0.57720 | Test Loss: 0.58977\n",
      "Epoch 225: | Train Loss: 0.57703 | Test Loss: 0.58973\n",
      "Epoch 226: | Train Loss: 0.57752 | Test Loss: 0.58969\n",
      "Epoch 227: | Train Loss: 0.57688 | Test Loss: 0.58974\n",
      "Epoch 228: | Train Loss: 0.57720 | Test Loss: 0.58967\n",
      "Epoch 229: | Train Loss: 0.57701 | Test Loss: 0.58973\n",
      "Epoch 230: | Train Loss: 0.57698 | Test Loss: 0.58975\n",
      "Epoch 231: | Train Loss: 0.57716 | Test Loss: 0.58971\n",
      "Epoch 232: | Train Loss: 0.57706 | Test Loss: 0.58972\n",
      "Epoch 233: | Train Loss: 0.57698 | Test Loss: 0.58974\n",
      "Epoch 234: | Train Loss: 0.57742 | Test Loss: 0.58970\n",
      "Epoch 235: | Train Loss: 0.57694 | Test Loss: 0.58972\n",
      "Epoch 236: | Train Loss: 0.57686 | Test Loss: 0.58974\n",
      "Epoch 237: | Train Loss: 0.57713 | Test Loss: 0.58975\n",
      "Epoch 238: | Train Loss: 0.57781 | Test Loss: 0.58974\n",
      "Epoch 239: | Train Loss: 0.57724 | Test Loss: 0.58978\n",
      "Epoch 240: | Train Loss: 0.57701 | Test Loss: 0.58973\n",
      "stats of l2reg of  0.03 are [0.8491  0.83978 0.57716 0.58973]\n",
      "running reg of 0.1\n",
      "initial run of high regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ac3ae8b1834162afeee97f50e37c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.70147 | Test Loss: 0.56021\n",
      "Epoch 002: | Train Loss: 0.56488 | Test Loss: 0.65562\n",
      "Epoch 003: | Train Loss: 0.54895 | Test Loss: 0.54832\n",
      "Epoch 004: | Train Loss: 0.59237 | Test Loss: 0.62530\n",
      "Epoch 005: | Train Loss: 0.61758 | Test Loss: 0.62037\n",
      "Epoch 006: | Train Loss: 0.61455 | Test Loss: 0.61958\n",
      "Epoch 007: | Train Loss: 0.61372 | Test Loss: 0.61900\n",
      "Epoch 008: | Train Loss: 0.61325 | Test Loss: 0.61907\n",
      "Epoch 009: | Train Loss: 0.61253 | Test Loss: 0.61932\n",
      "Epoch 010: | Train Loss: 0.61277 | Test Loss: 0.61975\n",
      "Epoch 011: | Train Loss: 0.61348 | Test Loss: 0.61958\n",
      "Epoch 012: | Train Loss: 0.61307 | Test Loss: 0.61904\n",
      "Epoch 013: | Train Loss: 0.61348 | Test Loss: 0.61896\n",
      "Epoch 014: | Train Loss: 0.61279 | Test Loss: 0.61936\n",
      "Epoch 015: | Train Loss: 0.61358 | Test Loss: 0.61929\n",
      "Epoch 016: | Train Loss: 0.61336 | Test Loss: 0.61892\n",
      "Epoch 017: | Train Loss: 0.61265 | Test Loss: 0.61936\n",
      "Epoch 018: | Train Loss: 0.61283 | Test Loss: 0.61967\n",
      "Epoch 019: | Train Loss: 0.61394 | Test Loss: 0.61924\n",
      "Epoch 020: | Train Loss: 0.61278 | Test Loss: 0.61920\n",
      "run with given regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872133de70dd460a987947bc3a0d3187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.60738 | Test Loss: 0.60979\n",
      "Epoch 002: | Train Loss: 0.59906 | Test Loss: 0.60373\n",
      "Epoch 003: | Train Loss: 0.59308 | Test Loss: 0.60116\n",
      "Epoch 004: | Train Loss: 0.59132 | Test Loss: 0.59912\n",
      "Epoch 005: | Train Loss: 0.58912 | Test Loss: 0.59825\n",
      "Epoch 006: | Train Loss: 0.58848 | Test Loss: 0.59746\n",
      "Epoch 007: | Train Loss: 0.58793 | Test Loss: 0.59702\n",
      "Epoch 008: | Train Loss: 0.58727 | Test Loss: 0.59673\n",
      "Epoch 009: | Train Loss: 0.58693 | Test Loss: 0.59681\n",
      "Epoch 010: | Train Loss: 0.58738 | Test Loss: 0.59658\n",
      "Epoch 011: | Train Loss: 0.58710 | Test Loss: 0.59641\n",
      "Epoch 012: | Train Loss: 0.58652 | Test Loss: 0.59647\n",
      "Epoch 013: | Train Loss: 0.58711 | Test Loss: 0.59664\n",
      "Epoch 014: | Train Loss: 0.58640 | Test Loss: 0.59673\n",
      "Epoch 015: | Train Loss: 0.58640 | Test Loss: 0.59663\n",
      "Epoch 016: | Train Loss: 0.58689 | Test Loss: 0.59690\n",
      "Epoch 017: | Train Loss: 0.58687 | Test Loss: 0.59676\n",
      "Epoch 018: | Train Loss: 0.58746 | Test Loss: 0.59654\n",
      "Epoch 019: | Train Loss: 0.58654 | Test Loss: 0.59672\n",
      "Epoch 020: | Train Loss: 0.58710 | Test Loss: 0.59648\n",
      "Epoch 021: | Train Loss: 0.58684 | Test Loss: 0.59673\n",
      "Epoch 022: | Train Loss: 0.58698 | Test Loss: 0.59655\n",
      "Epoch 023: | Train Loss: 0.58681 | Test Loss: 0.59644\n",
      "Epoch 024: | Train Loss: 0.58691 | Test Loss: 0.59666\n",
      "Epoch 025: | Train Loss: 0.58713 | Test Loss: 0.59666\n",
      "Epoch 026: | Train Loss: 0.58729 | Test Loss: 0.59652\n",
      "Epoch 027: | Train Loss: 0.58708 | Test Loss: 0.59651\n",
      "Epoch 028: | Train Loss: 0.58673 | Test Loss: 0.59651\n",
      "Epoch 029: | Train Loss: 0.58637 | Test Loss: 0.59657\n",
      "Epoch 030: | Train Loss: 0.58693 | Test Loss: 0.59660\n",
      "Epoch 031: | Train Loss: 0.58659 | Test Loss: 0.59663\n",
      "Epoch 032: | Train Loss: 0.58708 | Test Loss: 0.59650\n",
      "Epoch 033: | Train Loss: 0.58688 | Test Loss: 0.59677\n",
      "Epoch 034: | Train Loss: 0.58662 | Test Loss: 0.59650\n",
      "Epoch 035: | Train Loss: 0.58663 | Test Loss: 0.59685\n",
      "Epoch 036: | Train Loss: 0.58722 | Test Loss: 0.59660\n",
      "Epoch 037: | Train Loss: 0.58708 | Test Loss: 0.59665\n",
      "Epoch 038: | Train Loss: 0.58676 | Test Loss: 0.59671\n",
      "Epoch 039: | Train Loss: 0.58709 | Test Loss: 0.59650\n",
      "Epoch 040: | Train Loss: 0.58716 | Test Loss: 0.59666\n",
      "Epoch 041: | Train Loss: 0.58649 | Test Loss: 0.59665\n",
      "Epoch 042: | Train Loss: 0.58690 | Test Loss: 0.59651\n",
      "Epoch 043: | Train Loss: 0.58730 | Test Loss: 0.59641\n",
      "Epoch 044: | Train Loss: 0.58656 | Test Loss: 0.59665\n",
      "Epoch 045: | Train Loss: 0.58693 | Test Loss: 0.59649\n",
      "Epoch 046: | Train Loss: 0.58668 | Test Loss: 0.59652\n",
      "Epoch 047: | Train Loss: 0.58676 | Test Loss: 0.59656\n",
      "Epoch 048: | Train Loss: 0.58714 | Test Loss: 0.59675\n",
      "Epoch 049: | Train Loss: 0.58728 | Test Loss: 0.59662\n",
      "Epoch 050: | Train Loss: 0.58648 | Test Loss: 0.59669\n",
      "Epoch 051: | Train Loss: 0.58666 | Test Loss: 0.59669\n",
      "Epoch 052: | Train Loss: 0.58687 | Test Loss: 0.59666\n",
      "Epoch 053: | Train Loss: 0.58679 | Test Loss: 0.59658\n",
      "Epoch 054: | Train Loss: 0.58674 | Test Loss: 0.59654\n",
      "Epoch 055: | Train Loss: 0.58686 | Test Loss: 0.59658\n",
      "Epoch 056: | Train Loss: 0.58669 | Test Loss: 0.59645\n",
      "Epoch 057: | Train Loss: 0.58690 | Test Loss: 0.59658\n",
      "Epoch 058: | Train Loss: 0.58701 | Test Loss: 0.59666\n",
      "Epoch 059: | Train Loss: 0.58676 | Test Loss: 0.59660\n",
      "Epoch 060: | Train Loss: 0.58654 | Test Loss: 0.59672\n",
      "Epoch 061: | Train Loss: 0.58705 | Test Loss: 0.59685\n",
      "Epoch 062: | Train Loss: 0.58690 | Test Loss: 0.59675\n",
      "Epoch 063: | Train Loss: 0.58707 | Test Loss: 0.59673\n",
      "Epoch 064: | Train Loss: 0.58692 | Test Loss: 0.59668\n",
      "Epoch 065: | Train Loss: 0.58674 | Test Loss: 0.59668\n",
      "Epoch 066: | Train Loss: 0.58715 | Test Loss: 0.59642\n",
      "Epoch 067: | Train Loss: 0.58688 | Test Loss: 0.59663\n",
      "Epoch 068: | Train Loss: 0.58691 | Test Loss: 0.59659\n",
      "Epoch 069: | Train Loss: 0.58670 | Test Loss: 0.59670\n",
      "Epoch 070: | Train Loss: 0.58669 | Test Loss: 0.59664\n",
      "Epoch 071: | Train Loss: 0.58678 | Test Loss: 0.59669\n",
      "Epoch 072: | Train Loss: 0.58700 | Test Loss: 0.59654\n",
      "Epoch 073: | Train Loss: 0.58624 | Test Loss: 0.59659\n",
      "Epoch 074: | Train Loss: 0.58679 | Test Loss: 0.59651\n",
      "Epoch 075: | Train Loss: 0.58687 | Test Loss: 0.59652\n",
      "Epoch 076: | Train Loss: 0.58726 | Test Loss: 0.59644\n",
      "Epoch 077: | Train Loss: 0.58685 | Test Loss: 0.59653\n",
      "Epoch 078: | Train Loss: 0.58644 | Test Loss: 0.59670\n",
      "Epoch 079: | Train Loss: 0.58712 | Test Loss: 0.59651\n",
      "Epoch 080: | Train Loss: 0.58675 | Test Loss: 0.59655\n",
      "Epoch 081: | Train Loss: 0.58665 | Test Loss: 0.59661\n",
      "Epoch 082: | Train Loss: 0.58707 | Test Loss: 0.59634\n",
      "Epoch 083: | Train Loss: 0.58668 | Test Loss: 0.59659\n",
      "Epoch 084: | Train Loss: 0.58681 | Test Loss: 0.59662\n",
      "Epoch 085: | Train Loss: 0.58640 | Test Loss: 0.59668\n",
      "Epoch 086: | Train Loss: 0.58698 | Test Loss: 0.59686\n",
      "Epoch 087: | Train Loss: 0.58714 | Test Loss: 0.59669\n",
      "Epoch 088: | Train Loss: 0.58672 | Test Loss: 0.59668\n",
      "Epoch 089: | Train Loss: 0.58695 | Test Loss: 0.59655\n",
      "Epoch 090: | Train Loss: 0.58679 | Test Loss: 0.59644\n",
      "Epoch 091: | Train Loss: 0.58678 | Test Loss: 0.59664\n",
      "Epoch 092: | Train Loss: 0.58700 | Test Loss: 0.59674\n",
      "Epoch 093: | Train Loss: 0.58707 | Test Loss: 0.59665\n",
      "Epoch 094: | Train Loss: 0.58701 | Test Loss: 0.59656\n",
      "Epoch 095: | Train Loss: 0.58737 | Test Loss: 0.59657\n",
      "Epoch 096: | Train Loss: 0.58669 | Test Loss: 0.59658\n",
      "Epoch 097: | Train Loss: 0.58708 | Test Loss: 0.59675\n",
      "Epoch 098: | Train Loss: 0.58654 | Test Loss: 0.59648\n",
      "Epoch 099: | Train Loss: 0.58688 | Test Loss: 0.59678\n",
      "Epoch 100: | Train Loss: 0.58663 | Test Loss: 0.59669\n",
      "Epoch 101: | Train Loss: 0.58694 | Test Loss: 0.59671\n",
      "Epoch 102: | Train Loss: 0.58689 | Test Loss: 0.59679\n",
      "Epoch 103: | Train Loss: 0.58707 | Test Loss: 0.59661\n",
      "Epoch 104: | Train Loss: 0.58732 | Test Loss: 0.59652\n",
      "Epoch 105: | Train Loss: 0.58683 | Test Loss: 0.59663\n",
      "Epoch 106: | Train Loss: 0.58711 | Test Loss: 0.59655\n",
      "Epoch 107: | Train Loss: 0.58681 | Test Loss: 0.59667\n",
      "Epoch 108: | Train Loss: 0.58675 | Test Loss: 0.59655\n",
      "Epoch 109: | Train Loss: 0.58672 | Test Loss: 0.59679\n",
      "Epoch 110: | Train Loss: 0.58673 | Test Loss: 0.59654\n",
      "Epoch 111: | Train Loss: 0.58662 | Test Loss: 0.59639\n",
      "Epoch 112: | Train Loss: 0.58646 | Test Loss: 0.59662\n",
      "Epoch 113: | Train Loss: 0.58700 | Test Loss: 0.59671\n",
      "Epoch 114: | Train Loss: 0.58718 | Test Loss: 0.59689\n",
      "Epoch 115: | Train Loss: 0.58717 | Test Loss: 0.59659\n",
      "Epoch 116: | Train Loss: 0.58708 | Test Loss: 0.59667\n",
      "Epoch 117: | Train Loss: 0.58694 | Test Loss: 0.59648\n",
      "Epoch 118: | Train Loss: 0.58657 | Test Loss: 0.59655\n",
      "Epoch 119: | Train Loss: 0.58684 | Test Loss: 0.59679\n",
      "Epoch 120: | Train Loss: 0.58701 | Test Loss: 0.59660\n",
      "Epoch 121: | Train Loss: 0.58711 | Test Loss: 0.59662\n",
      "Epoch 122: | Train Loss: 0.58671 | Test Loss: 0.59660\n",
      "Epoch 123: | Train Loss: 0.58699 | Test Loss: 0.59647\n",
      "Epoch 124: | Train Loss: 0.58717 | Test Loss: 0.59666\n",
      "Epoch 125: | Train Loss: 0.58722 | Test Loss: 0.59664\n",
      "Epoch 126: | Train Loss: 0.58673 | Test Loss: 0.59671\n",
      "Epoch 127: | Train Loss: 0.58680 | Test Loss: 0.59666\n",
      "Epoch 128: | Train Loss: 0.58676 | Test Loss: 0.59635\n",
      "Epoch 129: | Train Loss: 0.58648 | Test Loss: 0.59657\n",
      "Epoch 130: | Train Loss: 0.58696 | Test Loss: 0.59653\n",
      "Epoch 131: | Train Loss: 0.58647 | Test Loss: 0.59639\n",
      "Epoch 132: | Train Loss: 0.58707 | Test Loss: 0.59651\n",
      "Epoch 133: | Train Loss: 0.58647 | Test Loss: 0.59679\n",
      "Epoch 134: | Train Loss: 0.58702 | Test Loss: 0.59671\n",
      "Epoch 135: | Train Loss: 0.58667 | Test Loss: 0.59676\n",
      "Epoch 136: | Train Loss: 0.58745 | Test Loss: 0.59651\n",
      "Epoch 137: | Train Loss: 0.58655 | Test Loss: 0.59656\n",
      "Epoch 138: | Train Loss: 0.58699 | Test Loss: 0.59640\n",
      "Epoch 139: | Train Loss: 0.58700 | Test Loss: 0.59652\n",
      "Epoch 140: | Train Loss: 0.58651 | Test Loss: 0.59658\n",
      "Epoch 141: | Train Loss: 0.58683 | Test Loss: 0.59653\n",
      "Epoch 142: | Train Loss: 0.58654 | Test Loss: 0.59656\n",
      "Epoch 143: | Train Loss: 0.58722 | Test Loss: 0.59673\n",
      "Epoch 144: | Train Loss: 0.58661 | Test Loss: 0.59652\n",
      "Epoch 145: | Train Loss: 0.58678 | Test Loss: 0.59666\n",
      "Epoch 146: | Train Loss: 0.58722 | Test Loss: 0.59655\n",
      "Epoch 147: | Train Loss: 0.58625 | Test Loss: 0.59682\n",
      "Epoch 148: | Train Loss: 0.58729 | Test Loss: 0.59645\n",
      "Epoch 149: | Train Loss: 0.58661 | Test Loss: 0.59644\n",
      "Epoch 150: | Train Loss: 0.58665 | Test Loss: 0.59646\n",
      "Epoch 151: | Train Loss: 0.58688 | Test Loss: 0.59649\n",
      "Epoch 152: | Train Loss: 0.58725 | Test Loss: 0.59637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: | Train Loss: 0.58687 | Test Loss: 0.59654\n",
      "Epoch 154: | Train Loss: 0.58656 | Test Loss: 0.59646\n",
      "Epoch 155: | Train Loss: 0.58660 | Test Loss: 0.59656\n",
      "Epoch 156: | Train Loss: 0.58687 | Test Loss: 0.59672\n",
      "Epoch 157: | Train Loss: 0.58711 | Test Loss: 0.59652\n",
      "Epoch 158: | Train Loss: 0.58637 | Test Loss: 0.59659\n",
      "Epoch 159: | Train Loss: 0.58695 | Test Loss: 0.59674\n",
      "Epoch 160: | Train Loss: 0.58702 | Test Loss: 0.59654\n",
      "Epoch 161: | Train Loss: 0.58697 | Test Loss: 0.59673\n",
      "Epoch 162: | Train Loss: 0.58654 | Test Loss: 0.59673\n",
      "Epoch 163: | Train Loss: 0.58720 | Test Loss: 0.59675\n",
      "Epoch 164: | Train Loss: 0.58722 | Test Loss: 0.59677\n",
      "Epoch 165: | Train Loss: 0.58693 | Test Loss: 0.59671\n",
      "Epoch 166: | Train Loss: 0.58687 | Test Loss: 0.59657\n",
      "Epoch 167: | Train Loss: 0.58692 | Test Loss: 0.59664\n",
      "Epoch 168: | Train Loss: 0.58698 | Test Loss: 0.59664\n",
      "Epoch 169: | Train Loss: 0.58688 | Test Loss: 0.59678\n",
      "Epoch 170: | Train Loss: 0.58706 | Test Loss: 0.59649\n",
      "Epoch 171: | Train Loss: 0.58709 | Test Loss: 0.59674\n",
      "Epoch 172: | Train Loss: 0.58714 | Test Loss: 0.59650\n",
      "Epoch 173: | Train Loss: 0.58636 | Test Loss: 0.59665\n",
      "Epoch 174: | Train Loss: 0.58643 | Test Loss: 0.59666\n",
      "Epoch 175: | Train Loss: 0.58735 | Test Loss: 0.59654\n",
      "Epoch 176: | Train Loss: 0.58709 | Test Loss: 0.59653\n",
      "Epoch 177: | Train Loss: 0.58670 | Test Loss: 0.59643\n",
      "Epoch 178: | Train Loss: 0.58652 | Test Loss: 0.59663\n",
      "Epoch 179: | Train Loss: 0.58664 | Test Loss: 0.59666\n",
      "Epoch 180: | Train Loss: 0.58701 | Test Loss: 0.59660\n",
      "Epoch 181: | Train Loss: 0.58674 | Test Loss: 0.59672\n",
      "Epoch 182: | Train Loss: 0.58672 | Test Loss: 0.59663\n",
      "Epoch 183: | Train Loss: 0.58688 | Test Loss: 0.59678\n",
      "Epoch 184: | Train Loss: 0.58688 | Test Loss: 0.59654\n",
      "Epoch 185: | Train Loss: 0.58701 | Test Loss: 0.59691\n",
      "Epoch 186: | Train Loss: 0.58713 | Test Loss: 0.59667\n",
      "Epoch 187: | Train Loss: 0.58700 | Test Loss: 0.59647\n",
      "Epoch 188: | Train Loss: 0.58742 | Test Loss: 0.59638\n",
      "Epoch 189: | Train Loss: 0.58652 | Test Loss: 0.59643\n",
      "Epoch 190: | Train Loss: 0.58674 | Test Loss: 0.59658\n",
      "Epoch 191: | Train Loss: 0.58711 | Test Loss: 0.59645\n",
      "Epoch 192: | Train Loss: 0.58694 | Test Loss: 0.59655\n",
      "Epoch 193: | Train Loss: 0.58714 | Test Loss: 0.59645\n",
      "Epoch 194: | Train Loss: 0.58721 | Test Loss: 0.59630\n",
      "Epoch 195: | Train Loss: 0.58644 | Test Loss: 0.59647\n",
      "Epoch 196: | Train Loss: 0.58641 | Test Loss: 0.59656\n",
      "Epoch 197: | Train Loss: 0.58671 | Test Loss: 0.59653\n",
      "Epoch 198: | Train Loss: 0.58699 | Test Loss: 0.59658\n",
      "Epoch 199: | Train Loss: 0.58700 | Test Loss: 0.59654\n",
      "Epoch 200: | Train Loss: 0.58685 | Test Loss: 0.59670\n",
      "Epoch 201: | Train Loss: 0.58705 | Test Loss: 0.59677\n",
      "Epoch 202: | Train Loss: 0.58711 | Test Loss: 0.59664\n",
      "Epoch 203: | Train Loss: 0.58744 | Test Loss: 0.59668\n",
      "Epoch 204: | Train Loss: 0.58695 | Test Loss: 0.59659\n",
      "Epoch 205: | Train Loss: 0.58706 | Test Loss: 0.59654\n",
      "Epoch 206: | Train Loss: 0.58663 | Test Loss: 0.59655\n",
      "Epoch 207: | Train Loss: 0.58692 | Test Loss: 0.59657\n",
      "Epoch 208: | Train Loss: 0.58688 | Test Loss: 0.59659\n",
      "Epoch 209: | Train Loss: 0.58710 | Test Loss: 0.59652\n",
      "Epoch 210: | Train Loss: 0.58700 | Test Loss: 0.59652\n",
      "Epoch 211: | Train Loss: 0.58669 | Test Loss: 0.59643\n",
      "Epoch 212: | Train Loss: 0.58668 | Test Loss: 0.59631\n",
      "Epoch 213: | Train Loss: 0.58646 | Test Loss: 0.59662\n",
      "Epoch 214: | Train Loss: 0.58658 | Test Loss: 0.59661\n",
      "Epoch 215: | Train Loss: 0.58664 | Test Loss: 0.59667\n",
      "Epoch 216: | Train Loss: 0.58685 | Test Loss: 0.59653\n",
      "Epoch 217: | Train Loss: 0.58683 | Test Loss: 0.59668\n",
      "Epoch 218: | Train Loss: 0.58701 | Test Loss: 0.59669\n",
      "Epoch 219: | Train Loss: 0.58724 | Test Loss: 0.59665\n",
      "Epoch 220: | Train Loss: 0.58693 | Test Loss: 0.59666\n",
      "Epoch 221: | Train Loss: 0.58699 | Test Loss: 0.59668\n",
      "Epoch 222: | Train Loss: 0.58694 | Test Loss: 0.59653\n",
      "Epoch 223: | Train Loss: 0.58682 | Test Loss: 0.59669\n",
      "Epoch 224: | Train Loss: 0.58696 | Test Loss: 0.59661\n",
      "Epoch 225: | Train Loss: 0.58678 | Test Loss: 0.59654\n",
      "Epoch 226: | Train Loss: 0.58675 | Test Loss: 0.59665\n",
      "Epoch 227: | Train Loss: 0.58705 | Test Loss: 0.59660\n",
      "Epoch 228: | Train Loss: 0.58708 | Test Loss: 0.59656\n",
      "Epoch 229: | Train Loss: 0.58668 | Test Loss: 0.59645\n",
      "Epoch 230: | Train Loss: 0.58657 | Test Loss: 0.59652\n",
      "Epoch 231: | Train Loss: 0.58675 | Test Loss: 0.59646\n",
      "Epoch 232: | Train Loss: 0.58681 | Test Loss: 0.59658\n",
      "Epoch 233: | Train Loss: 0.58665 | Test Loss: 0.59659\n",
      "Epoch 234: | Train Loss: 0.58717 | Test Loss: 0.59665\n",
      "Epoch 235: | Train Loss: 0.58688 | Test Loss: 0.59671\n",
      "Epoch 236: | Train Loss: 0.58715 | Test Loss: 0.59682\n",
      "Epoch 237: | Train Loss: 0.58669 | Test Loss: 0.59662\n",
      "Epoch 238: | Train Loss: 0.58648 | Test Loss: 0.59661\n",
      "Epoch 239: | Train Loss: 0.58680 | Test Loss: 0.59670\n",
      "Epoch 240: | Train Loss: 0.58665 | Test Loss: 0.59657\n",
      "stats of l2reg of  0.1 are [0.8491  0.83978 0.58681 0.59657]\n",
      "running reg of 0.3\n",
      "initial run of high regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57bff9db0db4df9b7f2d819b810203b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.62735 | Test Loss: 0.57179\n",
      "Epoch 002: | Train Loss: 0.62405 | Test Loss: 0.57380\n",
      "Epoch 003: | Train Loss: 0.62346 | Test Loss: 0.62766\n",
      "Epoch 004: | Train Loss: 0.62018 | Test Loss: 0.62286\n",
      "Epoch 005: | Train Loss: 0.61597 | Test Loss: 0.62130\n",
      "Epoch 006: | Train Loss: 0.61436 | Test Loss: 0.62039\n",
      "Epoch 007: | Train Loss: 0.61386 | Test Loss: 0.61948\n",
      "Epoch 008: | Train Loss: 0.61300 | Test Loss: 0.61954\n",
      "Epoch 009: | Train Loss: 0.61333 | Test Loss: 0.61935\n",
      "Epoch 010: | Train Loss: 0.61335 | Test Loss: 0.61919\n",
      "Epoch 011: | Train Loss: 0.61376 | Test Loss: 0.61912\n",
      "Epoch 012: | Train Loss: 0.61289 | Test Loss: 0.61873\n",
      "Epoch 013: | Train Loss: 0.61239 | Test Loss: 0.61951\n",
      "Epoch 014: | Train Loss: 0.61351 | Test Loss: 0.61904\n",
      "Epoch 015: | Train Loss: 0.61336 | Test Loss: 0.61940\n",
      "Epoch 016: | Train Loss: 0.61346 | Test Loss: 0.61914\n",
      "Epoch 017: | Train Loss: 0.61300 | Test Loss: 0.61919\n",
      "Epoch 018: | Train Loss: 0.61339 | Test Loss: 0.61908\n",
      "Epoch 019: | Train Loss: 0.61354 | Test Loss: 0.61902\n",
      "Epoch 020: | Train Loss: 0.61274 | Test Loss: 0.61913\n",
      "run with given regularization\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0e3c09ed9b442389def59e841a4d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.61365 | Test Loss: 0.61915\n",
      "Epoch 002: | Train Loss: 0.61313 | Test Loss: 0.61890\n",
      "Epoch 003: | Train Loss: 0.61292 | Test Loss: 0.61911\n",
      "Epoch 004: | Train Loss: 0.61304 | Test Loss: 0.61935\n",
      "Epoch 005: | Train Loss: 0.61277 | Test Loss: 0.61934\n",
      "Epoch 006: | Train Loss: 0.61340 | Test Loss: 0.61901\n",
      "Epoch 007: | Train Loss: 0.61330 | Test Loss: 0.61956\n",
      "Epoch 008: | Train Loss: 0.61315 | Test Loss: 0.61925\n",
      "Epoch 009: | Train Loss: 0.61397 | Test Loss: 0.61896\n",
      "Epoch 010: | Train Loss: 0.61235 | Test Loss: 0.61963\n",
      "Epoch 011: | Train Loss: 0.61330 | Test Loss: 0.61917\n",
      "Epoch 012: | Train Loss: 0.61302 | Test Loss: 0.61924\n",
      "Epoch 013: | Train Loss: 0.61312 | Test Loss: 0.61896\n",
      "Epoch 014: | Train Loss: 0.61349 | Test Loss: 0.61891\n",
      "Epoch 015: | Train Loss: 0.61305 | Test Loss: 0.61923\n",
      "Epoch 016: | Train Loss: 0.61261 | Test Loss: 0.61929\n",
      "Epoch 017: | Train Loss: 0.61327 | Test Loss: 0.61919\n",
      "Epoch 018: | Train Loss: 0.61357 | Test Loss: 0.61901\n",
      "Epoch 019: | Train Loss: 0.61308 | Test Loss: 0.61929\n",
      "Epoch 020: | Train Loss: 0.61340 | Test Loss: 0.61908\n",
      "Epoch 021: | Train Loss: 0.61243 | Test Loss: 0.61952\n",
      "Epoch 022: | Train Loss: 0.61345 | Test Loss: 0.61937\n",
      "Epoch 023: | Train Loss: 0.61382 | Test Loss: 0.61921\n",
      "Epoch 024: | Train Loss: 0.61338 | Test Loss: 0.61903\n",
      "Epoch 025: | Train Loss: 0.61248 | Test Loss: 0.61935\n",
      "Epoch 026: | Train Loss: 0.61345 | Test Loss: 0.61911\n",
      "Epoch 027: | Train Loss: 0.61299 | Test Loss: 0.61952\n",
      "Epoch 028: | Train Loss: 0.61335 | Test Loss: 0.61939\n",
      "Epoch 029: | Train Loss: 0.61326 | Test Loss: 0.61892\n",
      "Epoch 030: | Train Loss: 0.61332 | Test Loss: 0.61895\n",
      "Epoch 031: | Train Loss: 0.61301 | Test Loss: 0.61923\n",
      "Epoch 032: | Train Loss: 0.61307 | Test Loss: 0.61924\n",
      "Epoch 033: | Train Loss: 0.61281 | Test Loss: 0.61908\n",
      "Epoch 034: | Train Loss: 0.61317 | Test Loss: 0.61962\n",
      "Epoch 035: | Train Loss: 0.61324 | Test Loss: 0.61929\n",
      "Epoch 036: | Train Loss: 0.61352 | Test Loss: 0.61933\n",
      "Epoch 037: | Train Loss: 0.61260 | Test Loss: 0.61928\n",
      "Epoch 038: | Train Loss: 0.61375 | Test Loss: 0.61914\n",
      "Epoch 039: | Train Loss: 0.61284 | Test Loss: 0.61922\n",
      "Epoch 040: | Train Loss: 0.61331 | Test Loss: 0.61919\n",
      "Epoch 041: | Train Loss: 0.61310 | Test Loss: 0.61923\n",
      "Epoch 042: | Train Loss: 0.61331 | Test Loss: 0.61900\n",
      "Epoch 043: | Train Loss: 0.61310 | Test Loss: 0.61929\n",
      "Epoch 044: | Train Loss: 0.61253 | Test Loss: 0.61936\n",
      "Epoch 045: | Train Loss: 0.61352 | Test Loss: 0.61946\n",
      "Epoch 046: | Train Loss: 0.61378 | Test Loss: 0.61902\n",
      "Epoch 047: | Train Loss: 0.61270 | Test Loss: 0.61925\n",
      "Epoch 048: | Train Loss: 0.61276 | Test Loss: 0.61980\n",
      "Epoch 049: | Train Loss: 0.61395 | Test Loss: 0.61901\n",
      "Epoch 050: | Train Loss: 0.61298 | Test Loss: 0.61939\n",
      "Epoch 051: | Train Loss: 0.61276 | Test Loss: 0.61939\n",
      "Epoch 052: | Train Loss: 0.61296 | Test Loss: 0.61924\n",
      "Epoch 053: | Train Loss: 0.61291 | Test Loss: 0.61952\n",
      "Epoch 054: | Train Loss: 0.61333 | Test Loss: 0.61951\n",
      "Epoch 055: | Train Loss: 0.61346 | Test Loss: 0.61916\n",
      "Epoch 056: | Train Loss: 0.61309 | Test Loss: 0.61914\n",
      "Epoch 057: | Train Loss: 0.61302 | Test Loss: 0.61931\n",
      "Epoch 058: | Train Loss: 0.61342 | Test Loss: 0.61943\n",
      "Epoch 059: | Train Loss: 0.61328 | Test Loss: 0.61963\n",
      "Epoch 060: | Train Loss: 0.61333 | Test Loss: 0.61926\n",
      "Epoch 061: | Train Loss: 0.61343 | Test Loss: 0.61866\n",
      "Epoch 062: | Train Loss: 0.61218 | Test Loss: 0.61921\n",
      "Epoch 063: | Train Loss: 0.61339 | Test Loss: 0.61965\n",
      "Epoch 064: | Train Loss: 0.61373 | Test Loss: 0.61895\n",
      "Epoch 065: | Train Loss: 0.61291 | Test Loss: 0.61869\n",
      "Epoch 066: | Train Loss: 0.61277 | Test Loss: 0.61927\n",
      "Epoch 067: | Train Loss: 0.61324 | Test Loss: 0.61906\n",
      "Epoch 068: | Train Loss: 0.61265 | Test Loss: 0.61938\n",
      "Epoch 069: | Train Loss: 0.61394 | Test Loss: 0.61899\n",
      "Epoch 070: | Train Loss: 0.61291 | Test Loss: 0.61913\n",
      "Epoch 071: | Train Loss: 0.61299 | Test Loss: 0.61946\n",
      "Epoch 072: | Train Loss: 0.61326 | Test Loss: 0.61968\n",
      "Epoch 073: | Train Loss: 0.61253 | Test Loss: 0.61942\n",
      "Epoch 074: | Train Loss: 0.61339 | Test Loss: 0.61944\n",
      "Epoch 075: | Train Loss: 0.61316 | Test Loss: 0.61911\n",
      "Epoch 076: | Train Loss: 0.61325 | Test Loss: 0.61938\n",
      "Epoch 077: | Train Loss: 0.61245 | Test Loss: 0.61955\n",
      "Epoch 078: | Train Loss: 0.61422 | Test Loss: 0.61943\n",
      "Epoch 079: | Train Loss: 0.61275 | Test Loss: 0.61932\n",
      "Epoch 080: | Train Loss: 0.61332 | Test Loss: 0.61935\n",
      "Epoch 081: | Train Loss: 0.61294 | Test Loss: 0.61936\n",
      "Epoch 082: | Train Loss: 0.61339 | Test Loss: 0.61953\n",
      "Epoch 083: | Train Loss: 0.61288 | Test Loss: 0.61948\n",
      "Epoch 084: | Train Loss: 0.61313 | Test Loss: 0.61987\n",
      "Epoch 085: | Train Loss: 0.61329 | Test Loss: 0.61976\n",
      "Epoch 086: | Train Loss: 0.61317 | Test Loss: 0.61956\n",
      "Epoch 087: | Train Loss: 0.61367 | Test Loss: 0.61958\n",
      "Epoch 088: | Train Loss: 0.61327 | Test Loss: 0.61911\n",
      "Epoch 089: | Train Loss: 0.61250 | Test Loss: 0.61986\n",
      "Epoch 090: | Train Loss: 0.61320 | Test Loss: 0.61968\n",
      "Epoch 091: | Train Loss: 0.61395 | Test Loss: 0.61928\n",
      "Epoch 092: | Train Loss: 0.61312 | Test Loss: 0.61920\n",
      "Epoch 093: | Train Loss: 0.61342 | Test Loss: 0.61912\n",
      "Epoch 094: | Train Loss: 0.61228 | Test Loss: 0.61946\n",
      "Epoch 095: | Train Loss: 0.61403 | Test Loss: 0.61906\n",
      "Epoch 096: | Train Loss: 0.61308 | Test Loss: 0.61872\n",
      "Epoch 097: | Train Loss: 0.61348 | Test Loss: 0.61931\n",
      "Epoch 098: | Train Loss: 0.61316 | Test Loss: 0.61928\n",
      "Epoch 099: | Train Loss: 0.61319 | Test Loss: 0.61930\n",
      "Epoch 100: | Train Loss: 0.61258 | Test Loss: 0.61951\n",
      "Epoch 101: | Train Loss: 0.61332 | Test Loss: 0.61898\n",
      "Epoch 102: | Train Loss: 0.61265 | Test Loss: 0.61967\n",
      "Epoch 103: | Train Loss: 0.61352 | Test Loss: 0.61930\n",
      "Epoch 104: | Train Loss: 0.61321 | Test Loss: 0.61936\n",
      "Epoch 105: | Train Loss: 0.61322 | Test Loss: 0.61923\n",
      "Epoch 106: | Train Loss: 0.61326 | Test Loss: 0.61903\n",
      "Epoch 107: | Train Loss: 0.61271 | Test Loss: 0.61927\n",
      "Epoch 108: | Train Loss: 0.61325 | Test Loss: 0.61925\n",
      "Epoch 109: | Train Loss: 0.61321 | Test Loss: 0.61922\n",
      "Epoch 110: | Train Loss: 0.61363 | Test Loss: 0.61906\n",
      "Epoch 111: | Train Loss: 0.61294 | Test Loss: 0.61899\n",
      "Epoch 112: | Train Loss: 0.61293 | Test Loss: 0.61931\n",
      "Epoch 113: | Train Loss: 0.61314 | Test Loss: 0.61888\n",
      "Epoch 114: | Train Loss: 0.61271 | Test Loss: 0.61921\n",
      "Epoch 115: | Train Loss: 0.61365 | Test Loss: 0.61916\n",
      "Epoch 116: | Train Loss: 0.61341 | Test Loss: 0.61922\n",
      "Epoch 117: | Train Loss: 0.61283 | Test Loss: 0.61928\n",
      "Epoch 118: | Train Loss: 0.61348 | Test Loss: 0.61903\n",
      "Epoch 119: | Train Loss: 0.61251 | Test Loss: 0.61936\n",
      "Epoch 120: | Train Loss: 0.61390 | Test Loss: 0.61941\n",
      "Epoch 121: | Train Loss: 0.61298 | Test Loss: 0.61982\n",
      "Epoch 122: | Train Loss: 0.61342 | Test Loss: 0.61912\n",
      "Epoch 123: | Train Loss: 0.61350 | Test Loss: 0.61888\n",
      "Epoch 124: | Train Loss: 0.61236 | Test Loss: 0.61927\n",
      "Epoch 125: | Train Loss: 0.61307 | Test Loss: 0.61963\n",
      "Epoch 126: | Train Loss: 0.61296 | Test Loss: 0.61941\n",
      "Epoch 127: | Train Loss: 0.61341 | Test Loss: 0.61930\n",
      "Epoch 128: | Train Loss: 0.61274 | Test Loss: 0.61940\n",
      "Epoch 129: | Train Loss: 0.61343 | Test Loss: 0.61948\n",
      "Epoch 130: | Train Loss: 0.61329 | Test Loss: 0.61921\n",
      "Epoch 131: | Train Loss: 0.61393 | Test Loss: 0.61914\n",
      "Epoch 132: | Train Loss: 0.61260 | Test Loss: 0.61897\n",
      "Epoch 133: | Train Loss: 0.61295 | Test Loss: 0.61897\n",
      "Epoch 134: | Train Loss: 0.61334 | Test Loss: 0.61911\n",
      "Epoch 135: | Train Loss: 0.61276 | Test Loss: 0.61913\n",
      "Epoch 136: | Train Loss: 0.61345 | Test Loss: 0.61891\n",
      "Epoch 137: | Train Loss: 0.61285 | Test Loss: 0.61901\n",
      "Epoch 138: | Train Loss: 0.61279 | Test Loss: 0.61929\n",
      "Epoch 139: | Train Loss: 0.61325 | Test Loss: 0.61902\n",
      "Epoch 140: | Train Loss: 0.61306 | Test Loss: 0.61930\n",
      "Epoch 141: | Train Loss: 0.61334 | Test Loss: 0.61904\n",
      "Epoch 142: | Train Loss: 0.61321 | Test Loss: 0.61897\n",
      "Epoch 143: | Train Loss: 0.61285 | Test Loss: 0.61906\n",
      "Epoch 144: | Train Loss: 0.61298 | Test Loss: 0.61927\n",
      "Epoch 145: | Train Loss: 0.61311 | Test Loss: 0.61946\n",
      "Epoch 146: | Train Loss: 0.61354 | Test Loss: 0.61926\n",
      "Epoch 147: | Train Loss: 0.61365 | Test Loss: 0.61893\n",
      "Epoch 148: | Train Loss: 0.61289 | Test Loss: 0.61895\n",
      "Epoch 149: | Train Loss: 0.61320 | Test Loss: 0.61906\n",
      "Epoch 150: | Train Loss: 0.61310 | Test Loss: 0.61916\n",
      "Epoch 151: | Train Loss: 0.61281 | Test Loss: 0.61886\n",
      "Epoch 152: | Train Loss: 0.61286 | Test Loss: 0.61930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: | Train Loss: 0.61333 | Test Loss: 0.61897\n",
      "Epoch 154: | Train Loss: 0.61313 | Test Loss: 0.61927\n",
      "Epoch 155: | Train Loss: 0.61262 | Test Loss: 0.61907\n",
      "Epoch 156: | Train Loss: 0.61337 | Test Loss: 0.61924\n",
      "Epoch 157: | Train Loss: 0.61374 | Test Loss: 0.61846\n",
      "Epoch 158: | Train Loss: 0.61256 | Test Loss: 0.61910\n",
      "Epoch 159: | Train Loss: 0.61318 | Test Loss: 0.61921\n",
      "Epoch 160: | Train Loss: 0.61359 | Test Loss: 0.61898\n",
      "Epoch 161: | Train Loss: 0.61281 | Test Loss: 0.61874\n",
      "Epoch 162: | Train Loss: 0.61309 | Test Loss: 0.61920\n",
      "Epoch 163: | Train Loss: 0.61340 | Test Loss: 0.61922\n",
      "Epoch 164: | Train Loss: 0.61304 | Test Loss: 0.61916\n",
      "Epoch 165: | Train Loss: 0.61312 | Test Loss: 0.61916\n",
      "Epoch 166: | Train Loss: 0.61335 | Test Loss: 0.61861\n",
      "Epoch 167: | Train Loss: 0.61306 | Test Loss: 0.61885\n",
      "Epoch 168: | Train Loss: 0.61250 | Test Loss: 0.61908\n",
      "Epoch 169: | Train Loss: 0.61315 | Test Loss: 0.61922\n",
      "Epoch 170: | Train Loss: 0.61289 | Test Loss: 0.61953\n",
      "Epoch 171: | Train Loss: 0.61349 | Test Loss: 0.61932\n",
      "Epoch 172: | Train Loss: 0.61302 | Test Loss: 0.61905\n",
      "Epoch 173: | Train Loss: 0.61264 | Test Loss: 0.61930\n",
      "Epoch 174: | Train Loss: 0.61310 | Test Loss: 0.61928\n",
      "Epoch 175: | Train Loss: 0.61303 | Test Loss: 0.61929\n",
      "Epoch 176: | Train Loss: 0.61329 | Test Loss: 0.61928\n",
      "Epoch 177: | Train Loss: 0.61346 | Test Loss: 0.61916\n",
      "Epoch 178: | Train Loss: 0.61331 | Test Loss: 0.61923\n",
      "Epoch 179: | Train Loss: 0.61320 | Test Loss: 0.61962\n",
      "Epoch 180: | Train Loss: 0.61347 | Test Loss: 0.61917\n",
      "Epoch 181: | Train Loss: 0.61353 | Test Loss: 0.61907\n",
      "Epoch 182: | Train Loss: 0.61270 | Test Loss: 0.61881\n",
      "Epoch 183: | Train Loss: 0.61326 | Test Loss: 0.61898\n",
      "Epoch 184: | Train Loss: 0.61269 | Test Loss: 0.61906\n",
      "Epoch 185: | Train Loss: 0.61317 | Test Loss: 0.61878\n",
      "Epoch 186: | Train Loss: 0.61311 | Test Loss: 0.61892\n",
      "Epoch 187: | Train Loss: 0.61334 | Test Loss: 0.61878\n",
      "Epoch 188: | Train Loss: 0.61300 | Test Loss: 0.61917\n",
      "Epoch 189: | Train Loss: 0.61295 | Test Loss: 0.61936\n",
      "Epoch 190: | Train Loss: 0.61319 | Test Loss: 0.61907\n",
      "Epoch 191: | Train Loss: 0.61296 | Test Loss: 0.61904\n",
      "Epoch 192: | Train Loss: 0.61297 | Test Loss: 0.61946\n",
      "Epoch 193: | Train Loss: 0.61294 | Test Loss: 0.61941\n",
      "Epoch 194: | Train Loss: 0.61388 | Test Loss: 0.61935\n",
      "Epoch 195: | Train Loss: 0.61256 | Test Loss: 0.61949\n",
      "Epoch 196: | Train Loss: 0.61273 | Test Loss: 0.61950\n",
      "Epoch 197: | Train Loss: 0.61379 | Test Loss: 0.61961\n",
      "Epoch 198: | Train Loss: 0.61375 | Test Loss: 0.61918\n",
      "Epoch 199: | Train Loss: 0.61282 | Test Loss: 0.61897\n",
      "Epoch 200: | Train Loss: 0.61274 | Test Loss: 0.61940\n",
      "Epoch 201: | Train Loss: 0.61314 | Test Loss: 0.61937\n",
      "Epoch 202: | Train Loss: 0.61327 | Test Loss: 0.61953\n",
      "Epoch 203: | Train Loss: 0.61358 | Test Loss: 0.61969\n",
      "Epoch 204: | Train Loss: 0.61318 | Test Loss: 0.61922\n",
      "Epoch 205: | Train Loss: 0.61285 | Test Loss: 0.61956\n",
      "Epoch 206: | Train Loss: 0.61295 | Test Loss: 0.61953\n",
      "Epoch 207: | Train Loss: 0.61353 | Test Loss: 0.61922\n",
      "Epoch 208: | Train Loss: 0.61326 | Test Loss: 0.61939\n",
      "Epoch 209: | Train Loss: 0.61375 | Test Loss: 0.61862\n",
      "Epoch 210: | Train Loss: 0.61284 | Test Loss: 0.61916\n",
      "Epoch 211: | Train Loss: 0.61304 | Test Loss: 0.61917\n",
      "Epoch 212: | Train Loss: 0.61314 | Test Loss: 0.61900\n",
      "Epoch 213: | Train Loss: 0.61339 | Test Loss: 0.61916\n",
      "Epoch 214: | Train Loss: 0.61244 | Test Loss: 0.61909\n",
      "Epoch 215: | Train Loss: 0.61333 | Test Loss: 0.61942\n",
      "Epoch 216: | Train Loss: 0.61302 | Test Loss: 0.61945\n",
      "Epoch 217: | Train Loss: 0.61344 | Test Loss: 0.61915\n",
      "Epoch 218: | Train Loss: 0.61360 | Test Loss: 0.61894\n",
      "Epoch 219: | Train Loss: 0.61310 | Test Loss: 0.61879\n",
      "Epoch 220: | Train Loss: 0.61332 | Test Loss: 0.61893\n",
      "Epoch 221: | Train Loss: 0.61316 | Test Loss: 0.61927\n",
      "Epoch 222: | Train Loss: 0.61291 | Test Loss: 0.61903\n",
      "Epoch 223: | Train Loss: 0.61342 | Test Loss: 0.61903\n",
      "Epoch 224: | Train Loss: 0.61319 | Test Loss: 0.61918\n",
      "Epoch 225: | Train Loss: 0.61278 | Test Loss: 0.61926\n",
      "Epoch 226: | Train Loss: 0.61343 | Test Loss: 0.61893\n",
      "Epoch 227: | Train Loss: 0.61318 | Test Loss: 0.61893\n",
      "Epoch 228: | Train Loss: 0.61273 | Test Loss: 0.61933\n",
      "Epoch 229: | Train Loss: 0.61335 | Test Loss: 0.61983\n",
      "Epoch 230: | Train Loss: 0.61330 | Test Loss: 0.61938\n",
      "Epoch 231: | Train Loss: 0.61391 | Test Loss: 0.61854\n",
      "Epoch 232: | Train Loss: 0.61281 | Test Loss: 0.61905\n",
      "Epoch 233: | Train Loss: 0.61291 | Test Loss: 0.61913\n",
      "Epoch 234: | Train Loss: 0.61268 | Test Loss: 0.61950\n",
      "Epoch 235: | Train Loss: 0.61384 | Test Loss: 0.61914\n",
      "Epoch 236: | Train Loss: 0.61290 | Test Loss: 0.61925\n",
      "Epoch 237: | Train Loss: 0.61305 | Test Loss: 0.61905\n",
      "Epoch 238: | Train Loss: 0.61343 | Test Loss: 0.61900\n",
      "Epoch 239: | Train Loss: 0.61341 | Test Loss: 0.61946\n",
      "Epoch 240: | Train Loss: 0.61305 | Test Loss: 0.61914\n",
      "stats of l2reg of  0.3 are [0.8491  0.83978 0.61305 0.61914]\n",
      "full stats are [[3.0000e-05 9.8671e-01 9.4926e-01 7.6340e-02 4.3522e-01]\n",
      " [1.0000e-04 9.2615e-01 9.0298e-01 2.9351e-01 5.1758e-01]\n",
      " [3.0000e-04 9.5767e-01 9.4281e-01 1.8841e-01 2.7560e-01]\n",
      " [1.0000e-03 9.5167e-01 9.3106e-01 3.8223e-01 5.3368e-01]\n",
      " [3.0000e-03 9.4912e-01 9.3187e-01 1.9344e-01 2.7596e-01]\n",
      " [1.0000e-02 9.5014e-01 9.3348e-01 1.9436e-01 2.8110e-01]\n",
      " [3.0000e-02 8.4910e-01 8.3978e-01 5.7716e-01 5.8973e-01]\n",
      " [1.0000e-01 8.4910e-01 8.3978e-01 5.8681e-01 5.9657e-01]\n",
      " [3.0000e-01 8.4910e-01 8.3978e-01 6.1305e-01 6.1914e-01]]\n"
     ]
    }
   ],
   "source": [
    "regs=[0.00003,0.0001,0.0003,0.001,0.003,0.01,0.03,0.1,0.3]\n",
    "stats_4cn=run_loop_torch2(BinaryClassification4,train_loader,test_loader,train_loader_pred,target_train,target_test,400,64,0.001,regs,num_features=1849)\n",
    "np.savetxt(\"mlp_4n_v2_full_gal_400.txt\",stats_4cn)\n",
    "#output seems less constant maybe more iteration or other improvement needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "36cdad3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats_xgb=np.loadtxt(\"xgb_43sets_gal-type_v1.txt\")\n",
    "stats_log=np.loadtxt(\"log_43sets_gal-type_v1.txt\")\n",
    "stats_conv=np.loadtxt(\"conv2d_4n_v2_full_gal_240.txt\")\n",
    "stats_mlp=np.loadtxt(\"mlp_4n_v2_full_gal_240.txt\")\n",
    "plt.plot(stats_xgb[0],stats_xgb[1],label='xgboost train')\n",
    "plt.plot(stats_xgb[0],stats_xgb[2],label='xgboost test')\n",
    "plt.plot(stats_log[0],stats_log[1],label='logistic train')\n",
    "plt.plot(stats_log[0],stats_log[2],label='logistic test')\n",
    "plt.plot(stats_conv[0],stats_conv[1],label='convolutional train')\n",
    "plt.plot(stats_conv[0],stats_conv[2],label='convolutional test')\n",
    "plt.plot(stats_mlp[0],stats_mlp[1],label='mlp train')\n",
    "plt.plot(stats_mlp[0],stats_mlp[2],label='mlp test')\n",
    "plt.legend(loc=\"best\")\n",
    "#plt.title('Loss vs Epochs')\n",
    "plt.xlabel('l2 regularization')\n",
    "plt.ylabel('F1 score')\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fe84ac36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stats_xgb[0],stats_xgb[3],label='xgboost train')\n",
    "plt.plot(stats_xgb[0],stats_xgb[4],label='xgboost test')\n",
    "plt.plot(stats_log[0],stats_log[3],label='logistic train')\n",
    "plt.plot(stats_log[0],stats_log[4],label='logistic test')\n",
    "plt.plot(stats_conv[0],stats_conv[3],label='convolutional train')\n",
    "plt.plot(stats_conv[0],stats_conv[4],label='convolutional test')\n",
    "plt.plot(stats_mlp[0],stats_mlp[3],label='mlp train')\n",
    "plt.plot(stats_mlp[0],stats_mlp[4],label='mlp test')\n",
    "plt.legend(loc=\"best\")\n",
    "#plt.title('Loss vs Epochs')\n",
    "plt.xlabel('l2 regularization')\n",
    "plt.ylabel('log loss')\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4310060e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stats_xgb[0],stats_xgb[3],label='xgboost train')\n",
    "plt.plot(stats_xgb[0],stats_xgb[4],label='xgboost test')\n",
    "plt.plot(stats_log[0],stats_log[3],label='logistic train')\n",
    "plt.plot(stats_log[0],stats_log[4],label='logistic test')\n",
    "plt.plot(stats_conv[0],stats_conv[3],label='convolutional train')\n",
    "plt.plot(stats_conv[0],stats_conv[4],label='convolutional test')\n",
    "plt.plot(stats_mlp[0],stats_mlp[3],label='mlp train')\n",
    "plt.plot(stats_mlp[0],stats_mlp[4],label='mlp test')\n",
    "plt.legend(loc=\"best\")\n",
    "#plt.title('Loss vs Epochs')\n",
    "plt.xlabel('l2 regularization')\n",
    "plt.ylabel('log loss')\n",
    "plt.xscale(\"log\")\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2be474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
