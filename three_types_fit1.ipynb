{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22fdddf6",
   "metadata": {},
   "source": [
    "# Classifying into 3 types\n",
    "\n",
    "In this notebook I classify astronomical images into 3 types, stars, spiral galaxies and ellipitical galaxies. That are the three most common types of astronomical objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b8e862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.cm as cm\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random as random\n",
    "from astropy.io import fits\n",
    "#torch functions\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "#sklearn helper functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score,f1_score, log_loss\n",
    "#xgboost for comparison\n",
    "from xgboost import XGBClassifier\n",
    "#logistic regression for comparison \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "from functions_ml import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f29370",
   "metadata": {},
   "source": [
    "First I get the galaxy data, in the same way as for the galaxy classification. \n",
    "It is produced by the program get_zoo_galaxies.py.  The is applied  43 times and thus gets data from 43 fields. This fields cover the area from 310 (-50) degree to 60 degree in right ascension with a height from -1.26 to +1.26  degree in Declination. \n",
    "\n",
    "The data consist of two pieces, firstly the images, which were saved as 4 dimensions (1 dimension x of image, second y of image, third channels, forth image in order or batch on torch language) numpy arrays, because torch needs 4d arrays, even when as here only a single channel exist. The image are rdeep images from http://research.iac.es/proyecto/stripe82/pages/data.php\n",
    "This channel is the channel combination with the highest signal to noise ratio. Secondly, information on each images is loaded as data frame, that are in particular the classes spiral and elliptical which are boolean and exclusive here. There are citizen zoo classifications from the zoo projects. Only rather certain ones I included here, but there is no 100% certainty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa56a6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "#getting the list of images\n",
    "myPath='/home/tobias/ml-testing/astr-images'\n",
    "list_images=[f for f in os.listdir(myPath) \n",
    "    if f.endswith('_ell_spiral_im.npy') ]\n",
    "list_images.sort()\n",
    "print(len(list_images))\n",
    "#getting the list of tables \n",
    "list_tables=[f for f in os.listdir(myPath) \n",
    "    if f.endswith('_ell_spiral_table.csv')]\n",
    "list_tables.sort()\n",
    "print(len(list_tables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e765fb16",
   "metadata": {},
   "source": [
    "Next I combine the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0ad645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 43, 1, 7875)\n"
     ]
    }
   ],
   "source": [
    "cutouts_gal=comb_nump_4d(list_images)\n",
    "print(cutouts_gal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca03d9f",
   "metadata": {},
   "source": [
    "Next combining the tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec1afbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tables is 43\n",
      "shape of combined data frame (7875, 51)\n",
      "shape of image file is (43, 43, 1, 7875)\n"
     ]
    }
   ],
   "source": [
    "list_df_gal=[]\n",
    "for i in range(len(list_tables)):\n",
    "    i=pd.read_csv(list_tables[i])\n",
    "    list_df_gal.append(i)  \n",
    "print(f\"number of tables is {len(list_df_gal)}\")    \n",
    "df_gal=pd.concat(list_df_gal,ignore_index=True)\n",
    "print(f\"shape of combined data frame {df_gal.shape}\")\n",
    "print(f\"shape of image file is {cutouts_gal.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7582487",
   "metadata": {},
   "source": [
    "The images and the classification data has the same lengths. Now I am looking on classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf441c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    5766\n",
      "0    2109\n",
      "Name: spiral, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_gal.spiral.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c968fb6",
   "metadata": {},
   "source": [
    "The classes are somewhat inbalanced, the ones which are not spiral are ellipticals. \n",
    "\n",
    "Next I get stars, the images have the same size as the galaxies since that is needed for 3 way classification even although star can distinguished with a smaller window also. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c83aca81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stripe82_01_ell_spiral_im.npy', 'stripe82_02_ell_spiral_im.npy', 'stripe82_03_ell_spiral_im.npy', 'stripe82_04_ell_spiral_im.npy', 'stripe82_05_ell_spiral_im.npy', 'stripe82_06_ell_spiral_im.npy', 'stripe82_07_ell_spiral_im.npy', 'stripe82_08_ell_spiral_im.npy', 'stripe82_09_ell_spiral_im.npy', 'stripe82_10_ell_spiral_im.npy', 'stripe82_11_ell_spiral_im.npy', 'stripe82_12_ell_spiral_im.npy', 'stripe82_13_ell_spiral_im.npy', 'stripe82_14_ell_spiral_im.npy', 'stripe82_15_ell_spiral_im.npy', 'stripe82_16_ell_spiral_im.npy', 'stripe82_17_ell_spiral_im.npy', 'stripe82_18_ell_spiral_im.npy', 'stripe82_19_ell_spiral_im.npy', 'stripe82_20_ell_spiral_im.npy', 'stripe82_21_ell_spiral_im.npy', 'stripe82_22_ell_spiral_im.npy', 'stripe82_23_ell_spiral_im.npy', 'stripe82_24_ell_spiral_im.npy', 'stripe82_25_ell_spiral_im.npy', 'stripe82_26_ell_spiral_im.npy', 'stripe82_27_ell_spiral_im.npy', 'stripe82_28_ell_spiral_im.npy', 'stripe82_29_ell_spiral_im.npy', 'stripe82_30_ell_spiral_im.npy', 'stripe82_31_ell_spiral_im.npy', 'stripe82_32_ell_spiral_im.npy', 'stripe82_33_ell_spiral_im.npy', 'stripe82_34_ell_spiral_im.npy', 'stripe82_35_ell_spiral_im.npy', 'stripe82_36_ell_spiral_im.npy', 'stripe82_37_ell_spiral_im.npy', 'stripe82_38_ell_spiral_im.npy', 'stripe82_39_ell_spiral_im.npy', 'stripe82_40_ell_spiral_im.npy', 'stripe82_41_ell_spiral_im.npy', 'stripe82_42_ell_spiral_im.npy', 'stripe82_43_ell_spiral_im.npy']\n",
      "['stripe82_01_stars_table.csv', 'stripe82_02_stars_table.csv', 'stripe82_03_stars_table.csv', 'stripe82_04_stars_table.csv', 'stripe82_05_stars_table.csv', 'stripe82_06_stars_table.csv', 'stripe82_07_stars_table.csv', 'stripe82_08_stars_table.csv', 'stripe82_09_stars_table.csv', 'stripe82_10_stars_table.csv', 'stripe82_11_stars_table.csv', 'stripe82_12_stars_table.csv', 'stripe82_13_stars_table.csv', 'stripe82_14_stars_table.csv', 'stripe82_15_stars_table.csv', 'stripe82_16_stars_table.csv', 'stripe82_17_stars_table.csv', 'stripe82_18_stars_table.csv', 'stripe82_19_stars_table.csv', 'stripe82_20_stars_table.csv', 'stripe82_21_stars_table.csv', 'stripe82_22_stars_table.csv', 'stripe82_23_stars_table.csv', 'stripe82_24_stars_table.csv', 'stripe82_25_stars_table.csv', 'stripe82_26_stars_table.csv', 'stripe82_27_stars_table.csv', 'stripe82_28_stars_table.csv', 'stripe82_29_stars_table.csv', 'stripe82_30_stars_table.csv', 'stripe82_31_stars_table.csv', 'stripe82_32_stars_table.csv', 'stripe82_33_stars_table.csv', 'stripe82_34_stars_table.csv', 'stripe82_35_stars_table.csv', 'stripe82_36_stars_table.csv', 'stripe82_37_stars_table.csv', 'stripe82_38_stars_table.csv', 'stripe82_39_stars_table.csv', 'stripe82_40_stars_table.csv', 'stripe82_41_stars_table.csv', 'stripe82_42_stars_table.csv', 'stripe82_43_stars_table.csv']\n"
     ]
    }
   ],
   "source": [
    "#getting the list of star images\n",
    "list_images_star=[f for f in os.listdir(myPath) \n",
    "    if f.endswith('_stars_im.npy') ]\n",
    "list_images_star.sort()\n",
    "print(list_images)\n",
    "#getting the list of star tables \n",
    "list_tables_star=[f for f in os.listdir(myPath) \n",
    "    if f.endswith('_stars_table.csv')]\n",
    "list_tables_star.sort()\n",
    "print(list_tables_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752554d3",
   "metadata": {},
   "source": [
    "Combining them now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1522d834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 43, 1, 31530)\n",
      "shape of combined data frame (31530, 48)\n",
      "shape of image file is (43, 43, 1, 31530)\n"
     ]
    }
   ],
   "source": [
    "cutouts_star=comb_nump_4d(list_images_star)\n",
    "print(cutouts_star.shape)\n",
    "list_df_star=[]\n",
    "for i in range(len(list_tables_star)):\n",
    "    i=pd.read_csv(list_tables_star[i])\n",
    "    list_df_star.append(i)  \n",
    "df_star=pd.concat(list_df_star,ignore_index=True)\n",
    "print(f\"shape of combined data frame {df_star.shape}\")\n",
    "print(f\"shape of image file is {cutouts_star.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c762fa",
   "metadata": {},
   "source": [
    "Thast are mpre than 30000 here, clearly more than before. Adding so many of them likely mainly adds computing time. Therefore I now only use 20% of all. That might be increased at some point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07e029a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of used star image data is\n",
      "(6306, 1, 43, 43)\n"
     ]
    }
   ],
   "source": [
    "#images and df split\n",
    "im_star_used, im_star_other,df_star_used, df_star_other = train_test_split(cutouts_star.T,df_star,train_size=0.20, shuffle=True, random_state=1)\n",
    "print(\"shape of used star image data is\")\n",
    "print(im_star_used.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2312acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
